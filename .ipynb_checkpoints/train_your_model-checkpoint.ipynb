{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of files in the source data set: 40000\n",
      "The number of files in the training set: 36191\n",
      "The number of files in the test set: 3809\n",
      "All the classes in the source data set:\n",
      "['且', '世', '东', '九', '亭', '今', '从', '令', '作', '使', '侯', '元', '光', '利', '印', '去', '受', '右', '司', '合', '名', '周', '命', '和', '唯', '堂', '士', '多', '夜', '奉', '女', '好', '始', '字', '孝', '守', '宗', '官', '定', '宜', '室', '家', '寒', '左', '常', '建', '徐', '御', '必', '思', '意', '我', '敬', '新', '易', '春', '更', '朝', '李', '来', '林', '正', '武', '氏', '永', '流', '海', '深', '清', '游', '父', '物', '玉', '用', '申', '白', '皇', '益', '福', '秋', '立', '章', '老', '臣', '良', '莫', '虎', '衣', '西', '起', '足', '身', '通', '遂', '重', '陵', '雨', '高', '黄', '鼎']\n",
      "The number of files for each class in the training set:\n",
      "[361, 360, 361, 360, 362, 361, 362, 361, 363, 362, 360, 361, 362, 364, 361, 362, 362, 360, 364, 362, 360, 364, 363, 363, 360, 361, 361, 362, 362, 362, 364, 361, 363, 363, 362, 362, 363, 364, 362, 362, 361, 360, 361, 361, 362, 362, 360, 361, 363, 362, 360, 363, 364, 361, 363, 362, 361, 362, 364, 363, 362, 362, 362, 363, 366, 360, 361, 361, 362, 362, 361, 362, 363, 363, 363, 360, 360, 363, 361, 361, 361, 363, 365, 360, 362, 361, 362, 362, 362, 360, 363, 364, 361, 361, 362, 362, 363, 363, 363, 362]\n",
      "The number of files for each class in the test set:\n",
      "[39, 40, 39, 40, 38, 39, 38, 39, 37, 38, 40, 39, 38, 36, 39, 38, 38, 40, 36, 38, 40, 36, 37, 37, 40, 39, 39, 38, 38, 38, 36, 39, 37, 37, 38, 38, 37, 36, 38, 38, 39, 40, 39, 39, 38, 38, 40, 39, 37, 38, 40, 37, 36, 39, 37, 38, 39, 38, 36, 37, 38, 38, 38, 37, 34, 40, 39, 39, 38, 38, 39, 38, 37, 37, 37, 40, 40, 37, 39, 39, 39, 37, 35, 40, 38, 39, 38, 38, 38, 40, 37, 36, 39, 39, 38, 38, 37, 37, 37, 38]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "def split_dataset_into_training_and_test_sets(data_dir, training_dir, test_dir, test_size=0.1):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      - data_dir: The directory of the source data.\n",
    "          the structure must be:\n",
    "          directory/\n",
    "                label1/\n",
    "                    label1_001.jpg\n",
    "                    label2_002.jpg\n",
    "                    ...\n",
    "                label2/\n",
    "                    label2_001.jpg\n",
    "                    label2_002.jpg\n",
    "                    ...\n",
    "                 ... \n",
    "      - training_dir: The directory of the training set.\n",
    "      - test_dir: The directory of the test set.\n",
    "      - test_size: A real number, the size of the test set.\n",
    "      \n",
    "    Returns:\n",
    "      - training_samples:\n",
    "      - test_samples:\n",
    "    \"\"\"\n",
    "    if test_size<0 or test_size>1:\n",
    "        raise ValueError('Test size must be a real number between 0 and 1.')\n",
    "        \n",
    "    if not os.path.exists(data_dir):\n",
    "        raise ValueError('The data directory {} does not exist!'.format(data_dir))\n",
    "        \n",
    "    if os.path.exists(training_dir):\n",
    "        shutil.rmtree(training_dir, ignore_errors=False)\n",
    "    os.makedirs(training_dir)\n",
    "    \n",
    "    if os.path.exists(test_dir):\n",
    "        shutil.rmtree(test_dir, ignore_errors=False) \n",
    "    os.makedirs(test_dir)\n",
    "    \n",
    "    training_set_files = 0\n",
    "    test_set_files = 0\n",
    "    \n",
    "    classes = []\n",
    "    training_set = []\n",
    "    test_set = []\n",
    "    \n",
    "    for root, subdirs, files in os.walk(data_dir):\n",
    "        class_name = os.path.basename(root)\n",
    "        if class_name == root:\n",
    "            continue\n",
    "        \n",
    "        training_class_dir = os.path.join(training_dir, class_name)\n",
    "        test_class_dir = os.path.join(test_dir, class_name)\n",
    "                        \n",
    "        if not os.path.exists(training_class_dir):\n",
    "            os.makedirs(training_class_dir)\n",
    "                \n",
    "        if not os.path.exists(test_class_dir):\n",
    "            os.makedirs(test_class_dir)\n",
    "        \n",
    "        total_files = len(files)\n",
    "        mark = np.ones((total_files, ), dtype=int)\n",
    "        mask = np.random.choice(total_files, int(total_files*test_size))\n",
    "        mark[mask] = 0\n",
    "        \n",
    "        class_training_files = 0\n",
    "        class_test_files = 0\n",
    "        for index, file in enumerate(files):\n",
    "            file_path = os.path.join(root, file)\n",
    "            if mark[index] == 1:\n",
    "                shutil.copy(file_path, training_class_dir + '/' + file)\n",
    "                class_training_files += 1\n",
    "            else:\n",
    "                shutil.copy(file_path, test_class_dir + '/' + file)\n",
    "                class_test_files += 1\n",
    "                \n",
    "        training_set_files += class_training_files\n",
    "        test_set_files += class_test_files\n",
    "        classes.append(class_name)\n",
    "        training_set.append(class_training_files)\n",
    "        test_set.append(class_test_files)\n",
    "        \n",
    "    print('The number of files in the source data set: {}'.format(\n",
    "        training_set_files + test_set_files))\n",
    "    print('The number of files in the training set: {}'.format(training_set_files))\n",
    "    print('The number of files in the test set: {}'.format(test_set_files))\n",
    "    \n",
    "    print('All the classes in the source data set:')\n",
    "    print(classes)\n",
    "    print('The number of files for each class in the training set:')\n",
    "    print(training_set)\n",
    "    print('The number of files for each class in the test set:')\n",
    "    print(test_set)\n",
    "    \n",
    "    return training_set_files, test_set_files\n",
    "    \n",
    "training_samples, validation_samples = split_dataset_into_training_and_test_sets(\n",
    "    'train', 'dataset/train', 'dataset/validation', test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GCD of the training samples and validation samples: 1\n"
     ]
    }
   ],
   "source": [
    "def gcd(a, b):\n",
    "    \"\"\" calculate the GCD of a and b\n",
    "    \"\"\"\n",
    "    if b == 0:\n",
    "        return a\n",
    "    else:\n",
    "        return gcd(b, a % b)\n",
    "\n",
    "print('The GCD of the training samples and validation samples: {}'.format(\n",
    "    gcd(training_samples, validation_samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the ImageDataGenerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import BatchNormalization, Activation, Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LeakyReLU, PReLU\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, LambdaCallback\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def clear_session():\n",
    "    K.clear_session()\n",
    "    \n",
    "    \n",
    "def BN_ReLU(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def BN_PReLU(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = PReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def my_generator(path, **kwargs):\n",
    "    \"\"\" obtain the data generator by the path of the datset\n",
    "    more details please refer to 'https://keras.io/preprocessing/image/' \n",
    "    \n",
    "    \"\"\"\n",
    "    rescale = kwargs.get('rescale', None)\n",
    "    horizontal_flip = kwargs.get('horizontal_flip', False)\n",
    "    batch_size = kwargs.get('batch_size', 32)\n",
    "    shuffle = kwargs.get('shuffle', True)\n",
    "    target_size = kwargs.get('target_size', (224, 224))\n",
    "    color_mode = kwargs.get('color_mode', 'rgb')\n",
    "    class_mode = kwargs.get('class_mode', 'categorical')\n",
    "    \n",
    "    gen = ImageDataGenerator(rescale=rescale, \n",
    "                             horizontal_flip=horizontal_flip)\n",
    "    generator = gen.flow_from_directory(path, \n",
    "                                        batch_size=batch_size, \n",
    "                                        shuffle=shuffle, \n",
    "                                        target_size=target_size, \n",
    "                                        color_mode=color_mode, \n",
    "                                        class_mode=class_mode)\n",
    "    return generator\n",
    "\n",
    "\n",
    "def draw_plot(history, savefig_path=None):\n",
    "    \"\"\" draw the history curve in the training stage.\n",
    "    Inputs:\n",
    "      - history:\n",
    "      - savefig_path:\n",
    "    \"\"\"\n",
    "    loss = history.history['loss']\n",
    "    acc = history.history['acc']\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_acc = history.history['val_acc']\n",
    "    x = np.arange(1, len(loss) + 1, 1)\n",
    "    learning_rate = history.history['learning_rate']\n",
    "    decay = history.history['decay']\n",
    "    batch_size = history.history['batch_size']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title('{}, learning rate={}, lr_decay={}, batch size = {}'.format('loss', \n",
    "                                                                          learning_rate, \n",
    "                                                                          decay, \n",
    "                                                                          batch_size))\n",
    "    plt.plot(x, loss, 'g-', label='loss')\n",
    "    plt.plot(x, val_loss, 'y-', label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()\n",
    "    if savefig_path is not None:\n",
    "        plt.savefig(savefig_path + 'loss.png', format='png', dpi=300)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title('{}, learninng rate={}, lr_decay={}, batch_size={}'.format('accuracy', \n",
    "                                                                         learning_rate, \n",
    "                                                                         decay,\n",
    "                                                                         batch_size))\n",
    "    plt.plot(x, acc, 'b-', label='acc')\n",
    "    plt.plot(x, val_acc, 'y-', label='val_acc')\n",
    "    plt.legend()\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('acc')\n",
    "    plt.show()\n",
    "    if savefig_path is not None:\n",
    "        plt.savefig(savefig_path + 'accuracy.png', format='png', dpi=300)\n",
    "    \n",
    "def obtain_number_of_batches(samples, batch_size):\n",
    "    if samples % batch_size == 0:\n",
    "        return samples // batch_size\n",
    "    else:\n",
    "        return samples // batch_size + 1\n",
    "\n",
    "\n",
    "def train_model(model, train_generator, valid_generator, model_path, **kwargs):\n",
    "    \"\"\" train model and save the best weights\n",
    "    Inputs:\n",
    "      - model:\n",
    "      - model_path:\n",
    "      - kwargs:\n",
    "          - batch_size:\n",
    "          - learning_rate:\n",
    "          - decay:\n",
    "          - epochs:\n",
    "          \n",
    "    Return:\n",
    "      - history:\n",
    "    \"\"\"\n",
    "    lr_print_callback = LambdaCallback(on_epoch_end=lambda epoch, logs: print(\n",
    "        ' - lr: {}'.format(K.eval(model.optimizer.lr))))\n",
    "\n",
    "    mdcheck = ModelCheckpoint(filepath=model_path, \n",
    "                          monitor='val_acc', save_best_only=True)\n",
    "    callbacks = [mdcheck]\n",
    "\n",
    "    batch_size = kwargs.get('batch_size', 32)\n",
    "    learning_rate = kwargs.get('learning_rate', 0.01)\n",
    "    decay = kwargs.get('decay', 0.01)\n",
    "    epochs = kwargs.get('epochs', 40)\n",
    "    \n",
    "    adam = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, \n",
    "                decay=decay, amsgrad=False)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=adam, \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    train_steps = len(train_generator)\n",
    "    valid_steps = len(valid_generator)\n",
    "    history = model.fit_generator(train_generator, \n",
    "                                  steps_per_epoch=train_steps,\n",
    "                                  epochs=epochs, \n",
    "                                  validation_data=valid_generator,\n",
    "                                  validation_steps=valid_steps,\n",
    "                                  callbacks=callbacks)\n",
    "\n",
    "    history.history['learning_rate'] = learning_rate\n",
    "    history.history['decay'] = decay\n",
    "    history.history['batch_size'] = batch_size\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def freeze_layers(model, index=-1):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      - model:\n",
    "      - index: the index of the last freezed layer\n",
    "    Return:\n",
    "      - model:\n",
    "    \"\"\"\n",
    "    for layer in model.layers[:index+1]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[index+1:]:\n",
    "        layer.trainable = True\n",
    "    return model\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\" refer to the keras's function 'print_summary()'\n",
    "    \"\"\"\n",
    "    trainable_count = int(\n",
    "        np.sum([K.count_params(p) for p in set(model.trainable_weights)]))\n",
    "    non_trainable_count = int(\n",
    "        np.sum([K.count_params(p) for p in set(model.non_trainable_weights)]))\n",
    "\n",
    "    print('Total params: {:,}'.format(trainable_count + non_trainable_count))\n",
    "    print('Trainable params: {:,}'.format(trainable_count))\n",
    "    print('Non-trainable params: {:,}'.format(non_trainable_count))\n",
    "    \n",
    "    \n",
    "def get_channels(color_mode):\n",
    "    if color_mode == 'rgb':\n",
    "        return 3\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36191 images belonging to 100 classes.\n",
      "Found 3809 images belonging to 100 classes.\n"
     ]
    }
   ],
   "source": [
    "# global variables\n",
    "BATCH_SIZE = 128 # batch size\n",
    "IMAGE_SIZE = 128 # image size\n",
    "COLOR_MODE = 'rgb' # color mode \n",
    "\n",
    "train_generator = my_generator('dataset/train', \n",
    "                               rescale=1./255,\n",
    "                               # horizontal_flip=True, \n",
    "                               shuffle=True,\n",
    "                               batch_size=BATCH_SIZE, \n",
    "                               color_mode=COLOR_MODE, \n",
    "                               target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "valid_generator = my_generator('dataset/validation', \n",
    "                               rescale=1./255,\n",
    "                               shuffle=True,\n",
    "                               batch_size=BATCH_SIZE, \n",
    "                               color_mode=COLOR_MODE, \n",
    "                               target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "class_indices = train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful attributes of the generator\n",
    " - classes: A list, contains the class indices\n",
    " - filenames: A list, contains the path of files in the training set\n",
    " - class_indices: A dictionary, contains the mapping from class names to class indices\n",
    " <br>\n",
    " More details please refer to [Image Preprocessing](https://keras.io/preprocessing/image/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the architecture.\n",
    "I think we shouldn't use networks like ResNet50 because they have too much capacity and it's easy to overfit our dataset. But we can use some layers of those nets, it turns out that this is effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16\n",
    "Badly speaking, I only tried to fine-tune the last Conv block under my limited exploration. The results prove that its performance is satisfactory. Notes that use Dropout and Regularization may make the network more generalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 block1_conv1\n",
      "2 block1_conv2\n",
      "3 block1_pool\n",
      "4 block2_conv1\n",
      "5 block2_conv2\n",
      "6 block2_pool\n",
      "7 block3_conv1\n",
      "8 block3_conv2\n",
      "9 block3_conv3\n",
      "10 block3_pool\n",
      "11 block4_conv1\n",
      "12 block4_conv2\n",
      "13 block4_conv3\n",
      "14 block4_pool\n",
      "15 block5_conv1\n",
      "16 block5_conv2\n",
      "17 block5_conv3\n",
      "18 block5_pool\n",
      "19 flatten_1\n",
      "20 dense_1\n",
      "21 batch_normalization_1\n",
      "22 p_re_lu_1\n",
      "23 dropout_1\n",
      "24 dense_2\n",
      "25 batch_normalization_2\n",
      "26 p_re_lu_2\n",
      "27 dropout_2\n",
      "28 dense_3\n",
      "29 activation_1\n",
      "\n",
      " The architecture of the model:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              16779264  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 2048)              2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 512)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 32,607,140\n",
      "Trainable params: 32,602,020\n",
      "Non-trainable params: 5,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# 96 * 96\n",
    "# 128 * 128\n",
    "# 160 * 160\n",
    "def build_model_based_on_vgg16(fea_dims, out_dims, base_weights=None, \n",
    "                               input_shape=(224, 224, 3), weights=None):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      - fea_dims: \n",
    "      - out_dims:\n",
    "      \n",
    "    Return:\n",
    "       - model: \n",
    "    \"\"\"\n",
    "    vgg16_base_model = VGG16(weights=base_weights, include_top=False, \n",
    "                             input_shape=input_shape)\n",
    "    x = vgg16_base_model.output\n",
    "    x = Flatten()(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(fea_dims)(x)\n",
    "    x = BN_PReLU(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    \n",
    "    x = Dense(512)(x)\n",
    "    x = BN_PReLU(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    \n",
    "    x = Dense(out_dims, kernel_regularizer=l2(0.01))(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    model = Model(inputs=vgg16_base_model.input, outputs=x)\n",
    "    \n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "clear_session()\n",
    "channels = get_channels(COLOR_MODE)\n",
    "model = build_model_based_on_vgg16(2048, 100, base_weights='imagenet', \n",
    "                                   input_shape=(IMAGE_SIZE, IMAGE_SIZE, channels), \n",
    "                                   weights=None)\n",
    "for index, layer in enumerate(model.layers):\n",
    "    print(index, layer.name)\n",
    "    \n",
    "print('\\n The architecture of the model:')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 32,607,140\n",
      "Trainable params: 30,866,532\n",
      "Non-trainable params: 1,740,608\n"
     ]
    }
   ],
   "source": [
    "model = freeze_layers(model, index=10)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "283/283 [==============================] - 149s 526ms/step - loss: 4.3424 - acc: 0.1438 - val_loss: 7.2745 - val_acc: 0.0609\n",
      "Epoch 2/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 2.9110 - acc: 0.4348 - val_loss: 2.4982 - val_acc: 0.5584\n",
      "Epoch 3/50\n",
      "283/283 [==============================] - 147s 518ms/step - loss: 2.2172 - acc: 0.6048 - val_loss: 1.9526 - val_acc: 0.6863\n",
      "Epoch 4/50\n",
      "283/283 [==============================] - 147s 518ms/step - loss: 1.7955 - acc: 0.6948 - val_loss: 1.7408 - val_acc: 0.7065\n",
      "Epoch 5/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 1.4808 - acc: 0.7578 - val_loss: 1.2392 - val_acc: 0.8136\n",
      "Epoch 6/50\n",
      "283/283 [==============================] - 147s 520ms/step - loss: 1.2522 - acc: 0.8027 - val_loss: 1.1159 - val_acc: 0.8322\n",
      "Epoch 7/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 1.0686 - acc: 0.8371 - val_loss: 0.9636 - val_acc: 0.8648\n",
      "Epoch 8/50\n",
      "283/283 [==============================] - 147s 521ms/step - loss: 0.9088 - acc: 0.8673 - val_loss: 0.8962 - val_acc: 0.8729\n",
      "Epoch 9/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.7836 - acc: 0.8891 - val_loss: 0.8293 - val_acc: 0.8761\n",
      "Epoch 10/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.6673 - acc: 0.9111 - val_loss: 0.7291 - val_acc: 0.8939\n",
      "Epoch 11/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.5775 - acc: 0.9273 - val_loss: 0.7255 - val_acc: 0.8908\n",
      "Epoch 12/50\n",
      "283/283 [==============================] - 148s 522ms/step - loss: 0.5156 - acc: 0.9374 - val_loss: 0.6955 - val_acc: 0.8939\n",
      "Epoch 13/50\n",
      "283/283 [==============================] - 147s 520ms/step - loss: 0.4513 - acc: 0.9496 - val_loss: 0.6387 - val_acc: 0.9086\n",
      "Epoch 14/50\n",
      "283/283 [==============================] - 147s 518ms/step - loss: 0.3875 - acc: 0.9620 - val_loss: 0.5961 - val_acc: 0.9076\n",
      "Epoch 15/50\n",
      "283/283 [==============================] - 146s 517ms/step - loss: 0.3282 - acc: 0.9704 - val_loss: 0.5734 - val_acc: 0.9073\n",
      "Epoch 16/50\n",
      "283/283 [==============================] - 148s 522ms/step - loss: 0.3037 - acc: 0.9745 - val_loss: 0.5583 - val_acc: 0.9128\n",
      "Epoch 17/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.2779 - acc: 0.9780 - val_loss: 0.5320 - val_acc: 0.9152\n",
      "Epoch 18/50\n",
      "283/283 [==============================] - 147s 520ms/step - loss: 0.2495 - acc: 0.9821 - val_loss: 0.5164 - val_acc: 0.9136\n",
      "Epoch 19/50\n",
      "283/283 [==============================] - 149s 525ms/step - loss: 0.2365 - acc: 0.9827 - val_loss: 0.5114 - val_acc: 0.9170\n",
      "Epoch 20/50\n",
      "283/283 [==============================] - 146s 517ms/step - loss: 0.2052 - acc: 0.9878 - val_loss: 0.5005 - val_acc: 0.9155\n",
      "Epoch 21/50\n",
      "283/283 [==============================] - 148s 521ms/step - loss: 0.1947 - acc: 0.9884 - val_loss: 0.4758 - val_acc: 0.9186\n",
      "Epoch 22/50\n",
      "283/283 [==============================] - 147s 519ms/step - loss: 0.1719 - acc: 0.9919 - val_loss: 0.4566 - val_acc: 0.9205\n",
      "Epoch 23/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.1488 - acc: 0.9937 - val_loss: 0.4501 - val_acc: 0.9205\n",
      "Epoch 24/50\n",
      "283/283 [==============================] - 146s 518ms/step - loss: 0.1518 - acc: 0.9930 - val_loss: 0.4638 - val_acc: 0.9212\n",
      "Epoch 25/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.1645 - acc: 0.9906 - val_loss: 0.4758 - val_acc: 0.9155\n",
      "Epoch 26/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.1527 - acc: 0.9920 - val_loss: 0.4633 - val_acc: 0.9202\n",
      "Epoch 27/50\n",
      "283/283 [==============================] - 147s 520ms/step - loss: 0.1524 - acc: 0.9910 - val_loss: 0.4725 - val_acc: 0.9170\n",
      "Epoch 28/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.1302 - acc: 0.9952 - val_loss: 0.4354 - val_acc: 0.9210\n",
      "Epoch 29/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.1186 - acc: 0.9949 - val_loss: 0.4244 - val_acc: 0.9223\n",
      "Epoch 30/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.1041 - acc: 0.9965 - val_loss: 0.4003 - val_acc: 0.9270\n",
      "Epoch 31/50\n",
      "283/283 [==============================] - 148s 522ms/step - loss: 0.1025 - acc: 0.9963 - val_loss: 0.4038 - val_acc: 0.9262\n",
      "Epoch 32/50\n",
      "283/283 [==============================] - 149s 527ms/step - loss: 0.0986 - acc: 0.9963 - val_loss: 0.4052 - val_acc: 0.9265\n",
      "Epoch 33/50\n",
      "283/283 [==============================] - 148s 523ms/step - loss: 0.1069 - acc: 0.9954 - val_loss: 0.4408 - val_acc: 0.9218\n",
      "Epoch 34/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.1186 - acc: 0.9938 - val_loss: 0.4431 - val_acc: 0.9205\n",
      "Epoch 35/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.1334 - acc: 0.9915 - val_loss: 0.4735 - val_acc: 0.9212\n",
      "Epoch 36/50\n",
      "283/283 [==============================] - 147s 519ms/step - loss: 0.1137 - acc: 0.9949 - val_loss: 0.4023 - val_acc: 0.9233\n",
      "Epoch 37/50\n",
      "283/283 [==============================] - 146s 517ms/step - loss: 0.0799 - acc: 0.9979 - val_loss: 0.3736 - val_acc: 0.9252\n",
      "Epoch 38/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.0641 - acc: 0.9988 - val_loss: 0.3588 - val_acc: 0.9265\n",
      "Epoch 39/50\n",
      "283/283 [==============================] - 146s 517ms/step - loss: 0.0600 - acc: 0.9990 - val_loss: 0.3519 - val_acc: 0.9302\n",
      "Epoch 40/50\n",
      "283/283 [==============================] - 146s 517ms/step - loss: 0.0618 - acc: 0.9984 - val_loss: 0.3692 - val_acc: 0.9244\n",
      "Epoch 41/50\n",
      "283/283 [==============================] - 148s 522ms/step - loss: 0.0636 - acc: 0.9986 - val_loss: 0.3799 - val_acc: 0.9260\n",
      "Epoch 42/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.0672 - acc: 0.9980 - val_loss: 0.3771 - val_acc: 0.9241\n",
      "Epoch 43/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.0755 - acc: 0.9966 - val_loss: 0.4375 - val_acc: 0.9157\n",
      "Epoch 44/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.0980 - acc: 0.9942 - val_loss: 0.4792 - val_acc: 0.9210\n",
      "Epoch 45/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.1048 - acc: 0.9951 - val_loss: 0.4107 - val_acc: 0.9257\n",
      "Epoch 46/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.0706 - acc: 0.9981 - val_loss: 0.3651 - val_acc: 0.9260\n",
      "Epoch 47/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.0564 - acc: 0.9984 - val_loss: 0.3603 - val_acc: 0.9312\n",
      "Epoch 48/50\n",
      "283/283 [==============================] - 146s 516ms/step - loss: 0.0504 - acc: 0.9988 - val_loss: 0.3439 - val_acc: 0.9278\n",
      "Epoch 49/50\n",
      "283/283 [==============================] - 147s 521ms/step - loss: 0.0536 - acc: 0.9983 - val_loss: 0.3502 - val_acc: 0.9299\n",
      "Epoch 50/50\n",
      "283/283 [==============================] - 148s 524ms/step - loss: 0.0525 - acc: 0.9989 - val_loss: 0.3436 - val_acc: 0.9302\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'lr_decay'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-5a5d15589724>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m                       \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                       decay=DECAY, epochs=EPOCHS)\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdraw_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-116-791786108a83>\u001b[0m in \u001b[0;36mdraw_plot\u001b[1;34m(history, savefig_path)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0mlr_decay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'batch_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lr_decay'"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "DECAY = 1e-3\n",
    "EPOCHS = 50\n",
    "model_path = 'models/VGG16/model.h5'\n",
    "history = train_model(model, train_generator, valid_generator, \n",
    "                      model_path=model_path, \n",
    "                      batch_size=BATCH_SIZE, \n",
    "                      learning_rate = LEARNING_RATE, \n",
    "                      decay=DECAY, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d8f1bff080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d950497ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = []\n",
    "models_list.append((model_path, BATCH_SIZE, (IMAGE_SIZE, IMAGE_SIZE), COLOR_MODE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "def build_model_based_on_vgg19(fea_dims, out_dims, \n",
    "                               base_weights=None, \n",
    "                               input_shape=(224, 224, 3), \n",
    "                               weights_path=None):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d877f90d54b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m model = build_model_based_on_resnet50(1024, 100, base_weights='imagenet', \n\u001b[0;32m     41\u001b[0m                                       \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                                       weights=weights_path)\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-d877f90d54b6>\u001b[0m in \u001b[0;36mbuild_model_based_on_resnet50\u001b[1;34m(fea_dims, out_dims, base_weights, input_shape, weights)\u001b[0m\n\u001b[0;32m     19\u001b[0m     resnet50_base_model = ResNet50(weights=base_weights, \n\u001b[0;32m     20\u001b[0m                                    \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                                    input_shape=input_shape)\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnet50_base_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\applications\\resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[0;32m    269\u001b[0m                                     \u001b[0mcache_subdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                                     md5_hash='a268eb855778b3df3c7506639542a6af')\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'theano'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[0mlayer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_all_kernels_in_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   2654\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2655\u001b[0m                 load_weights_from_hdf5_group(\n\u001b[1;32m-> 2656\u001b[1;33m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[0;32m   2657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers, reshape)\u001b[0m\n\u001b[0;32m   3380\u001b[0m                              ' elements.')\n\u001b[0;32m   3381\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3382\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2371\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2372\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2373\u001b[1;33m         \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m     \u001b[1;31m# hack for list_devices() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "weights_path = None\n",
    "def build_model_based_on_resnet50(fea_dims, out_dims, \n",
    "                                  base_weights=None, \n",
    "                                  input_shape=(229, 229, 3), \n",
    "                                  weights=None):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      - fea_dims: \n",
    "      - out_dims:\n",
    "      - base_weights: the weights of the base model\n",
    "      - input_shape:\n",
    "      - weights:\n",
    "      \n",
    "    Return:\n",
    "       - model: \n",
    "    \"\"\"\n",
    "    resnet50_base_model = ResNet50(weights=base_weights, \n",
    "                                   include_top=False, \n",
    "                                   input_shape=input_shape)\n",
    "    x = resnet50_base_model.output\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    # x = Dense(fea_dims)(x)\n",
    "    # x = BN_ReLU(x)\n",
    "    # x = BN_PReLU(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(out_dims)(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=resnet50_base_model.input, outputs=x)\n",
    "    \n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "        \n",
    "    return model\n",
    "\n",
    "clear_session()\n",
    "model = build_model_based_on_resnet50(1024, 100, base_weights='imagenet', \n",
    "                                      input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), \n",
    "                                      weights=weights_path)\n",
    "for index, layer in enumerate(model.layers):\n",
    "    print(index, layer.name)\n",
    "\n",
    "print('\\nThe architecture of the model: ')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1131/1131 [==============================] - 637s 564ms/step - loss: 4.9436 - acc: 0.0122 - val_loss: 10.2242 - val_acc: 0.0152\n",
      "Epoch 2/40\n",
      "1131/1131 [==============================] - 631s 558ms/step - loss: 4.5673 - acc: 0.0387 - val_loss: 4.1789 - val_acc: 0.0835\n",
      "Epoch 3/40\n",
      "1131/1131 [==============================] - 630s 557ms/step - loss: 3.5106 - acc: 0.1674 - val_loss: 2.8113 - val_acc: 0.3279\n",
      "Epoch 4/40\n",
      "1131/1131 [==============================] - 629s 556ms/step - loss: 2.4586 - acc: 0.3780 - val_loss: 2.3116 - val_acc: 0.5117\n",
      "Epoch 5/40\n",
      "1131/1131 [==============================] - 631s 557ms/step - loss: 1.8806 - acc: 0.5186 - val_loss: 1.5284 - val_acc: 0.6542\n",
      "Epoch 6/40\n",
      "1131/1131 [==============================] - 628s 556ms/step - loss: 1.4572 - acc: 0.6248 - val_loss: 1.2476 - val_acc: 0.7159\n",
      "Epoch 7/40\n",
      "1131/1131 [==============================] - 628s 555ms/step - loss: 1.1651 - acc: 0.7002 - val_loss: 1.1068 - val_acc: 0.7692\n",
      "Epoch 8/40\n",
      "1131/1131 [==============================] - 628s 555ms/step - loss: 0.9775 - acc: 0.7490 - val_loss: 1.1290 - val_acc: 0.7758\n",
      "Epoch 9/40\n",
      "1131/1131 [==============================] - 627s 555ms/step - loss: 0.8145 - acc: 0.7877 - val_loss: 1.0636 - val_acc: 0.7900\n",
      "Epoch 10/40\n",
      "1131/1131 [==============================] - 630s 557ms/step - loss: 0.6975 - acc: 0.8179 - val_loss: 0.8932 - val_acc: 0.8220\n",
      "Epoch 11/40\n",
      "1131/1131 [==============================] - 629s 556ms/step - loss: 0.5856 - acc: 0.8475 - val_loss: 0.8823 - val_acc: 0.8315\n",
      "Epoch 12/40\n",
      "1131/1131 [==============================] - 634s 561ms/step - loss: 0.5020 - acc: 0.8699 - val_loss: 0.8625 - val_acc: 0.8388\n",
      "Epoch 13/40\n",
      "1131/1131 [==============================] - 635s 561ms/step - loss: 0.4425 - acc: 0.8844 - val_loss: 0.8926 - val_acc: 0.8362\n",
      "Epoch 14/40\n",
      "1131/1131 [==============================] - 645s 571ms/step - loss: 0.3679 - acc: 0.9044 - val_loss: 0.8499 - val_acc: 0.8441\n",
      "Epoch 15/40\n",
      "1131/1131 [==============================] - 647s 572ms/step - loss: 0.3171 - acc: 0.9182 - val_loss: 0.8214 - val_acc: 0.8448\n",
      "Epoch 16/40\n",
      "1131/1131 [==============================] - 637s 563ms/step - loss: 0.2651 - acc: 0.9319 - val_loss: 0.8492 - val_acc: 0.8441\n",
      "Epoch 17/40\n",
      "1131/1131 [==============================] - 633s 559ms/step - loss: 0.2246 - acc: 0.9419 - val_loss: 0.9159 - val_acc: 0.8435\n",
      "Epoch 18/40\n",
      "1129/1131 [============================>.] - ETA: 1s - loss: 0.1859 - acc: 0.9534"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-c96ad742b0fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m                       \u001b[0mweights_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                       \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                       decay=DECAY, epochs=EPOCHS)\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdraw_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msavefig_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-6b78d61421c6>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_generator, valid_generator, weights_path, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m                                   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                                   \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m                                   callbacks=callbacks)\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2224\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.01 # learning rate\n",
    "DECAY = 0.01 # learning rate decay\n",
    "EPOCHS = 40 # epochs\n",
    "\n",
    "\n",
    "# model = freeze_layers(model, index=174)\n",
    "weights_path = 'models/ResNet50/weights.hdf5'\n",
    "history = train_model(model, train_generator, valid_generator, \n",
    "                      weights_path, batch_size=BATCH_SIZE, \n",
    "                      learning_rate=LEARNING_RATE, \n",
    "                      decay=DECAY, epochs=EPOCHS)\n",
    "\n",
    "draw_plot(history, savefig_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv2d_1\n",
      "2 batch_normalization_1\n",
      "3 activation_1\n",
      "4 conv2d_2\n",
      "5 batch_normalization_2\n",
      "6 activation_2\n",
      "7 conv2d_3\n",
      "8 batch_normalization_3\n",
      "9 activation_3\n",
      "10 max_pooling2d_1\n",
      "11 conv2d_4\n",
      "12 batch_normalization_4\n",
      "13 activation_4\n",
      "14 conv2d_5\n",
      "15 batch_normalization_5\n",
      "16 activation_5\n",
      "17 max_pooling2d_2\n",
      "18 conv2d_9\n",
      "19 batch_normalization_9\n",
      "20 activation_9\n",
      "21 conv2d_7\n",
      "22 conv2d_10\n",
      "23 batch_normalization_7\n",
      "24 batch_normalization_10\n",
      "25 activation_7\n",
      "26 activation_10\n",
      "27 average_pooling2d_1\n",
      "28 conv2d_6\n",
      "29 conv2d_8\n",
      "30 conv2d_11\n",
      "31 conv2d_12\n",
      "32 batch_normalization_6\n",
      "33 batch_normalization_8\n",
      "34 batch_normalization_11\n",
      "35 batch_normalization_12\n",
      "36 activation_6\n",
      "37 activation_8\n",
      "38 activation_11\n",
      "39 activation_12\n",
      "40 mixed_5b\n",
      "41 conv2d_16\n",
      "42 batch_normalization_16\n",
      "43 activation_16\n",
      "44 conv2d_14\n",
      "45 conv2d_17\n",
      "46 batch_normalization_14\n",
      "47 batch_normalization_17\n",
      "48 activation_14\n",
      "49 activation_17\n",
      "50 conv2d_13\n",
      "51 conv2d_15\n",
      "52 conv2d_18\n",
      "53 batch_normalization_13\n",
      "54 batch_normalization_15\n",
      "55 batch_normalization_18\n",
      "56 activation_13\n",
      "57 activation_15\n",
      "58 activation_18\n",
      "59 block35_1_mixed\n",
      "60 block35_1_conv\n",
      "61 block35_1\n",
      "62 block35_1_ac\n",
      "63 conv2d_22\n",
      "64 batch_normalization_22\n",
      "65 activation_22\n",
      "66 conv2d_20\n",
      "67 conv2d_23\n",
      "68 batch_normalization_20\n",
      "69 batch_normalization_23\n",
      "70 activation_20\n",
      "71 activation_23\n",
      "72 conv2d_19\n",
      "73 conv2d_21\n",
      "74 conv2d_24\n",
      "75 batch_normalization_19\n",
      "76 batch_normalization_21\n",
      "77 batch_normalization_24\n",
      "78 activation_19\n",
      "79 activation_21\n",
      "80 activation_24\n",
      "81 block35_2_mixed\n",
      "82 block35_2_conv\n",
      "83 block35_2\n",
      "84 block35_2_ac\n",
      "85 conv2d_28\n",
      "86 batch_normalization_28\n",
      "87 activation_28\n",
      "88 conv2d_26\n",
      "89 conv2d_29\n",
      "90 batch_normalization_26\n",
      "91 batch_normalization_29\n",
      "92 activation_26\n",
      "93 activation_29\n",
      "94 conv2d_25\n",
      "95 conv2d_27\n",
      "96 conv2d_30\n",
      "97 batch_normalization_25\n",
      "98 batch_normalization_27\n",
      "99 batch_normalization_30\n",
      "100 activation_25\n",
      "101 activation_27\n",
      "102 activation_30\n",
      "103 block35_3_mixed\n",
      "104 block35_3_conv\n",
      "105 block35_3\n",
      "106 block35_3_ac\n",
      "107 conv2d_34\n",
      "108 batch_normalization_34\n",
      "109 activation_34\n",
      "110 conv2d_32\n",
      "111 conv2d_35\n",
      "112 batch_normalization_32\n",
      "113 batch_normalization_35\n",
      "114 activation_32\n",
      "115 activation_35\n",
      "116 conv2d_31\n",
      "117 conv2d_33\n",
      "118 conv2d_36\n",
      "119 batch_normalization_31\n",
      "120 batch_normalization_33\n",
      "121 batch_normalization_36\n",
      "122 activation_31\n",
      "123 activation_33\n",
      "124 activation_36\n",
      "125 block35_4_mixed\n",
      "126 block35_4_conv\n",
      "127 block35_4\n",
      "128 block35_4_ac\n",
      "129 conv2d_40\n",
      "130 batch_normalization_40\n",
      "131 activation_40\n",
      "132 conv2d_38\n",
      "133 conv2d_41\n",
      "134 batch_normalization_38\n",
      "135 batch_normalization_41\n",
      "136 activation_38\n",
      "137 activation_41\n",
      "138 conv2d_37\n",
      "139 conv2d_39\n",
      "140 conv2d_42\n",
      "141 batch_normalization_37\n",
      "142 batch_normalization_39\n",
      "143 batch_normalization_42\n",
      "144 activation_37\n",
      "145 activation_39\n",
      "146 activation_42\n",
      "147 block35_5_mixed\n",
      "148 block35_5_conv\n",
      "149 block35_5\n",
      "150 block35_5_ac\n",
      "151 conv2d_46\n",
      "152 batch_normalization_46\n",
      "153 activation_46\n",
      "154 conv2d_44\n",
      "155 conv2d_47\n",
      "156 batch_normalization_44\n",
      "157 batch_normalization_47\n",
      "158 activation_44\n",
      "159 activation_47\n",
      "160 conv2d_43\n",
      "161 conv2d_45\n",
      "162 conv2d_48\n",
      "163 batch_normalization_43\n",
      "164 batch_normalization_45\n",
      "165 batch_normalization_48\n",
      "166 activation_43\n",
      "167 activation_45\n",
      "168 activation_48\n",
      "169 block35_6_mixed\n",
      "170 block35_6_conv\n",
      "171 block35_6\n",
      "172 block35_6_ac\n",
      "173 conv2d_52\n",
      "174 batch_normalization_52\n",
      "175 activation_52\n",
      "176 conv2d_50\n",
      "177 conv2d_53\n",
      "178 batch_normalization_50\n",
      "179 batch_normalization_53\n",
      "180 activation_50\n",
      "181 activation_53\n",
      "182 conv2d_49\n",
      "183 conv2d_51\n",
      "184 conv2d_54\n",
      "185 batch_normalization_49\n",
      "186 batch_normalization_51\n",
      "187 batch_normalization_54\n",
      "188 activation_49\n",
      "189 activation_51\n",
      "190 activation_54\n",
      "191 block35_7_mixed\n",
      "192 block35_7_conv\n",
      "193 block35_7\n",
      "194 block35_7_ac\n",
      "195 conv2d_58\n",
      "196 batch_normalization_58\n",
      "197 activation_58\n",
      "198 conv2d_56\n",
      "199 conv2d_59\n",
      "200 batch_normalization_56\n",
      "201 batch_normalization_59\n",
      "202 activation_56\n",
      "203 activation_59\n",
      "204 conv2d_55\n",
      "205 conv2d_57\n",
      "206 conv2d_60\n",
      "207 batch_normalization_55\n",
      "208 batch_normalization_57\n",
      "209 batch_normalization_60\n",
      "210 activation_55\n",
      "211 activation_57\n",
      "212 activation_60\n",
      "213 block35_8_mixed\n",
      "214 block35_8_conv\n",
      "215 block35_8\n",
      "216 block35_8_ac\n",
      "217 conv2d_64\n",
      "218 batch_normalization_64\n",
      "219 activation_64\n",
      "220 conv2d_62\n",
      "221 conv2d_65\n",
      "222 batch_normalization_62\n",
      "223 batch_normalization_65\n",
      "224 activation_62\n",
      "225 activation_65\n",
      "226 conv2d_61\n",
      "227 conv2d_63\n",
      "228 conv2d_66\n",
      "229 batch_normalization_61\n",
      "230 batch_normalization_63\n",
      "231 batch_normalization_66\n",
      "232 activation_61\n",
      "233 activation_63\n",
      "234 activation_66\n",
      "235 block35_9_mixed\n",
      "236 block35_9_conv\n",
      "237 block35_9\n",
      "238 block35_9_ac\n",
      "239 conv2d_70\n",
      "240 batch_normalization_70\n",
      "241 activation_70\n",
      "242 conv2d_68\n",
      "243 conv2d_71\n",
      "244 batch_normalization_68\n",
      "245 batch_normalization_71\n",
      "246 activation_68\n",
      "247 activation_71\n",
      "248 conv2d_67\n",
      "249 conv2d_69\n",
      "250 conv2d_72\n",
      "251 batch_normalization_67\n",
      "252 batch_normalization_69\n",
      "253 batch_normalization_72\n",
      "254 activation_67\n",
      "255 activation_69\n",
      "256 activation_72\n",
      "257 block35_10_mixed\n",
      "258 block35_10_conv\n",
      "259 block35_10\n",
      "260 block35_10_ac\n",
      "261 conv2d_74\n",
      "262 batch_normalization_74\n",
      "263 activation_74\n",
      "264 conv2d_75\n",
      "265 batch_normalization_75\n",
      "266 activation_75\n",
      "267 conv2d_73\n",
      "268 conv2d_76\n",
      "269 batch_normalization_73\n",
      "270 batch_normalization_76\n",
      "271 activation_73\n",
      "272 activation_76\n",
      "273 max_pooling2d_3\n",
      "274 mixed_6a\n",
      "275 conv2d_78\n",
      "276 batch_normalization_78\n",
      "277 activation_78\n",
      "278 conv2d_79\n",
      "279 batch_normalization_79\n",
      "280 activation_79\n",
      "281 conv2d_77\n",
      "282 conv2d_80\n",
      "283 batch_normalization_77\n",
      "284 batch_normalization_80\n",
      "285 activation_77\n",
      "286 activation_80\n",
      "287 block17_1_mixed\n",
      "288 block17_1_conv\n",
      "289 block17_1\n",
      "290 block17_1_ac\n",
      "291 conv2d_82\n",
      "292 batch_normalization_82\n",
      "293 activation_82\n",
      "294 conv2d_83\n",
      "295 batch_normalization_83\n",
      "296 activation_83\n",
      "297 conv2d_81\n",
      "298 conv2d_84\n",
      "299 batch_normalization_81\n",
      "300 batch_normalization_84\n",
      "301 activation_81\n",
      "302 activation_84\n",
      "303 block17_2_mixed\n",
      "304 block17_2_conv\n",
      "305 block17_2\n",
      "306 block17_2_ac\n",
      "307 conv2d_86\n",
      "308 batch_normalization_86\n",
      "309 activation_86\n",
      "310 conv2d_87\n",
      "311 batch_normalization_87\n",
      "312 activation_87\n",
      "313 conv2d_85\n",
      "314 conv2d_88\n",
      "315 batch_normalization_85\n",
      "316 batch_normalization_88\n",
      "317 activation_85\n",
      "318 activation_88\n",
      "319 block17_3_mixed\n",
      "320 block17_3_conv\n",
      "321 block17_3\n",
      "322 block17_3_ac\n",
      "323 conv2d_90\n",
      "324 batch_normalization_90\n",
      "325 activation_90\n",
      "326 conv2d_91\n",
      "327 batch_normalization_91\n",
      "328 activation_91\n",
      "329 conv2d_89\n",
      "330 conv2d_92\n",
      "331 batch_normalization_89\n",
      "332 batch_normalization_92\n",
      "333 activation_89\n",
      "334 activation_92\n",
      "335 block17_4_mixed\n",
      "336 block17_4_conv\n",
      "337 block17_4\n",
      "338 block17_4_ac\n",
      "339 conv2d_94\n",
      "340 batch_normalization_94\n",
      "341 activation_94\n",
      "342 conv2d_95\n",
      "343 batch_normalization_95\n",
      "344 activation_95\n",
      "345 conv2d_93\n",
      "346 conv2d_96\n",
      "347 batch_normalization_93\n",
      "348 batch_normalization_96\n",
      "349 activation_93\n",
      "350 activation_96\n",
      "351 block17_5_mixed\n",
      "352 block17_5_conv\n",
      "353 block17_5\n",
      "354 block17_5_ac\n",
      "355 conv2d_98\n",
      "356 batch_normalization_98\n",
      "357 activation_98\n",
      "358 conv2d_99\n",
      "359 batch_normalization_99\n",
      "360 activation_99\n",
      "361 conv2d_97\n",
      "362 conv2d_100\n",
      "363 batch_normalization_97\n",
      "364 batch_normalization_100\n",
      "365 activation_97\n",
      "366 activation_100\n",
      "367 block17_6_mixed\n",
      "368 block17_6_conv\n",
      "369 block17_6\n",
      "370 block17_6_ac\n",
      "371 conv2d_102\n",
      "372 batch_normalization_102\n",
      "373 activation_102\n",
      "374 conv2d_103\n",
      "375 batch_normalization_103\n",
      "376 activation_103\n",
      "377 conv2d_101\n",
      "378 conv2d_104\n",
      "379 batch_normalization_101\n",
      "380 batch_normalization_104\n",
      "381 activation_101\n",
      "382 activation_104\n",
      "383 block17_7_mixed\n",
      "384 block17_7_conv\n",
      "385 block17_7\n",
      "386 block17_7_ac\n",
      "387 conv2d_106\n",
      "388 batch_normalization_106\n",
      "389 activation_106\n",
      "390 conv2d_107\n",
      "391 batch_normalization_107\n",
      "392 activation_107\n",
      "393 conv2d_105\n",
      "394 conv2d_108\n",
      "395 batch_normalization_105\n",
      "396 batch_normalization_108\n",
      "397 activation_105\n",
      "398 activation_108\n",
      "399 block17_8_mixed\n",
      "400 block17_8_conv\n",
      "401 block17_8\n",
      "402 block17_8_ac\n",
      "403 conv2d_110\n",
      "404 batch_normalization_110\n",
      "405 activation_110\n",
      "406 conv2d_111\n",
      "407 batch_normalization_111\n",
      "408 activation_111\n",
      "409 conv2d_109\n",
      "410 conv2d_112\n",
      "411 batch_normalization_109\n",
      "412 batch_normalization_112\n",
      "413 activation_109\n",
      "414 activation_112\n",
      "415 block17_9_mixed\n",
      "416 block17_9_conv\n",
      "417 block17_9\n",
      "418 block17_9_ac\n",
      "419 conv2d_114\n",
      "420 batch_normalization_114\n",
      "421 activation_114\n",
      "422 conv2d_115\n",
      "423 batch_normalization_115\n",
      "424 activation_115\n",
      "425 conv2d_113\n",
      "426 conv2d_116\n",
      "427 batch_normalization_113\n",
      "428 batch_normalization_116\n",
      "429 activation_113\n",
      "430 activation_116\n",
      "431 block17_10_mixed\n",
      "432 block17_10_conv\n",
      "433 block17_10\n",
      "434 block17_10_ac\n",
      "435 conv2d_118\n",
      "436 batch_normalization_118\n",
      "437 activation_118\n",
      "438 conv2d_119\n",
      "439 batch_normalization_119\n",
      "440 activation_119\n",
      "441 conv2d_117\n",
      "442 conv2d_120\n",
      "443 batch_normalization_117\n",
      "444 batch_normalization_120\n",
      "445 activation_117\n",
      "446 activation_120\n",
      "447 block17_11_mixed\n",
      "448 block17_11_conv\n",
      "449 block17_11\n",
      "450 block17_11_ac\n",
      "451 conv2d_122\n",
      "452 batch_normalization_122\n",
      "453 activation_122\n",
      "454 conv2d_123\n",
      "455 batch_normalization_123\n",
      "456 activation_123\n",
      "457 conv2d_121\n",
      "458 conv2d_124\n",
      "459 batch_normalization_121\n",
      "460 batch_normalization_124\n",
      "461 activation_121\n",
      "462 activation_124\n",
      "463 block17_12_mixed\n",
      "464 block17_12_conv\n",
      "465 block17_12\n",
      "466 block17_12_ac\n",
      "467 conv2d_126\n",
      "468 batch_normalization_126\n",
      "469 activation_126\n",
      "470 conv2d_127\n",
      "471 batch_normalization_127\n",
      "472 activation_127\n",
      "473 conv2d_125\n",
      "474 conv2d_128\n",
      "475 batch_normalization_125\n",
      "476 batch_normalization_128\n",
      "477 activation_125\n",
      "478 activation_128\n",
      "479 block17_13_mixed\n",
      "480 block17_13_conv\n",
      "481 block17_13\n",
      "482 block17_13_ac\n",
      "483 conv2d_130\n",
      "484 batch_normalization_130\n",
      "485 activation_130\n",
      "486 conv2d_131\n",
      "487 batch_normalization_131\n",
      "488 activation_131\n",
      "489 conv2d_129\n",
      "490 conv2d_132\n",
      "491 batch_normalization_129\n",
      "492 batch_normalization_132\n",
      "493 activation_129\n",
      "494 activation_132\n",
      "495 block17_14_mixed\n",
      "496 block17_14_conv\n",
      "497 block17_14\n",
      "498 block17_14_ac\n",
      "499 conv2d_134\n",
      "500 batch_normalization_134\n",
      "501 activation_134\n",
      "502 conv2d_135\n",
      "503 batch_normalization_135\n",
      "504 activation_135\n",
      "505 conv2d_133\n",
      "506 conv2d_136\n",
      "507 batch_normalization_133\n",
      "508 batch_normalization_136\n",
      "509 activation_133\n",
      "510 activation_136\n",
      "511 block17_15_mixed\n",
      "512 block17_15_conv\n",
      "513 block17_15\n",
      "514 block17_15_ac\n",
      "515 conv2d_138\n",
      "516 batch_normalization_138\n",
      "517 activation_138\n",
      "518 conv2d_139\n",
      "519 batch_normalization_139\n",
      "520 activation_139\n",
      "521 conv2d_137\n",
      "522 conv2d_140\n",
      "523 batch_normalization_137\n",
      "524 batch_normalization_140\n",
      "525 activation_137\n",
      "526 activation_140\n",
      "527 block17_16_mixed\n",
      "528 block17_16_conv\n",
      "529 block17_16\n",
      "530 block17_16_ac\n",
      "531 conv2d_142\n",
      "532 batch_normalization_142\n",
      "533 activation_142\n",
      "534 conv2d_143\n",
      "535 batch_normalization_143\n",
      "536 activation_143\n",
      "537 conv2d_141\n",
      "538 conv2d_144\n",
      "539 batch_normalization_141\n",
      "540 batch_normalization_144\n",
      "541 activation_141\n",
      "542 activation_144\n",
      "543 block17_17_mixed\n",
      "544 block17_17_conv\n",
      "545 block17_17\n",
      "546 block17_17_ac\n",
      "547 conv2d_146\n",
      "548 batch_normalization_146\n",
      "549 activation_146\n",
      "550 conv2d_147\n",
      "551 batch_normalization_147\n",
      "552 activation_147\n",
      "553 conv2d_145\n",
      "554 conv2d_148\n",
      "555 batch_normalization_145\n",
      "556 batch_normalization_148\n",
      "557 activation_145\n",
      "558 activation_148\n",
      "559 block17_18_mixed\n",
      "560 block17_18_conv\n",
      "561 block17_18\n",
      "562 block17_18_ac\n",
      "563 conv2d_150\n",
      "564 batch_normalization_150\n",
      "565 activation_150\n",
      "566 conv2d_151\n",
      "567 batch_normalization_151\n",
      "568 activation_151\n",
      "569 conv2d_149\n",
      "570 conv2d_152\n",
      "571 batch_normalization_149\n",
      "572 batch_normalization_152\n",
      "573 activation_149\n",
      "574 activation_152\n",
      "575 block17_19_mixed\n",
      "576 block17_19_conv\n",
      "577 block17_19\n",
      "578 block17_19_ac\n",
      "579 conv2d_154\n",
      "580 batch_normalization_154\n",
      "581 activation_154\n",
      "582 conv2d_155\n",
      "583 batch_normalization_155\n",
      "584 activation_155\n",
      "585 conv2d_153\n",
      "586 conv2d_156\n",
      "587 batch_normalization_153\n",
      "588 batch_normalization_156\n",
      "589 activation_153\n",
      "590 activation_156\n",
      "591 block17_20_mixed\n",
      "592 block17_20_conv\n",
      "593 block17_20\n",
      "594 block17_20_ac\n",
      "595 conv2d_161\n",
      "596 batch_normalization_161\n",
      "597 activation_161\n",
      "598 conv2d_157\n",
      "599 conv2d_159\n",
      "600 conv2d_162\n",
      "601 batch_normalization_157\n",
      "602 batch_normalization_159\n",
      "603 batch_normalization_162\n",
      "604 activation_157\n",
      "605 activation_159\n",
      "606 activation_162\n",
      "607 conv2d_158\n",
      "608 conv2d_160\n",
      "609 conv2d_163\n",
      "610 batch_normalization_158\n",
      "611 batch_normalization_160\n",
      "612 batch_normalization_163\n",
      "613 activation_158\n",
      "614 activation_160\n",
      "615 activation_163\n",
      "616 max_pooling2d_4\n",
      "617 mixed_7a\n",
      "618 conv2d_165\n",
      "619 batch_normalization_165\n",
      "620 activation_165\n",
      "621 conv2d_166\n",
      "622 batch_normalization_166\n",
      "623 activation_166\n",
      "624 conv2d_164\n",
      "625 conv2d_167\n",
      "626 batch_normalization_164\n",
      "627 batch_normalization_167\n",
      "628 activation_164\n",
      "629 activation_167\n",
      "630 block8_1_mixed\n",
      "631 block8_1_conv\n",
      "632 block8_1\n",
      "633 block8_1_ac\n",
      "634 conv2d_169\n",
      "635 batch_normalization_169\n",
      "636 activation_169\n",
      "637 conv2d_170\n",
      "638 batch_normalization_170\n",
      "639 activation_170\n",
      "640 conv2d_168\n",
      "641 conv2d_171\n",
      "642 batch_normalization_168\n",
      "643 batch_normalization_171\n",
      "644 activation_168\n",
      "645 activation_171\n",
      "646 block8_2_mixed\n",
      "647 block8_2_conv\n",
      "648 block8_2\n",
      "649 block8_2_ac\n",
      "650 conv2d_173\n",
      "651 batch_normalization_173\n",
      "652 activation_173\n",
      "653 conv2d_174\n",
      "654 batch_normalization_174\n",
      "655 activation_174\n",
      "656 conv2d_172\n",
      "657 conv2d_175\n",
      "658 batch_normalization_172\n",
      "659 batch_normalization_175\n",
      "660 activation_172\n",
      "661 activation_175\n",
      "662 block8_3_mixed\n",
      "663 block8_3_conv\n",
      "664 block8_3\n",
      "665 block8_3_ac\n",
      "666 conv2d_177\n",
      "667 batch_normalization_177\n",
      "668 activation_177\n",
      "669 conv2d_178\n",
      "670 batch_normalization_178\n",
      "671 activation_178\n",
      "672 conv2d_176\n",
      "673 conv2d_179\n",
      "674 batch_normalization_176\n",
      "675 batch_normalization_179\n",
      "676 activation_176\n",
      "677 activation_179\n",
      "678 block8_4_mixed\n",
      "679 block8_4_conv\n",
      "680 block8_4\n",
      "681 block8_4_ac\n",
      "682 conv2d_181\n",
      "683 batch_normalization_181\n",
      "684 activation_181\n",
      "685 conv2d_182\n",
      "686 batch_normalization_182\n",
      "687 activation_182\n",
      "688 conv2d_180\n",
      "689 conv2d_183\n",
      "690 batch_normalization_180\n",
      "691 batch_normalization_183\n",
      "692 activation_180\n",
      "693 activation_183\n",
      "694 block8_5_mixed\n",
      "695 block8_5_conv\n",
      "696 block8_5\n",
      "697 block8_5_ac\n",
      "698 conv2d_185\n",
      "699 batch_normalization_185\n",
      "700 activation_185\n",
      "701 conv2d_186\n",
      "702 batch_normalization_186\n",
      "703 activation_186\n",
      "704 conv2d_184\n",
      "705 conv2d_187\n",
      "706 batch_normalization_184\n",
      "707 batch_normalization_187\n",
      "708 activation_184\n",
      "709 activation_187\n",
      "710 block8_6_mixed\n",
      "711 block8_6_conv\n",
      "712 block8_6\n",
      "713 block8_6_ac\n",
      "714 conv2d_189\n",
      "715 batch_normalization_189\n",
      "716 activation_189\n",
      "717 conv2d_190\n",
      "718 batch_normalization_190\n",
      "719 activation_190\n",
      "720 conv2d_188\n",
      "721 conv2d_191\n",
      "722 batch_normalization_188\n",
      "723 batch_normalization_191\n",
      "724 activation_188\n",
      "725 activation_191\n",
      "726 block8_7_mixed\n",
      "727 block8_7_conv\n",
      "728 block8_7\n",
      "729 block8_7_ac\n",
      "730 conv2d_193\n",
      "731 batch_normalization_193\n",
      "732 activation_193\n",
      "733 conv2d_194\n",
      "734 batch_normalization_194\n",
      "735 activation_194\n",
      "736 conv2d_192\n",
      "737 conv2d_195\n",
      "738 batch_normalization_192\n",
      "739 batch_normalization_195\n",
      "740 activation_192\n",
      "741 activation_195\n",
      "742 block8_8_mixed\n",
      "743 block8_8_conv\n",
      "744 block8_8\n",
      "745 block8_8_ac\n",
      "746 conv2d_197\n",
      "747 batch_normalization_197\n",
      "748 activation_197\n",
      "749 conv2d_198\n",
      "750 batch_normalization_198\n",
      "751 activation_198\n",
      "752 conv2d_196\n",
      "753 conv2d_199\n",
      "754 batch_normalization_196\n",
      "755 batch_normalization_199\n",
      "756 activation_196\n",
      "757 activation_199\n",
      "758 block8_9_mixed\n",
      "759 block8_9_conv\n",
      "760 block8_9\n",
      "761 block8_9_ac\n",
      "762 conv2d_201\n",
      "763 batch_normalization_201\n",
      "764 activation_201\n",
      "765 conv2d_202\n",
      "766 batch_normalization_202\n",
      "767 activation_202\n",
      "768 conv2d_200\n",
      "769 conv2d_203\n",
      "770 batch_normalization_200\n",
      "771 batch_normalization_203\n",
      "772 activation_200\n",
      "773 activation_203\n",
      "774 block8_10_mixed\n",
      "775 block8_10_conv\n",
      "776 block8_10\n",
      "777 conv_7b\n",
      "778 conv_7b_bn\n",
      "779 conv_7b_ac\n",
      "780 avg_pool\n",
      "781 predictions\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 160, 160, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 79, 79, 32)   288         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 79, 79, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 79, 79, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 77, 77, 32)   9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 77, 77, 32)   96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 77, 77, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 77, 77, 64)   18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 77, 77, 64)   192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 77, 77, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 38, 38, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 38, 38, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 38, 38, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 38, 38, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 36, 36, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 36, 36, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 36, 36, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 17, 17, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 17, 17, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 17, 17, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 17, 17, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 17, 17, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 17, 17, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 17, 17, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 17, 17, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 17, 17, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 17, 17, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 17, 17, 96)   18432       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 17, 17, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 17, 17, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 17, 17, 64)   12288       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 17, 17, 96)   288         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 17, 17, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 17, 17, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 17, 17, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 17, 17, 96)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 17, 17, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 17, 17, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 17, 17, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 17, 17, 320)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 17, 17, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 17, 17, 32)   96          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 17, 17, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 17, 17, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 17, 17, 48)   13824       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 17, 17, 32)   96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 17, 17, 48)   144         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 17, 17, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 17, 17, 48)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 17, 17, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 17, 17, 32)   9216        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 17, 17, 64)   27648       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 17, 17, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 17, 17, 32)   96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 17, 17, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 17, 17, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 17, 17, 32)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 17, 17, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 17, 17, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 17, 17, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 17, 17, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 17, 17, 32)   96          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 17, 17, 32)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 17, 17, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 17, 17, 48)   13824       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 17, 17, 32)   96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 17, 17, 48)   144         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 17, 17, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 17, 17, 48)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 17, 17, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 17, 17, 32)   9216        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 17, 17, 64)   27648       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 17, 17, 32)   96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 17, 17, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 17, 17, 64)   192         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 17, 17, 32)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 17, 17, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 17, 17, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 17, 17, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 17, 17, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 17, 17, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 17, 17, 32)   96          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 17, 17, 32)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 48)   13824       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 32)   96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 48)   144         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 48)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 17, 17, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 17, 17, 32)   9216        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 64)   27648       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 17, 17, 32)   96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 17, 17, 32)   96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 64)   192         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 17, 17, 32)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 17, 17, 32)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_25[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 17, 17, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 17, 17, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 32)   96          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 32)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 48)   13824       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 32)   96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 48)   144         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 48)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_33 (Conv2D)              (None, 17, 17, 32)   9216        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 64)   27648       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 32)   96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 32)   96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 64)   192         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 32)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_31[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 17, 17, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 17, 17, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 32)   96          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 48)   13824       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 32)   96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 48)   144         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 48)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 32)   9216        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 64)   27648       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 32)   96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 32)   96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 64)   192         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 64)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_37[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 17, 17, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 17, 17, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 32)   96          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 32)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 48)   13824       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 32)   96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 48)   144         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 32)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 48)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 32)   9216        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 64)   27648       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 32)   96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 64)   192         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 32)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 64)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_43[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 17, 17, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 17, 17, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 32)   96          conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 32)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 48)   13824       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 32)   96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 48)   144         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 48)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 32)   9216        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 64)   27648       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 32)   96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 64)   192         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 32)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_49[0][0]              \n",
      "                                                                 activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 17, 17, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 17, 17, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 32)   96          conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 32)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 48)   13824       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 32)   96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 48)   144         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 32)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 48)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 32)   9216        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 64)   27648       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 32)   96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 32)   96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 64)   192         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 32)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 32)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 64)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_55[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 17, 17, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 17, 17, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 32)   96          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 32)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 48)   13824       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 32)   96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 48)   144         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 32)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 48)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 32)   9216        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 64)   27648       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 32)   96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 32)   96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 64)   192         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 32)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 32)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 64)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 17, 17, 128)  0           activation_61[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 17, 17, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 17, 17, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 17, 17, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 32)   96          conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 32)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 17, 17, 48)   13824       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 32)   96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 17, 17, 48)   144         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 48)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 32)   9216        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 64)   27648       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 32)   96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 32)   96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 64)   192         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 64)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 17, 17, 128)  0           activation_67[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 17, 17, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 17, 17, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 17, 17, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 256)  768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 256)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 256)  589824      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 17, 17, 256)  768         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 256)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 384)    1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 384)    884736      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 384)    1152        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 384)    1152        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 384)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 384)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 320)    0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 8, 8, 1088)   0           activation_73[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 128)    139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 128)    384         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 128)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 160)    143360      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 160)    480         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 160)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 192)    208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 192)    215040      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 192)    576         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 192)    576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 192)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 192)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_77[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 8, 8, 1088)   0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 8, 8, 1088)   0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 128)    139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 128)    384         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 128)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 160)    143360      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 160)    480         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 160)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 192)    208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    215040      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 192)    576         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 192)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_81[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 8, 8, 1088)   0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 8, 8, 1088)   0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 128)    139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 128)    384         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 128)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 160)    143360      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 160)    480         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 160)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 192)    208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 192)    215040      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 192)    576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 192)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_85[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 8, 8, 1088)   0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 8, 8, 1088)   0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 128)    139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 128)    384         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 128)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 160)    143360      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 160)    480         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 160)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 192)    208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 192)    215040      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 192)    576         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 192)    576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 192)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 192)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_89[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 8, 8, 1088)   0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 8, 8, 1088)   0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 128)    139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 128)    384         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 128)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 8, 160)    143360      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 8, 8, 160)    480         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 8, 8, 160)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 8, 8, 192)    215040      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 8, 8, 192)    576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 8, 8, 192)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_93[0][0]              \n",
      "                                                                 activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 8, 8, 1088)   0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 8, 8, 1088)   0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 8, 8, 128)    139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 8, 8, 128)    384         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 8, 8, 128)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 8, 8, 160)    143360      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 8, 8, 160)    480         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 8, 8, 160)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 8, 8, 192)    208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 8, 8, 192)    215040      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 8, 8, 192)    576         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 8, 8, 192)    576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 8, 8, 192)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 8, 8, 192)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_97[0][0]              \n",
      "                                                                 activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 8, 8, 1088)   0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 8, 8, 1088)   0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 8, 8, 128)    139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 8, 8, 128)    384         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 8, 8, 128)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 8, 8, 160)    143360      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 8, 8, 160)    480         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 8, 8, 160)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 8, 8, 192)    208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 8, 8, 192)    215040      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 8, 8, 192)    576         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 8, 8, 192)    576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 8, 8, 192)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 8, 8, 192)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 8, 8, 1088)   0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 8, 8, 1088)   0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 8, 8, 128)    139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 8, 8, 128)    384         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 8, 8, 128)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 8, 8, 160)    143360      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 8, 8, 160)    480         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 8, 8, 160)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 8, 8, 192)    208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 8, 8, 192)    215040      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 8, 8, 192)    576         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 8, 8, 192)    576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 8, 8, 192)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 8, 8, 192)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_105[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 8, 8, 1088)   0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 8, 8, 1088)   0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 8, 8, 128)    139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 8, 8, 128)    384         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 8, 8, 128)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 8, 8, 160)    143360      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 8, 8, 160)    480         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 8, 8, 160)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 8, 8, 192)    208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 8, 8, 192)    215040      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 8, 8, 192)    576         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 8, 8, 192)    576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 8, 8, 192)    0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 8, 8, 192)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 8, 8, 384)    0           activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 8, 8, 1088)   418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 8, 8, 1088)   0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 8, 8, 1088)   0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 8, 8, 128)    139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 8, 8, 128)    384         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 8, 8, 128)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 8, 8, 160)    143360      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 8, 8, 160)    480         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 8, 8, 160)    0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 8, 8, 192)    208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 8, 8, 192)    215040      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 8, 8, 192)    576         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 8, 8, 192)    576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 8, 8, 192)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 8, 8, 192)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_113[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 8, 8, 1088)   0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 8, 8, 1088)   0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 8, 8, 128)    139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 8, 8, 128)    384         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 8, 8, 128)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 8, 8, 160)    143360      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 8, 8, 160)    480         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 8, 8, 160)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 8, 8, 192)    208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 8, 8, 192)    215040      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 8, 8, 192)    576         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 8, 8, 192)    576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 8, 8, 192)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 8, 8, 192)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_117[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 8, 8, 1088)   0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 8, 8, 1088)   0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 8, 8, 128)    139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 8, 8, 128)    384         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 8, 8, 128)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 8, 8, 160)    143360      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 8, 8, 160)    480         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 8, 8, 160)    0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 8, 8, 192)    208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 8, 8, 192)    215040      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 8, 8, 192)    576         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 8, 8, 192)    576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 8, 8, 192)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 8, 8, 192)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 8, 8, 1088)   0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 8, 8, 1088)   0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 8, 8, 128)    139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 8, 8, 128)    384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 8, 8, 128)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 8, 8, 160)    143360      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 8, 8, 160)    480         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 8, 8, 160)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 8, 8, 192)    208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 8, 8, 192)    215040      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 8, 8, 192)    576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 8, 8, 192)    576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 8, 8, 192)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 8, 8, 192)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 8, 8, 1088)   0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 8, 8, 1088)   0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 8, 8, 128)    139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 8, 8, 128)    384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 8, 8, 128)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 8, 8, 160)    143360      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 8, 8, 160)    480         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 8, 8, 160)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 8, 8, 192)    208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 8, 8, 192)    215040      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 8, 8, 192)    576         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 8, 8, 192)    576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 8, 8, 192)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 8, 8, 192)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_129[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 8, 8, 1088)   0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 8, 8, 1088)   0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 8, 8, 128)    139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 8, 8, 128)    384         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 8, 8, 128)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 8, 8, 160)    143360      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 8, 8, 160)    480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 8, 8, 160)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 8, 8, 192)    208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 8, 8, 192)    215040      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 8, 8, 192)    576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 8, 8, 192)    576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 8, 8, 192)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 8, 8, 192)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_133[0][0]             \n",
      "                                                                 activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 8, 8, 1088)   0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 8, 8, 1088)   0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 8, 8, 128)    139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 8, 8, 128)    384         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 8, 8, 128)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 8, 8, 160)    143360      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 8, 8, 160)    480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 8, 8, 160)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 8, 8, 192)    208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 8, 8, 192)    215040      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 8, 8, 192)    576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 8, 8, 192)    576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 8, 8, 192)    0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 8, 8, 192)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_137[0][0]             \n",
      "                                                                 activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 8, 8, 1088)   0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 8, 8, 1088)   0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 8, 8, 128)    139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 8, 8, 128)    384         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 8, 8, 128)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 8, 8, 160)    143360      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 8, 8, 160)    480         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 8, 8, 160)    0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 8, 8, 192)    208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 8, 8, 192)    215040      activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 8, 8, 192)    576         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 8, 8, 192)    576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 8, 8, 192)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 8, 8, 192)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_141[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 8, 8, 1088)   0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 8, 8, 1088)   0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 8, 8, 128)    139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 8, 8, 128)    384         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 8, 8, 128)    0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 8, 8, 160)    143360      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 8, 8, 160)    480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 8, 8, 160)    0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 8, 8, 192)    208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 8, 8, 192)    215040      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 8, 8, 192)    576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 8, 8, 192)    576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 8, 8, 192)    0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 8, 8, 192)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 8, 8, 1088)   0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 8, 8, 1088)   0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 8, 8, 128)    139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 8, 8, 128)    384         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 8, 8, 128)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 8, 8, 160)    143360      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 8, 8, 160)    480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 8, 8, 160)    0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 8, 8, 192)    208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 8, 8, 192)    215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 8, 8, 192)    576         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 8, 8, 192)    576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 8, 8, 192)    0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 8, 8, 192)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_149[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 8, 8, 1088)   0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 8, 8, 1088)   0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 8, 8, 128)    139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 8, 8, 128)    384         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 8, 8, 128)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 8, 8, 160)    143360      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 8, 8, 160)    480         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 8, 8, 160)    0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 8, 8, 192)    208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 8, 8, 192)    215040      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 8, 8, 192)    576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 8, 8, 192)    576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 8, 8, 192)    0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 8, 8, 192)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 8, 8, 384)    0           activation_153[0][0]             \n",
      "                                                                 activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 8, 8, 1088)   418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 8, 8, 1088)   0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 8, 8, 1088)   0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 8, 8, 256)    278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 8, 8, 256)    768         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 8, 8, 256)    0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 8, 8, 256)    278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 8, 8, 256)    278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 8, 8, 288)    663552      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 8, 8, 256)    768         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 8, 8, 256)    768         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 8, 8, 288)    864         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 8, 8, 256)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 8, 8, 256)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 8, 8, 288)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 3, 3, 384)    884736      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 3, 3, 288)    663552      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 3, 3, 320)    829440      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 3, 3, 384)    1152        conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_160 (BatchN (None, 3, 3, 288)    864         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 3, 3, 320)    960         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 3, 3, 384)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 3, 3, 288)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 3, 3, 320)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 3, 3, 2080)   0           activation_158[0][0]             \n",
      "                                                                 activation_160[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 3, 3, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 3, 3, 192)    576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 3, 3, 192)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 3, 3, 224)    129024      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 3, 3, 224)    672         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 3, 3, 224)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 3, 3, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 3, 3, 256)    172032      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 3, 3, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 3, 3, 256)    768         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 3, 3, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 3, 3, 256)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_164[0][0]             \n",
      "                                                                 activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 3, 3, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 3, 3, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 3, 3, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 3, 3, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 3, 3, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 3, 3, 224)    129024      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 3, 3, 224)    672         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 3, 3, 224)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 3, 3, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 3, 3, 256)    172032      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 3, 3, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 3, 3, 256)    768         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 3, 3, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 3, 3, 256)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_168[0][0]             \n",
      "                                                                 activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 3, 3, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 3, 3, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 3, 3, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 3, 3, 192)    576         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 3, 3, 192)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 3, 3, 224)    129024      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 3, 3, 224)    672         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 3, 3, 224)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 3, 3, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 3, 3, 256)    172032      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 3, 3, 192)    576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 3, 3, 256)    768         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 3, 3, 192)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 3, 3, 256)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_172[0][0]             \n",
      "                                                                 activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 3, 3, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 3, 3, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 3, 3, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 3, 3, 192)    576         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 3, 3, 192)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 3, 3, 224)    129024      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 3, 3, 224)    672         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 3, 3, 224)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 3, 3, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 3, 3, 256)    172032      activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 3, 3, 192)    576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 3, 3, 256)    768         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 3, 3, 192)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 3, 3, 256)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_176[0][0]             \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 3, 3, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 3, 3, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 3, 3, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 3, 3, 192)    576         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 3, 3, 192)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 3, 3, 224)    129024      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 3, 3, 224)    672         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 3, 3, 224)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 3, 3, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 3, 3, 256)    172032      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 3, 3, 192)    576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 3, 3, 256)    768         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 3, 3, 192)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 3, 3, 256)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_180[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 3, 3, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 3, 3, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 3, 3, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 3, 3, 192)    576         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 3, 3, 192)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 3, 3, 224)    129024      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 3, 3, 224)    672         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 3, 3, 224)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 3, 3, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 3, 3, 256)    172032      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 3, 3, 192)    576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 3, 3, 256)    768         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 3, 3, 192)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 3, 3, 256)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_184[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 3, 3, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 3, 3, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 3, 3, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 3, 3, 192)    576         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 3, 3, 192)    0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 3, 3, 224)    129024      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 3, 3, 224)    672         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 3, 3, 224)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 3, 3, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 3, 3, 256)    172032      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 3, 3, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 3, 3, 256)    768         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 3, 3, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 3, 3, 256)    0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_188[0][0]             \n",
      "                                                                 activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 3, 3, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 3, 3, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 3, 3, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 3, 3, 192)    576         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 3, 3, 192)    0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 3, 3, 224)    129024      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 3, 3, 224)    672         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 3, 3, 224)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 3, 3, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 3, 3, 256)    172032      activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 3, 3, 192)    576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 3, 3, 256)    768         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 3, 3, 192)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 3, 3, 256)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_192[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 3, 3, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 3, 3, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 3, 3, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 3, 3, 192)    576         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 3, 3, 192)    0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 3, 3, 224)    129024      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 3, 3, 224)    672         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 3, 3, 224)    0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 3, 3, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 3, 3, 256)    172032      activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 3, 3, 192)    576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 3, 3, 256)    768         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 3, 3, 192)    0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 3, 3, 256)    0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_196[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 3, 3, 2080)   0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 3, 3, 2080)   0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 3, 3, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 3, 3, 192)    576         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 3, 3, 192)    0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 3, 3, 224)    129024      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 3, 3, 224)    672         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 3, 3, 224)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 3, 3, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 3, 3, 256)    172032      activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 3, 3, 192)    576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 3, 3, 256)    768         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 3, 3, 192)    0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 3, 3, 256)    0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 3, 3, 448)    0           activation_200[0][0]             \n",
      "                                                                 activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 3, 3, 2080)   933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 3, 3, 2080)   0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 3, 3, 1536)   3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 3, 3, 1536)   4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 3, 3, 1536)   0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1536)         0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         1537000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 55,873,160\n",
      "Trainable params: 55,812,616\n",
      "Non-trainable params: 60,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "clear_session()\n",
    "model = InceptionResNetV2(weights=None, input_shape=(160, 160, 1))\n",
    "for index, layer in enumerate(model.layers):\n",
    "    print(index, layer.name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv2d_1\n",
      "2 batch_normalization_1\n",
      "3 activation_1\n",
      "4 conv2d_2\n",
      "5 batch_normalization_2\n",
      "6 activation_2\n",
      "7 conv2d_3\n",
      "8 batch_normalization_3\n",
      "9 activation_3\n",
      "10 max_pooling2d_1\n",
      "11 conv2d_4\n",
      "12 batch_normalization_4\n",
      "13 activation_4\n",
      "14 conv2d_5\n",
      "15 batch_normalization_5\n",
      "16 activation_5\n",
      "17 max_pooling2d_2\n",
      "18 conv2d_9\n",
      "19 batch_normalization_9\n",
      "20 activation_9\n",
      "21 conv2d_7\n",
      "22 conv2d_10\n",
      "23 batch_normalization_7\n",
      "24 batch_normalization_10\n",
      "25 activation_7\n",
      "26 activation_10\n",
      "27 average_pooling2d_1\n",
      "28 conv2d_6\n",
      "29 conv2d_8\n",
      "30 conv2d_11\n",
      "31 conv2d_12\n",
      "32 batch_normalization_6\n",
      "33 batch_normalization_8\n",
      "34 batch_normalization_11\n",
      "35 batch_normalization_12\n",
      "36 activation_6\n",
      "37 activation_8\n",
      "38 activation_11\n",
      "39 activation_12\n",
      "40 mixed_5b\n",
      "41 conv2d_204\n",
      "42 batch_normalization_204\n",
      "43 p_re_lu_1\n",
      "44 conv2d_205\n",
      "45 batch_normalization_205\n",
      "46 p_re_lu_2\n",
      "47 max_pooling2d_5\n",
      "48 flatten_1\n",
      "49 dense_1\n",
      "50 batch_normalization_206\n",
      "51 p_re_lu_3\n",
      "52 dropout_1\n",
      "53 dense_2\n",
      "54 activation_204\n",
      "\n",
      "The architecture of the model:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 160, 160, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 79, 79, 32)   288         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 79, 79, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 79, 79, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 77, 77, 32)   9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 77, 77, 32)   96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 77, 77, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 77, 77, 64)   18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 77, 77, 64)   192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 77, 77, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 38, 38, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 38, 38, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 38, 38, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 38, 38, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 36, 36, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 36, 36, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 36, 36, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 17, 17, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 17, 17, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 17, 17, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 17, 17, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 17, 17, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 17, 17, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 17, 17, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 17, 17, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 17, 17, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 17, 17, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 17, 17, 96)   18432       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 17, 17, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 17, 17, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 17, 17, 64)   12288       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 17, 17, 96)   288         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 17, 17, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 17, 17, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 17, 17, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 17, 17, 96)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 17, 17, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 17, 17, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 17, 17, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 17, 17, 320)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 8, 8, 512)    655872      mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 8, 8, 512)    2048        conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 8, 8, 512)    32768       batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 4, 4, 512)    1049088     p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 4, 4, 512)    2048        conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 4, 4, 512)    8192        batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 2, 2, 512)    0           p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_3 (PReLU)               (None, 512)          512         batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           p_re_lu_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          51300       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 100)          0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,294,308\n",
      "Trainable params: 3,289,380\n",
      "Non-trainable params: 4,928\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "\n",
    "weights_path = None\n",
    "\n",
    "def build_model_based_on_inception_resnet_v2(fea_dims, out_dims, \n",
    "                                             base_weights=None, \n",
    "                                             input_shape=(299, 299, 3), \n",
    "                                             weights=None):\n",
    "    \n",
    "    base_inception_resnet_v2_model = InceptionResNetV2(weights=base_weights, \n",
    "                                                       include_top=False, \n",
    "                                                       input_shape=input_shape)\n",
    "    \n",
    "    # x = base_inception_resnet_v2_model.output\n",
    "    x = base_inception_resnet_v2_model.get_layer('mixed_5b').output \n",
    "    \n",
    "    x = Conv2D(512, (2, 2), strides=(2, 2), padding='valid')(x)\n",
    "    x = BN_PReLU(x)\n",
    "    x = Conv2D(512, (2, 2), strides=(2, 2), padding='valid')(x)\n",
    "    x = BN_PReLU(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(fea_dims)(x)\n",
    "    x = BN_PReLU(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(out_dims)(x)\n",
    "    x = Activation('softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_inception_resnet_v2_model.input, outputs=x)\n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "        \n",
    "    return model\n",
    "\n",
    "clear_session()\n",
    "channels = get_channel(COLOR_MODE)\n",
    "model = build_model_based_on_inception_resnet_v2(512, 100, \n",
    "                                                 base_weights=None, \n",
    "                                                 input_shape=(IMAGE_SIZE, IMAGE_SIZE, channels), \n",
    "                                                 weights=weights_path)\n",
    "for index, layer in enumerate(model.layers):\n",
    "    print(index, layer.name)\n",
    "    \n",
    "print('\\nThe architecture of the model:')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "283/283 [==============================] - 113s 398ms/step - loss: 4.7789 - acc: 0.0333 - val_loss: 4.3722 - val_acc: 0.0402\n",
      "Epoch 2/50\n",
      "283/283 [==============================] - 103s 362ms/step - loss: 3.3464 - acc: 0.2015 - val_loss: 3.9841 - val_acc: 0.1591\n",
      "Epoch 3/50\n",
      "283/283 [==============================] - 102s 361ms/step - loss: 2.4170 - acc: 0.3949 - val_loss: 2.2168 - val_acc: 0.4484\n",
      "Epoch 4/50\n",
      "283/283 [==============================] - 103s 363ms/step - loss: 1.9502 - acc: 0.5060 - val_loss: 1.7206 - val_acc: 0.5666\n",
      "Epoch 5/50\n",
      "283/283 [==============================] - 103s 363ms/step - loss: 1.6387 - acc: 0.5819 - val_loss: 1.4020 - val_acc: 0.6448\n",
      "Epoch 6/50\n",
      "283/283 [==============================] - 102s 361ms/step - loss: 1.4351 - acc: 0.6297 - val_loss: 1.3014 - val_acc: 0.6734\n",
      "Epoch 7/50\n",
      "283/283 [==============================] - 102s 361ms/step - loss: 1.2600 - acc: 0.6699 - val_loss: 1.1518 - val_acc: 0.7183\n",
      "Epoch 8/50\n",
      "283/283 [==============================] - 102s 362ms/step - loss: 1.1203 - acc: 0.7057 - val_loss: 1.0655 - val_acc: 0.7341\n",
      "Epoch 9/50\n",
      "283/283 [==============================] - 102s 361ms/step - loss: 1.0128 - acc: 0.7332 - val_loss: 0.9866 - val_acc: 0.7537\n",
      "Epoch 10/50\n",
      "283/283 [==============================] - 103s 363ms/step - loss: 0.9051 - acc: 0.7565 - val_loss: 0.9238 - val_acc: 0.7684\n",
      "Epoch 11/50\n",
      "283/283 [==============================] - 103s 362ms/step - loss: 0.8264 - acc: 0.7796 - val_loss: 0.9367 - val_acc: 0.7687\n",
      "Epoch 12/50\n",
      "283/283 [==============================] - 102s 361ms/step - loss: 0.7580 - acc: 0.7951 - val_loss: 0.9018 - val_acc: 0.7818\n",
      "Epoch 13/50\n",
      "283/283 [==============================] - 102s 362ms/step - loss: 0.6910 - acc: 0.8090 - val_loss: 0.8622 - val_acc: 0.7860\n",
      "Epoch 14/50\n",
      "283/283 [==============================] - 102s 362ms/step - loss: 0.6285 - acc: 0.8254 - val_loss: 0.8183 - val_acc: 0.7971\n",
      "Epoch 15/50\n",
      "283/283 [==============================] - 102s 362ms/step - loss: 0.5824 - acc: 0.8378 - val_loss: 0.8264 - val_acc: 0.7994\n",
      "Epoch 16/50\n",
      "283/283 [==============================] - 102s 362ms/step - loss: 0.5329 - acc: 0.8491 - val_loss: 0.8456 - val_acc: 0.7960\n",
      "Epoch 17/50\n",
      "283/283 [==============================] - 103s 363ms/step - loss: 0.4899 - acc: 0.8599 - val_loss: 0.7795 - val_acc: 0.8162\n",
      "Epoch 18/50\n",
      "283/283 [==============================] - 102s 362ms/step - loss: 0.4483 - acc: 0.8700 - val_loss: 0.7819 - val_acc: 0.8141\n",
      "Epoch 19/50\n",
      "283/283 [==============================] - 102s 362ms/step - loss: 0.4193 - acc: 0.8784 - val_loss: 0.7960 - val_acc: 0.8115\n",
      "Epoch 20/50\n",
      "247/283 [=========================>....] - ETA: 12s - loss: 0.3845 - acc: 0.8878"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-a901ea0b43c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m                       \u001b[0mweights_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                       \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                       decay=DECAY, epochs=EPOCHS)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-6b78d61421c6>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_generator, valid_generator, weights_path, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m                                   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                                   \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m                                   callbacks=callbacks)\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2224\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.1 # learning rate\n",
    "DECAY = 0.01 # learning rate decay\n",
    "EPOCHS = 50 # epochs\n",
    "\n",
    "\n",
    "# model = freeze_layers(model, index=776)\n",
    "weights_path = 'models/InceptionResNetV2/weights.hdf5'\n",
    "history = train_model(model, train_generator, valid_generator, \n",
    "                      weights_path, batch_size=BATCH_SIZE, \n",
    "                      learning_rate=LEARNING_RATE, \n",
    "                      decay=DECAY, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception\n",
    "Because of GPU performance limitations, I can only use a limited number of layers. In my tests, it turns out that fine-tune all layers achieve a better accuracy of validtion. I didn't use Dropout For it was not as effective (maybe BatchNormalization makes it less important?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 block1_conv1\n",
      "2 block1_conv1_bn\n",
      "3 block1_conv1_act\n",
      "4 block1_conv2\n",
      "5 block1_conv2_bn\n",
      "6 block1_conv2_act\n",
      "7 block2_sepconv1\n",
      "8 block2_sepconv1_bn\n",
      "9 block2_sepconv2_act\n",
      "10 block2_sepconv2\n",
      "11 block2_sepconv2_bn\n",
      "12 conv2d_1\n",
      "13 block2_pool\n",
      "14 batch_normalization_1\n",
      "15 add_1\n",
      "16 block3_sepconv1_act\n",
      "17 block3_sepconv1\n",
      "18 block3_sepconv1_bn\n",
      "19 block3_sepconv2_act\n",
      "20 block3_sepconv2\n",
      "21 block3_sepconv2_bn\n",
      "22 conv2d_2\n",
      "23 block3_pool\n",
      "24 batch_normalization_2\n",
      "25 add_2\n",
      "26 block4_sepconv1_act\n",
      "27 block4_sepconv1\n",
      "28 block4_sepconv1_bn\n",
      "29 block4_sepconv2_act\n",
      "30 block4_sepconv2\n",
      "31 block4_sepconv2_bn\n",
      "32 conv2d_3\n",
      "33 block4_pool\n",
      "34 batch_normalization_3\n",
      "35 add_3\n",
      "36 block5_sepconv1_act\n",
      "37 block5_sepconv1\n",
      "38 block5_sepconv1_bn\n",
      "39 block5_sepconv2_act\n",
      "40 block5_sepconv2\n",
      "41 block5_sepconv2_bn\n",
      "42 block5_sepconv3_act\n",
      "43 block5_sepconv3\n",
      "44 block5_sepconv3_bn\n",
      "45 add_4\n",
      "46 block6_sepconv1_act\n",
      "47 block6_sepconv1\n",
      "48 block6_sepconv1_bn\n",
      "49 block6_sepconv2_act\n",
      "50 block6_sepconv2\n",
      "51 block6_sepconv2_bn\n",
      "52 block6_sepconv3_act\n",
      "53 block6_sepconv3\n",
      "54 block6_sepconv3_bn\n",
      "55 add_5\n",
      "56 block7_sepconv1_act\n",
      "57 block7_sepconv1\n",
      "58 block7_sepconv1_bn\n",
      "59 block7_sepconv2_act\n",
      "60 block7_sepconv2\n",
      "61 block7_sepconv2_bn\n",
      "62 block7_sepconv3_act\n",
      "63 block7_sepconv3\n",
      "64 block7_sepconv3_bn\n",
      "65 add_6\n",
      "66 block8_sepconv1_act\n",
      "67 block8_sepconv1\n",
      "68 block8_sepconv1_bn\n",
      "69 block8_sepconv2_act\n",
      "70 block8_sepconv2\n",
      "71 block8_sepconv2_bn\n",
      "72 block8_sepconv3_act\n",
      "73 block8_sepconv3\n",
      "74 block8_sepconv3_bn\n",
      "75 add_7\n",
      "76 block9_sepconv1_act\n",
      "77 block9_sepconv1\n",
      "78 block9_sepconv1_bn\n",
      "79 block9_sepconv2_act\n",
      "80 block9_sepconv2\n",
      "81 block9_sepconv2_bn\n",
      "82 block9_sepconv3_act\n",
      "83 block9_sepconv3\n",
      "84 block9_sepconv3_bn\n",
      "85 add_8\n",
      "86 block10_sepconv1_act\n",
      "87 block10_sepconv1\n",
      "88 block10_sepconv1_bn\n",
      "89 block10_sepconv2_act\n",
      "90 block10_sepconv2\n",
      "91 block10_sepconv2_bn\n",
      "92 block10_sepconv3_act\n",
      "93 block10_sepconv3\n",
      "94 block10_sepconv3_bn\n",
      "95 add_9\n",
      "96 block11_sepconv1_act\n",
      "97 block11_sepconv1\n",
      "98 block11_sepconv1_bn\n",
      "99 block11_sepconv2_act\n",
      "100 block11_sepconv2\n",
      "101 block11_sepconv2_bn\n",
      "102 block11_sepconv3_act\n",
      "103 block11_sepconv3\n",
      "104 block11_sepconv3_bn\n",
      "105 add_10\n",
      "106 block12_sepconv1_act\n",
      "107 block12_sepconv1\n",
      "108 block12_sepconv1_bn\n",
      "109 block12_sepconv2_act\n",
      "110 block12_sepconv2\n",
      "111 block12_sepconv2_bn\n",
      "112 block12_sepconv3_act\n",
      "113 block12_sepconv3\n",
      "114 block12_sepconv3_bn\n",
      "115 add_11\n",
      "116 block13_sepconv1_act\n",
      "117 block13_sepconv1\n",
      "118 block13_sepconv1_bn\n",
      "119 block13_sepconv2_act\n",
      "120 block13_sepconv2\n",
      "121 block13_sepconv2_bn\n",
      "122 conv2d_4\n",
      "123 block13_pool\n",
      "124 batch_normalization_4\n",
      "125 add_12\n",
      "126 block14_sepconv1\n",
      "127 block14_sepconv1_bn\n",
      "128 block14_sepconv1_act\n",
      "129 block14_sepconv2\n",
      "130 block14_sepconv2_bn\n",
      "131 block14_sepconv2_act\n",
      "132 global_average_pooling2d_1\n",
      "133 dense_1\n",
      "134 prediction\n",
      "\n",
      "The architecture of the model:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 63, 63, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 63, 63, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 63, 63, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 61, 61, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 61, 61, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 61, 61, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 61, 61, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 61, 61, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 61, 61, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 31, 31, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 31, 31, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 31, 31, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 31, 31, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 31, 31, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 31, 31, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 31, 31, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 31, 31, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 16, 16, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 16, 16, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 16, 16, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 16, 16, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 728)    186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 728)    2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 4, 4, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          204900      global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Activation)         (None, 100)          0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,066,380\n",
      "Trainable params: 21,011,852\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "def build_model_based_on_xception(fea_dims, out_dims, \n",
    "                                  base_weights=None, \n",
    "                                  input_shape=(229, 229, 3), \n",
    "                                  weights=None):\n",
    "    \n",
    "    base_xception_model = Xception(weights=base_weights, \n",
    "                                   include_top=False, \n",
    "                                   input_shape=input_shape)\n",
    "    # x = base_xception_model.get_layer('block4_sepconv1_act').output\n",
    "    # x = base_xception_model.get_layer('block4_sepconv2_bn').output\n",
    "    # x = Conv2D(512, (2, 2), strides=(2, 2), padding='valid')(x)\n",
    "    # x = BN_PReLU(x)\n",
    "    # x = Conv2D(512, (2, 2), strides=(2, 2), padding='valid')(x)\n",
    "    # x = BN_PReLU(x)\n",
    "    x = base_xception_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # x = BN_PReLU(x)\n",
    "    # x = Dropout(0.6)(x)\n",
    "    x = Dense(out_dims)(x)\n",
    "    x = Activation('softmax', name='prediction')(x)\n",
    "    \n",
    "    model = Model(inputs=base_xception_model.input, outputs=x)\n",
    "    \n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "clear_session()\n",
    "\n",
    "channels = get_channels(COLOR_MODE)\n",
    "model = build_model_based_on_xception(1024, 100, \n",
    "                                      base_weights='imagenet', \n",
    "                                      input_shape=(IMAGE_SIZE, IMAGE_SIZE, channels), \n",
    "                                      weights=None)\n",
    "\n",
    "for index, layer in enumerate(model.layers):\n",
    "    print(index, layer.name)\n",
    "    \n",
    "print('\\nThe architecture of the model:')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/50\n",
      "283/283 [==============================] - 212s 749ms/step - loss: 4.6888 - acc: 0.0101 - val_loss: 5.0351 - val_acc: 0.0126\n",
      "Epoch 2/50\n",
      "283/283 [==============================] - 207s 730ms/step - loss: 4.3728 - acc: 0.0287 - val_loss: 4.0771 - val_acc: 0.0554\n",
      "Epoch 3/50\n",
      "283/283 [==============================] - 208s 735ms/step - loss: 2.6485 - acc: 0.3366 - val_loss: 3.1159 - val_acc: 0.2746\n",
      "Epoch 4/50\n",
      "283/283 [==============================] - 602s 2s/step - loss: 0.9294 - acc: 0.7587 - val_loss: 0.9779 - val_acc: 0.7409\n",
      "Epoch 5/50\n",
      "  2/283 [..............................] - ETA: 28:50 - loss: 0.5694 - acc: 0.8438"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.01 # learning rate\n",
    "DECAY = 0.01 # learning rate decay\n",
    "EPOCHS = 50 # epochs\n",
    "\n",
    "model = freeze_layers(model, index=25)\n",
    "model_path = 'models/Xception/model1.h5'\n",
    "history = train_model(model, train_generator, valid_generator, \n",
    "                      model_path, batch_size=BATCH_SIZE, \n",
    "                      learning_rate=LEARNING_RATE, \n",
    "                      decay=DECAY, epochs=EPOCHS)\n",
    "# 92 - 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 block1_conv1\n",
      "2 block1_conv1_bn\n",
      "3 block1_conv1_act\n",
      "4 block1_conv2\n",
      "5 block1_conv2_bn\n",
      "6 block1_conv2_act\n",
      "7 block2_sepconv1\n",
      "8 block2_sepconv1_bn\n",
      "9 block2_sepconv2_act\n",
      "10 block2_sepconv2\n",
      "11 block2_sepconv2_bn\n",
      "12 conv2d_1\n",
      "13 block2_pool\n",
      "14 batch_normalization_1\n",
      "15 add_1\n",
      "16 block3_sepconv1_act\n",
      "17 block3_sepconv1\n",
      "18 block3_sepconv1_bn\n",
      "19 block3_sepconv2_act\n",
      "20 block3_sepconv2\n",
      "21 block3_sepconv2_bn\n",
      "22 conv2d_2\n",
      "23 block3_pool\n",
      "24 batch_normalization_2\n",
      "25 add_2\n",
      "26 block4_sepconv1_act\n",
      "27 block4_sepconv1\n",
      "28 block4_sepconv1_bn\n",
      "29 block4_sepconv2_act\n",
      "30 block4_sepconv2\n",
      "31 block4_sepconv2_bn\n",
      "32 conv2d_3\n",
      "33 block4_pool\n",
      "34 batch_normalization_3\n",
      "35 add_3\n",
      "36 block5_sepconv1_act\n",
      "37 block5_sepconv1\n",
      "38 block5_sepconv1_bn\n",
      "39 block5_sepconv2_act\n",
      "40 block5_sepconv2\n",
      "41 block5_sepconv2_bn\n",
      "42 block5_sepconv3_act\n",
      "43 block5_sepconv3\n",
      "44 block5_sepconv3_bn\n",
      "45 add_4\n",
      "46 block6_sepconv1_act\n",
      "47 block6_sepconv1\n",
      "48 block6_sepconv1_bn\n",
      "49 block6_sepconv2_act\n",
      "50 block6_sepconv2\n",
      "51 block6_sepconv2_bn\n",
      "52 block6_sepconv3_act\n",
      "53 block6_sepconv3\n",
      "54 block6_sepconv3_bn\n",
      "55 add_5\n",
      "56 block7_sepconv1_act\n",
      "57 block7_sepconv1\n",
      "58 block7_sepconv1_bn\n",
      "59 block7_sepconv2_act\n",
      "60 block7_sepconv2\n",
      "61 block7_sepconv2_bn\n",
      "62 block7_sepconv3_act\n",
      "63 block7_sepconv3\n",
      "64 block7_sepconv3_bn\n",
      "65 add_6\n",
      "66 block8_sepconv1_act\n",
      "67 block8_sepconv1\n",
      "68 block8_sepconv1_bn\n",
      "69 block8_sepconv2_act\n",
      "70 block8_sepconv2\n",
      "71 block8_sepconv2_bn\n",
      "72 block8_sepconv3_act\n",
      "73 block8_sepconv3\n",
      "74 block8_sepconv3_bn\n",
      "75 add_7\n",
      "76 block9_sepconv1_act\n",
      "77 block9_sepconv1\n",
      "78 block9_sepconv1_bn\n",
      "79 block9_sepconv2_act\n",
      "80 block9_sepconv2\n",
      "81 block9_sepconv2_bn\n",
      "82 block9_sepconv3_act\n",
      "83 block9_sepconv3\n",
      "84 block9_sepconv3_bn\n",
      "85 add_8\n",
      "86 block10_sepconv1_act\n",
      "87 block10_sepconv1\n",
      "88 block10_sepconv1_bn\n",
      "89 block10_sepconv2_act\n",
      "90 block10_sepconv2\n",
      "91 block10_sepconv2_bn\n",
      "92 block10_sepconv3_act\n",
      "93 block10_sepconv3\n",
      "94 block10_sepconv3_bn\n",
      "95 add_9\n",
      "96 block11_sepconv1_act\n",
      "97 block11_sepconv1\n",
      "98 block11_sepconv1_bn\n",
      "99 block11_sepconv2_act\n",
      "100 block11_sepconv2\n",
      "101 block11_sepconv2_bn\n",
      "102 block11_sepconv3_act\n",
      "103 block11_sepconv3\n",
      "104 block11_sepconv3_bn\n",
      "105 add_10\n",
      "106 block12_sepconv1_act\n",
      "107 block12_sepconv1\n",
      "108 block12_sepconv1_bn\n",
      "109 block12_sepconv2_act\n",
      "110 block12_sepconv2\n",
      "111 block12_sepconv2_bn\n",
      "112 block12_sepconv3_act\n",
      "113 block12_sepconv3\n",
      "114 block12_sepconv3_bn\n",
      "115 add_11\n",
      "116 block13_sepconv1_act\n",
      "117 block13_sepconv1\n",
      "118 block13_sepconv1_bn\n",
      "119 block13_sepconv2_act\n",
      "120 block13_sepconv2\n",
      "121 block13_sepconv2_bn\n",
      "122 conv2d_4\n",
      "123 block13_pool\n",
      "124 batch_normalization_4\n",
      "125 add_12\n",
      "126 block14_sepconv1\n",
      "127 block14_sepconv1_bn\n",
      "128 block14_sepconv1_act\n",
      "129 block14_sepconv2\n",
      "130 block14_sepconv2_bn\n",
      "131 block14_sepconv2_act\n",
      "132 max_pooling2d_1\n",
      "133 flatten_1\n",
      "134 dense_1\n",
      "135 batch_normalization_5\n",
      "136 p_re_lu_1\n",
      "137 dropout_1\n",
      "138 dense_2\n",
      "139 prediction\n",
      "\n",
      "The architecture of the model:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 63, 63, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 63, 63, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 63, 63, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 61, 61, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 61, 61, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 61, 61, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 61, 61, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 61, 61, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 61, 61, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 31, 31, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 31, 31, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 31, 31, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 31, 31, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 31, 31, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 31, 31, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 31, 31, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 31, 31, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 16, 16, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 16, 16, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 16, 16, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 16, 16, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 728)    186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 728)    2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 4, 4, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 2, 2, 2048)   0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 8192)         0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         8389632     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1024)         4096        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 1024)         1024        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          102500      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Activation)         (None, 100)          0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 29,358,732\n",
      "Trainable params: 29,302,156\n",
      "Non-trainable params: 56,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import Xception\n",
    "\n",
    "weights_path = None\n",
    "\n",
    "def build_model_based_on_xception(fea_dims, out_dims, \n",
    "                                  base_weights=None, \n",
    "                                  input_shape=(229, 229, 3), \n",
    "                                  weights=None):\n",
    "    \n",
    "    base_xception_model = Xception(weights=base_weights, \n",
    "                                   include_top=False, \n",
    "                                   input_shape=input_shape)\n",
    "    x = base_xception_model.output\n",
    "    # x = base_xception_model.get_layer('block4_sepconv1_act').output\n",
    "    # x = base_xception_model.get_layer('block4_sepconv2_bn').output\n",
    "    # x = Conv2D(512, (2, 2), strides=(2, 2), padding='valid')(x)\n",
    "    # x = BN_PReLU(x)\n",
    "    # x = Conv2D(512, (2, 2), strides=(2, 2), padding='valid')(x)\n",
    "    # x = BN_PReLU(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(fea_dims)(x)\n",
    "    x = BN_PReLU(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(out_dims)(x)\n",
    "    x = Activation('softmax', name='prediction')(x)\n",
    "    \n",
    "    model = Model(inputs=base_xception_model.input, outputs=x)\n",
    "    \n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "clear_session()\n",
    "channels = get_channels(COLOR_MODE)\n",
    "model = build_model_based_on_xception(1024, 100, \n",
    "                                      base_weights='imagenet', \n",
    "                                      input_shape=(IMAGE_SIZE, IMAGE_SIZE, channels), \n",
    "                                      weights=weights_path)\n",
    "\n",
    "for index, layer in enumerate(model.layers):\n",
    "    print(index, layer.name)\n",
    "    \n",
    "print('\\nThe architecture of the model:')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01 # learning rate\n",
    "DECAY = 0.01 # learning rate decay\n",
    "EPOCHS = 50 # epochs\n",
    "\n",
    "model = freeze_layers(model, index=-1)\n",
    "weights_path = 'models/Xception/weights.hdf5'\n",
    "history = train_model(model, train_generator, valid_generator, \n",
    "                      weights_path, batch_size=BATCH_SIZE, \n",
    "                      learning_rate=LEARNING_RATE, \n",
    "                      decay=DECAY, epochs=EPOCHS)\n",
    "# 92 - 84\n",
    "#  (model, input_shape, batch_size, weights)\n",
    "# (model, (IMAGE_SIZE, IMAGE_SIZE), BATCH_SIZE, weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv2d_1\n",
      "2 batch_normalization_1\n",
      "3 activation_1\n",
      "4 conv2d_2\n",
      "5 batch_normalization_2\n",
      "6 activation_2\n",
      "7 max_pooling2d_1\n",
      "8 conv2d_3\n",
      "9 batch_normalization_3\n",
      "10 activation_3\n",
      "11 conv2d_4\n",
      "12 batch_normalization_4\n",
      "13 activation_4\n",
      "14 max_pooling2d_2\n",
      "15 conv2d_5\n",
      "16 batch_normalization_5\n",
      "17 activation_5\n",
      "18 conv2d_6\n",
      "19 batch_normalization_6\n",
      "20 activation_6\n",
      "21 max_pooling2d_3\n",
      "22 conv2d_7\n",
      "23 batch_normalization_7\n",
      "24 activation_7\n",
      "25 conv2d_8\n",
      "26 batch_normalization_8\n",
      "27 activation_8\n",
      "28 max_pooling2d_4\n",
      "29 conv2d_9\n",
      "30 batch_normalization_9\n",
      "31 activation_9\n",
      "32 conv2d_10\n",
      "33 batch_normalization_10\n",
      "34 activation_10\n",
      "35 max_pooling2d_5\n",
      "36 flatten_1\n",
      "37 batch_normalization_11\n",
      "38 p_re_lu_1\n",
      "39 dropout_1\n",
      "40 dense_1\n",
      "41 activation_11\n",
      "\n",
      " The architecture of the model:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 32)      4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 128)       32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 128)       65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 256)       131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 256)       262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 512)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 2,156,964\n",
      "Trainable params: 2,151,972\n",
      "Non-trainable params: 4,992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weights_path = None\n",
    "\n",
    "def build_my_model(out_dims, input_shape=(192, 192, 1), weights=None):\n",
    "    input_dims = Input(input_shape)\n",
    "    \n",
    "    x = Conv2D(32, (2, 2), strides=(1, 1), padding='same')(input_dims)\n",
    "    x = BN_ReLU(x)\n",
    "    x = Conv2D(32, (2, 2), strides=(1, 1), padding='same')(x)\n",
    "    x = BN_ReLU(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "    # 96 * 96 * 32\n",
    "    x = Conv2D(64, (2, 2), strides=(1, 1), padding='same')(x)\n",
    "    x = BN_ReLU(x)\n",
    "    x = Conv2D(64, (2, 2), strides=(1, 1), padding='same')(x)\n",
    "    x = BN_ReLU(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "    # 48 * 48 * 64\n",
    "    x = Conv2D(128, (2, 2), strides=(1, 1), padding='same')(x)\n",
    "    x = BN_ReLU(x)\n",
    "    x = Conv2D(128, (2, 2), strides=(1, 1), padding='same')(x)\n",
    "    x = BN_ReLU(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "    # 24 * 24 * 128\n",
    "    x = Conv2D(256, (2, 2), strides=(1, 1), padding='same')(x)\n",
    "    x = BN_ReLU(x)\n",
    "    x = Conv2D(256, (2, 2), strides=(1, 1), padding='same')(x)\n",
    "    x = BN_ReLU(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "    # 12 * 12 * 256\n",
    "    x = Conv2D(512, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BN_ReLU(x)\n",
    "    x = Conv2D(512, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BN_ReLU(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = BN_PReLU(x)\n",
    "    x = Dropout(0.8)(x)\n",
    "    \n",
    "    x = Dense(out_dims, kernel_regularizer=l2(0.01))(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_dims, outputs=x)\n",
    "    \n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "    \n",
    "    return model\n",
    "\n",
    "clear_session()\n",
    "model = build_my_model(100, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 1), weights=weights_path)\n",
    "for index, layer in enumerate(model.layers):\n",
    "    print(index, layer.name)\n",
    "\n",
    "print('\\n The architecture of the model:')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "283/283 [==============================] - 152s 537ms/step - loss: 4.4084 - acc: 0.1709 - val_loss: 5.8559 - val_acc: 0.0231\n",
      "Epoch 2/40\n",
      "283/283 [==============================] - 151s 533ms/step - loss: 2.5300 - acc: 0.5239 - val_loss: 2.4815 - val_acc: 0.5337\n",
      "Epoch 3/40\n",
      "283/283 [==============================] - 151s 533ms/step - loss: 1.9268 - acc: 0.6546 - val_loss: 1.7227 - val_acc: 0.7233\n",
      "Epoch 4/40\n",
      "283/283 [==============================] - 240s 848ms/step - loss: 1.5986 - acc: 0.7260 - val_loss: 1.4779 - val_acc: 0.7726\n",
      "Epoch 5/40\n",
      "283/283 [==============================] - 559s 2s/step - loss: 1.3882 - acc: 0.7689 - val_loss: 1.2837 - val_acc: 0.8044\n",
      "Epoch 6/40\n",
      "283/283 [==============================] - 559s 2s/step - loss: 1.2329 - acc: 0.8036 - val_loss: 1.2109 - val_acc: 0.8160\n",
      "Epoch 7/40\n",
      "283/283 [==============================] - 233s 822ms/step - loss: 1.1148 - acc: 0.8293 - val_loss: 1.0854 - val_acc: 0.8401\n",
      "Epoch 8/40\n",
      "283/283 [==============================] - 151s 535ms/step - loss: 1.0160 - acc: 0.8452 - val_loss: 1.1005 - val_acc: 0.8189\n",
      "Epoch 9/40\n",
      "283/283 [==============================] - 152s 536ms/step - loss: 0.9270 - acc: 0.8660 - val_loss: 0.9913 - val_acc: 0.8498\n",
      "Epoch 10/40\n",
      "283/283 [==============================] - 152s 536ms/step - loss: 0.8519 - acc: 0.8842 - val_loss: 0.9589 - val_acc: 0.8577\n",
      "Epoch 11/40\n",
      "283/283 [==============================] - 152s 537ms/step - loss: 0.7887 - acc: 0.8947 - val_loss: 0.9450 - val_acc: 0.8522\n",
      "Epoch 12/40\n",
      "283/283 [==============================] - 305s 1s/step - loss: 0.7348 - acc: 0.9066 - val_loss: 0.9314 - val_acc: 0.8548\n",
      "Epoch 13/40\n",
      "283/283 [==============================] - 189s 668ms/step - loss: 0.6827 - acc: 0.9192 - val_loss: 0.8840 - val_acc: 0.8656\n",
      "Epoch 14/40\n",
      "283/283 [==============================] - 152s 538ms/step - loss: 0.6336 - acc: 0.9293 - val_loss: 0.8595 - val_acc: 0.8693\n",
      "Epoch 15/40\n",
      "283/283 [==============================] - 151s 533ms/step - loss: 0.5930 - acc: 0.9388 - val_loss: 0.8273 - val_acc: 0.8708\n",
      "Epoch 16/40\n",
      "283/283 [==============================] - 151s 534ms/step - loss: 0.5572 - acc: 0.9457 - val_loss: 0.8225 - val_acc: 0.8698\n",
      "Epoch 17/40\n",
      "283/283 [==============================] - 151s 533ms/step - loss: 0.5301 - acc: 0.9527 - val_loss: 0.8214 - val_acc: 0.8645\n",
      "Epoch 18/40\n",
      "283/283 [==============================] - 151s 533ms/step - loss: 0.4995 - acc: 0.9578 - val_loss: 0.8097 - val_acc: 0.8708\n",
      "Epoch 19/40\n",
      "283/283 [==============================] - 151s 533ms/step - loss: 0.4711 - acc: 0.9637 - val_loss: 0.7965 - val_acc: 0.8700\n",
      "Epoch 20/40\n",
      "283/283 [==============================] - 332s 1s/step - loss: 0.4479 - acc: 0.9677 - val_loss: 0.7761 - val_acc: 0.8742\n",
      "Epoch 21/40\n",
      "283/283 [==============================] - 151s 533ms/step - loss: 0.4271 - acc: 0.9714 - val_loss: 0.7848 - val_acc: 0.8724\n",
      "Epoch 22/40\n",
      "283/283 [==============================] - 152s 538ms/step - loss: 0.4098 - acc: 0.9738 - val_loss: 0.7644 - val_acc: 0.8714\n",
      "Epoch 23/40\n",
      "283/283 [==============================] - 154s 543ms/step - loss: 0.3924 - acc: 0.9763 - val_loss: 0.7637 - val_acc: 0.8721\n",
      "Epoch 24/40\n",
      "283/283 [==============================] - 153s 541ms/step - loss: 0.3735 - acc: 0.9808 - val_loss: 0.7545 - val_acc: 0.8682\n",
      "Epoch 25/40\n",
      "283/283 [==============================] - 152s 536ms/step - loss: 0.3608 - acc: 0.9814 - val_loss: 0.7460 - val_acc: 0.8732\n",
      "Epoch 26/40\n",
      "283/283 [==============================] - 152s 537ms/step - loss: 0.3476 - acc: 0.9847 - val_loss: 0.7609 - val_acc: 0.8690\n",
      "Epoch 27/40\n",
      "283/283 [==============================] - 153s 541ms/step - loss: 0.3340 - acc: 0.9862 - val_loss: 0.7368 - val_acc: 0.8703\n",
      "Epoch 28/40\n",
      "283/283 [==============================] - 153s 540ms/step - loss: 0.3208 - acc: 0.9881 - val_loss: 0.7345 - val_acc: 0.8742\n",
      "Epoch 29/40\n",
      "283/283 [==============================] - 153s 539ms/step - loss: 0.3115 - acc: 0.9881 - val_loss: 0.7362 - val_acc: 0.8700\n",
      "Epoch 30/40\n",
      "283/283 [==============================] - 153s 541ms/step - loss: 0.3006 - acc: 0.9903 - val_loss: 0.7192 - val_acc: 0.8690\n",
      "Epoch 31/40\n",
      "283/283 [==============================] - 152s 539ms/step - loss: 0.2916 - acc: 0.9918 - val_loss: 0.7178 - val_acc: 0.8708\n",
      "Epoch 32/40\n",
      "283/283 [==============================] - 153s 539ms/step - loss: 0.2805 - acc: 0.9923 - val_loss: 0.7081 - val_acc: 0.8706\n",
      "Epoch 33/40\n",
      "283/283 [==============================] - 154s 544ms/step - loss: 0.2747 - acc: 0.9921 - val_loss: 0.7143 - val_acc: 0.8672\n",
      "Epoch 34/40\n",
      "283/283 [==============================] - 160s 564ms/step - loss: 0.2674 - acc: 0.9937 - val_loss: 0.7116 - val_acc: 0.8698\n",
      "Epoch 35/40\n",
      "283/283 [==============================] - 154s 544ms/step - loss: 0.2596 - acc: 0.9937 - val_loss: 0.7078 - val_acc: 0.8690\n",
      "Epoch 36/40\n",
      "283/283 [==============================] - 152s 536ms/step - loss: 0.2514 - acc: 0.9940 - val_loss: 0.6992 - val_acc: 0.8690\n",
      "Epoch 37/40\n",
      "283/283 [==============================] - 152s 537ms/step - loss: 0.2454 - acc: 0.9952 - val_loss: 0.6988 - val_acc: 0.8666\n",
      "Epoch 38/40\n",
      "283/283 [==============================] - 152s 536ms/step - loss: 0.2373 - acc: 0.9955 - val_loss: 0.6875 - val_acc: 0.8700\n",
      "Epoch 39/40\n",
      "283/283 [==============================] - 152s 536ms/step - loss: 0.2348 - acc: 0.9956 - val_loss: 0.6927 - val_acc: 0.8698\n",
      "Epoch 40/40\n",
      "282/283 [============================>.] - ETA: 0s - loss: 0.2278 - acc: 0.9960"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.01 # learning rate\n",
    "DECAY = 0.01 # learning rate decay\n",
    "EPOCHS = 40 # epochs\n",
    "\n",
    "weights_path = 'models/MyModel/weights.hdf5'\n",
    "\n",
    "history = train_model(model, train_generator, valid_generator, \n",
    "                      weights_path, batch_size=BATCH_SIZE, \n",
    "                      learning_rate=LEARNING_RATE, \n",
    "                      decay=DECAY, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def obtain_prediction(model, generator):\n",
    "    \"\"\" Obtain the model's prediction for the dataset\n",
    "    Inputs:\n",
    "      - model: The pre-trained model\n",
    "      - generator: \n",
    "      \n",
    "    Return:\n",
    "      - prediction: A numpy array, contains the prediction of the current \n",
    "              dataset by pre-trained model\n",
    "    \"\"\"\n",
    "    steps = len(generator)\n",
    "    prediction = model.predict_generator(generator, steps=steps, verbose=0)\n",
    "    return prediction\n",
    "    \n",
    "\n",
    "def obtain_topk_indices(generator, prediction, k=5):\n",
    "    \"\"\"Obtain the indices of top-k probability values \n",
    "    Inputs:\n",
    "      - generator: The data generator of the dataset\n",
    "      - prediction: The predictions of the dataset\n",
    "      - k: \n",
    "    \n",
    "    Return:\n",
    "      - topk_indices: The indices we need.\n",
    "    \"\"\"\n",
    "    samples = len(generator.classes)\n",
    "    if k > samples:\n",
    "        raise ValueError('k is greater than the number of samples.')\n",
    "    if k <= 0:\n",
    "        raise ValueError('k can\\'t less than 0!')\n",
    "    topk_indices = np.argsort(prediction, axis=1)[:, -k:]\n",
    "    return topk_indices\n",
    "\n",
    "\n",
    "def evaluate_topk_accuracy(generator, prediction=None, \n",
    "                           topk_indices=None, k=5):\n",
    "    \"\"\" Evaluate the top-k accuracy\n",
    "    Inputs:\n",
    "      - generator: The data generator of the dataset\n",
    "      - prediction: The predictions of the dataset\n",
    "      - topk_indices: \n",
    "      - k: \n",
    "      \n",
    "    \"\"\"\n",
    "    if topk_indices is None and prediction is None:\n",
    "        raise ValueError('prediction and topk_indices can\\'t both be \\'None\\'')\n",
    "    \n",
    "    if topk_indices is None:\n",
    "        topk_indices = obtain_topk_indices(generator, prediction, k=k)\n",
    "        \n",
    "    correct_number = 0\n",
    "    total_number = 0\n",
    "    for (indices, correct_class) in zip(topk_indices, generator.classes):\n",
    "        if correct_class in indices:\n",
    "            correct_number += 1\n",
    "        total_number += 1\n",
    "    print('Accuracy: {:.2%}'.format(correct_number / total_number))\n",
    "\n",
    "\n",
    "def obtain_filename_from_path(path):\n",
    "    filename = path[path.rfind('\\\\')+1:]\n",
    "    return filename\n",
    "    \n",
    "    \n",
    "def obtain_topk_classes(generator, class_indices, prediction=None, \n",
    "                        topk_indices=None, k=5):\n",
    "    \"\"\"Obtain the classes of top-k probability values \n",
    "    Inputs:\n",
    "      - generator: The data generator of the dataset\n",
    "      - class_indices:\n",
    "      - prediction: The predictions of the dataset\n",
    "      - topk_indices:\n",
    "      - k: \n",
    "    \n",
    "    Return:\n",
    "      - topk_classes: The classes we need.\n",
    "    \"\"\"\n",
    "    if topk_indices is None and prediction is None:\n",
    "        raise ValueError('prediction and topk_indices can\\'t both be \\'None\\'')\n",
    "    \n",
    "    if topk_indices is None:\n",
    "        topk_indices = obtain_topk_indices(generator, prediction, k=k)\n",
    "        \n",
    "    topk_classes = []\n",
    "    for indices in topk_indices:\n",
    "        classes = []\n",
    "        for index in indices:\n",
    "            classes.append(list(class_indices)[index])\n",
    "        topk_classes.append(classes)\n",
    "    return topk_classes\n",
    "\n",
    "\n",
    "def predictions_ensemble(generator, predictions, k=5):\n",
    "    \"\"\" use many models' predictions to compute the best answer.  \n",
    "    \"\"\"\n",
    "    all_topk_indices = []\n",
    "    for prediction in predictions:\n",
    "        all_topk_indices.append(obtain_topk_indices(generator, prediction, k=k))\n",
    "    \n",
    "    all_topk_indices = np.array(all_topk_indices)\n",
    "    topk_indices_ensemble = []\n",
    "    samples = len(generator.classes)\n",
    "    for index in range(samples):\n",
    "        (values, counts) = np.unique(all_topk_indices[:, index, :], \n",
    "                                     return_counts=True)\n",
    "        top_k = np.argsort(counts)[-k:]\n",
    "        topk_indices_ensemble.append(values[top_k])\n",
    "        \n",
    "    return topk_indices_ensemble\n",
    "        \n",
    "\n",
    "def models_ensemble(models_path, generator):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      - models_path:\n",
    "      - generator:\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for path in models_path:\n",
    "        model = load_model(path)\n",
    "        predictions.append(obtain_prediction(model, generator))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def write_into_csv(generator, class_indices, topk_indices=None, \n",
    "                   topk_classes=None, csv_path=None):\n",
    "    \"\"\"Write the answer into a csv file\n",
    "    Inputs:\n",
    "      - generator:\n",
    "      - class_indices:\n",
    "      - topk_indices:\n",
    "      - csv_path:\n",
    "    Return:\n",
    "      - data:\n",
    "    \"\"\"\n",
    "    if topk_indices is None and topk_classes is None:\n",
    "        raise ValueError('topk_indices and topk_classes can\\'t both be \\'None\\'')\n",
    "    data = []\n",
    "    data.append(['filename', 'label'])\n",
    "    if topk_indices is not None:\n",
    "        for path, indices in zip(generator.filenames, topk_indices):\n",
    "            classes = []\n",
    "            for index in indices:\n",
    "                classes.append(list(class_indices.keys())[index])\n",
    "            classes.reverse()\n",
    "            # classes = classes[::-1]\n",
    "            filename = obtain_filename_from_path(path)\n",
    "            data.append([filename, ''.join(classes)])\n",
    "    \n",
    "    elif topk_classes is not None:\n",
    "        for path, classes in zip(generator.filenames, topk_classes):\n",
    "            classes.reverse()\n",
    "            # classes = classes[::-1]\n",
    "            filename = obtain_filename_from_path(path)\n",
    "            data.append([filename, ''.join(classes)])\n",
    "    \n",
    "    if csv_path is not None:\n",
    "        with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerows(data)\n",
    "              \n",
    "    print('Done!')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3809 images belonging to 100 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = my_generator('dataset/validation', \n",
    "                         rescale=1./255, \n",
    "                         shuffle=False,\n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "                         color_mode=COLOR_MODE)\n",
    "models_path = []\n",
    "models_path.append('models/VGG16/model.h5')\n",
    "predictions = models_ensemble(models_path, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.37%\n"
     ]
    }
   ],
   "source": [
    "topk_indices = predictions_ensemble(generator, predictions, k=5)\n",
    "evaluate_topk_accuracy(generator, topk_indices=topk_indices, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = my_generator('dataset/test', \n",
    "                              rescale=1./255, \n",
    "                              shuffle=False,\n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "                              color_mode=COLOR_MODE)\n",
    "\n",
    "models_path = []\n",
    "models_path.append('models/VGG16/model1.h5')\n",
    "predictions = models_ensemble(models_path, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "topk_indices = predictions_ensemble(test_generator, predictions, k=5)\n",
    "answer = write_into_csv(test_generator, generator.class_indices, \n",
    "                        topk_indices=topk_indices, csv_path='results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
