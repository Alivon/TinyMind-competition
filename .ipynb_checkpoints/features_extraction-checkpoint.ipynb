{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "\n",
    "\n",
    "def search(directory, path_list, label_list, label=None):\n",
    "    \"\"\" obtains the path and label of all image files in the directory \n",
    "    \n",
    "    Inputs:\n",
    "      - directory: A folder.\n",
    "        the structure of the folder must be:\n",
    "        directory/\n",
    "            label1/\n",
    "                label1_001.jpg\n",
    "                label2_002.jpg\n",
    "                ...\n",
    "            label2/\n",
    "                label2_001.jpg\n",
    "                label2_002.jpg\n",
    "                ...\n",
    "            ...\n",
    "      - path_list: A list contains the path of all image files.\n",
    "      - label_list: A list contains the label of all image files.\n",
    "      - label: If label is None, represents only folders in the current directory.\n",
    "              Otherwise it represents the label of all files in the current directory\n",
    "    \n",
    "    \"\"\"\n",
    "    for file in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        if os.path.isdir(file_path):\n",
    "            search(file_path, path_list, label_list, label=file)\n",
    "        elif file[-4:] in {'.png', '.jpg'}:\n",
    "            path_list.append(file_path)\n",
    "            label_list.append(label)\n",
    "            \n",
    "            \n",
    "def get_paths_and_labels_from_directory(directory, returns='list'):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if returns not in {'array', 'list'}:\n",
    "        raise ValueError('The parameter of \\'returns\\' is wrong. \\\n",
    "        It must be \\'array\\' or \\'list\\'.')\n",
    "        \n",
    "    return_paths, return_labels = [], []\n",
    "    search(directory, return_paths, return_labels)\n",
    "    \n",
    "    if returns is 'array':\n",
    "        return_paths = np.array(return_paths)\n",
    "        return_labels = np.array(return_labels)\n",
    "    \n",
    "    return return_paths, return_labels\n",
    "\n",
    "\n",
    "def map_labels_to_integers(label_array):\n",
    "    \"\"\" \n",
    "    Input: \n",
    "      - label_array:\n",
    "    \n",
    "    Returns:\n",
    "      - unique_labels:\n",
    "      - integer_array:\n",
    "    \"\"\"\n",
    "    unique_labels, integer_array = np.unique(label_array, \n",
    "                                             return_inverse=True)\n",
    "    \n",
    "    return unique_labels, integer_array\n",
    "\n",
    "\n",
    "def read_images_from_paths(path_array, color_mode='RGB', image_size=224):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      - path_array\n",
    "      - color_mode:\n",
    "      - image_size:\n",
    "      \n",
    "    Return:\n",
    "      - image_array:\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start = time.time()\n",
    "    image_list = []\n",
    "    for index, path in enumerate(path_array):\n",
    "        if (index + 1) % 1000 is 0:\n",
    "            print('Now reading {}th image and this task has taken time {}s'.format(\n",
    "                index + 1, time.time() - start))\n",
    "        image_data = io.imread(path)\n",
    "        image_data = transform.resize(image_data, output_shape=(\n",
    "            image_size, image_size), mode='constant')\n",
    "        image_list.append(image_data)\n",
    "    \n",
    "    image_array = np.array(image_list)\n",
    "    if color_mode is 'gray':\n",
    "        image_array = np.expand_dims(image_array, axis=3)\n",
    "    print('Done! A total of {} images were processed and it took time {}s'.format(\n",
    "        image_array.shape[0], time.time() - start))\n",
    "    \n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_array, label_array = get_paths_and_labels_from_directory('train/', returns='array')\n",
    "print('The shape of path_array: {}'.format(path_array.shape))\n",
    "print('The shape pf label_array: {}'.format(label_array.shape))\n",
    "unique_label, integer_array = map_labels_to_integers(label_array)\n",
    "print('The unique labels:')\n",
    "print(unique_label)\n",
    "print('The integers corresponding to the labels:')\n",
    "print(integer_array)\n",
    "print('The unique integers:')\n",
    "print(np.unique(integer_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data set (train + validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_path, valid_path, train_label, valid_label = train_test_split(path_array, \n",
    "                                                                    integer_array, \n",
    "                                                                    test_size=0.1, \n",
    "                                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = read_images_from_paths(train_path, color_mode='gray', image_size=96), train_label\n",
    "\n",
    "print(\"The shape of X_train: {}\".format(X_train.shape))\n",
    "print(\"The shape of y_train: {}\".format(y_train.shape))\n",
    "print('The number of classes in the training set: {}'.format(np.unique(y_train).shape[0]))\n",
    "labels, counts = np.unique(y_train, return_counts=True)\n",
    "print('The unique labels in the training set: ')\n",
    "print(labels)\n",
    "print('The number of each label: ')\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, y_valid = read_images_from_paths(valid_path, color_mode='gray', image_size=96), valid_label\n",
    "print(\"The shape of X_valid: {}\".format(X_valid.shape))\n",
    "print(\"The shape of y_valid: {}\".format(y_valid.shape))\n",
    "print('The number of classes in the validation set: {}'.format(np.unique(y_valid).shape[0]))\n",
    "labels, counts = np.unique(y_valid, return_counts=True)\n",
    "print('The unique labels in the validation set: ')\n",
    "print(labels)\n",
    "print('The number of each label: ')\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path, _ = get_path_and_label('test/', returns='array')\n",
    "print(test_path.shape)\n",
    "X_test = get_image_from_path(test_path, color_mode='gray', image_size=96)\n",
    "print(\"The shape of X_test: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Flatten, Dense, BatchNormalization, Activation, Dropout\n",
    "from keras.models import Model\n",
    "def build_model_based_on_resnet50(fea_dims, out_dims):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      - fea_dims: \n",
    "      - out_dims:\n",
    "      \n",
    "    Return:\n",
    "       - model: \n",
    "    \"\"\"\n",
    "    resnet50_base_model = ResNet50(weights=None, include_top=False, input_shape=(96, 96, 1))\n",
    "    x = resnet50_base_model.get_layer('avg_pool').output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(fea_dims)(x)\n",
    "    x = BatchNormalzation()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(out_dims)(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    \n",
    "    model_input = resnet50_base_model.input\n",
    "    model_output = x \n",
    "    model = Model(inputs=model_input, outputs=model_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Flatten, Dense, BatchNormalization, Activation, Dropout\n",
    "from keras.models import Model\n",
    "def build_model_based_on_vgg16(fea_dims, out_dims):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      - fea_dims: \n",
    "      - out_dims:\n",
    "      \n",
    "    Return:\n",
    "       - model: \n",
    "    \"\"\"\n",
    "    vgg16_base_model = VGG16(weights=None, include_top=False, input_shape=(96, 96, 1))\n",
    "    x = vgg16_base_model.get_layer('block5_pool').output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(fea_dims)(x)\n",
    "    x = BatchNormalzation()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(out_dims)(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    \n",
    "    model_input = vgg16_base_model.input\n",
    "    model_output = x \n",
    "    model = Model(inputs=model_input, outputs=model_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ResNet50 architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet')\n",
    "for layer in  base_model.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features by ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(path_array, nn_model, image_size):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      - path_array:\n",
    "    Return:\n",
    "      - features\n",
    "    \"\"\"\n",
    "    import time\n",
    "\n",
    "    features = []\n",
    "    start = time.time()\n",
    "    for index, path in enumerate(path_array):\n",
    "        \n",
    "        if (index + 1) % 1000 is 0:\n",
    "            print('Now Extract the features of {}th image, It has taken time {}s'.format(\n",
    "                index + 1, time.time() - start))\n",
    "\n",
    "        image_data = image.load_img(path, target_size=(image_size, image_size))\n",
    "        image_data = image.img_to_array(image_data)\n",
    "        image_data = np.expand_dims(image_data, axis=0)\n",
    "        image_data = preprocess_input(image_data)\n",
    "        features.append(np.squeeze(nn_model.predict(image_data)))\n",
    "\n",
    "    features = np.array(features)\n",
    "    print('The shape of features: {}'.format(features.shape))\n",
    "    print('Done! A total of {} images were processed and it took time {}s'.format(\n",
    "        path_array.shape[0], time.time() - start))\n",
    "    \n",
    "    return features\n",
    "\n",
    "features = feature_extraction(train_path, model, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splits the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = features, integer_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, \n",
    "                                                      y, \n",
    "                                                      test_size=0.05, \n",
    "                                                      random_state=0)\n",
    "\n",
    "print(\"The shape of X_train: {}\".format(X_train.shape))\n",
    "print(\"The shape of y_train: {}\".format(y_train.shape))\n",
    "print('The number of classes in the training set: ', np.unique(y_train).shape[0])\n",
    "labels, counts = np.unique(y_train, return_counts=True)\n",
    "print('The unique labels in the training set: ')\n",
    "print(labels)\n",
    "print('The number of each label: ')\n",
    "print(counts)\n",
    "print()\n",
    "print(\"The shape of X_valid: {}\".format(X_valid.shape))\n",
    "print(\"The shape of y_valid: {}\".format(y_valid.shape))\n",
    "print('The number of classes in the test set: ', np.unique(y_valid).shape[0])\n",
    "labels, counts = np.unique(y_valid, return_counts=True)\n",
    "print('The unique labels in the training set: ')\n",
    "print(labels)\n",
    "print('The number of each label: ')\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open('train_features_resnet50_avg_pool.npy', 'wb'), X_train)\n",
    "np.save(open('train_labels_resnet50_avg_pool.npy', 'wb'), y_train)\n",
    "np.save(open('valid_features_resnet50_avg_pool.npy', 'wb'), X_valid)\n",
    "np.save(open('valid_labels_resnet50_avg_pool.npy', 'wb'), y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(open('train_features_resnet50_avg_pool.npy', 'rb'))\n",
    "y_train = np.load(open('train_labels_resnet50_avg_pool.npy', 'rb'))\n",
    "X_valid = np.load(open('valid_features_resnet50_avg_pool.npy', 'rb'))\n",
    "y_valid = np.load(open('valid_labels_resnet50_avg_pool.npy', 'rb'))\n",
    "print(\"The shape of X_train: {}\".format(X_train.shape))\n",
    "print(\"The shape of y_train: {}\".format(y_train.shape))\n",
    "print('The number of classes in the training set: ', np.unique(y_train).shape[0])\n",
    "labels, counts = np.unique(y_train, return_counts=True)\n",
    "print('The unique labels in the training set: ')\n",
    "print(labels)\n",
    "print('The number of each label: ')\n",
    "print(counts)\n",
    "print()\n",
    "print(\"The shape of X_valid: {}\".format(X_valid.shape))\n",
    "print(\"The shape of y_valid: {}\".format(y_valid.shape))\n",
    "print('The number of classes in the test set: ', np.unique(y_valid).shape[0])\n",
    "labels, counts = np.unique(y_valid, return_counts=True)\n",
    "print('The unique labels in the training set: ')\n",
    "print(labels)\n",
    "print('The number of each label: ')\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=100, input_dim=2048))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n",
    "\n",
    "history = model.fit(X_train, to_categorical(y_train, num_classes=100), epochs=40, \n",
    "          batch_size=64, validation_data=(X_valid, to_categorical(y_valid, num_classes=100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test top-5 accuracy of the valiation with our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_valid)\n",
    "top_five = np.argsort(prediction, axis=1)[:, -5:]\n",
    "correct_number = 0\n",
    "total_number = 0\n",
    "for (five, correct_class) in zip(top_five, y_valid):\n",
    "    if correct_class in five:\n",
    "        correct_number += 1\n",
    "    total_number += 1\n",
    "print('Validation accuracy: {:.2%}'.format(correct_number / total_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(open('test_features_resnet50_avg_pool.npy', 'rb'))\n",
    "print('The shape of X_test: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = []\n",
    "for path in test_path:\n",
    "    filename.append(path[path.rfind('\\\\')+1:])\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "top_five = np.argsort(prediction, axis=1)[:, -5:]\n",
    "answer = unique_label[top_five]\n",
    "\n",
    "import csv\n",
    "data = []\n",
    "data.append(['filename', 'label'])\n",
    "for name, label in zip(filename, answer):\n",
    "    label = list(label)\n",
    "    label.reverse()\n",
    "    # label = label[::-1]\n",
    "    data.append([name, ''.join(label)])\n",
    "with open('results.csv', 'w', newline='',encoding='utf-8-sig') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
