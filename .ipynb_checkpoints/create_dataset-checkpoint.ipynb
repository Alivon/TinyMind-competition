{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "\n",
    "\n",
    "def search(directory, path_list, label_list, label=None):\n",
    "    \"\"\" obtains the path and label of all image files in the directory \n",
    "    \n",
    "    Inputs:\n",
    "      - directory: A folder.\n",
    "        the structure of the folder must be:\n",
    "        directory/\n",
    "            label1/\n",
    "                label1_001.jpg\n",
    "                label2_002.jpg\n",
    "                ...\n",
    "            label2/\n",
    "                label2_001.jpg\n",
    "                label2_002.jpg\n",
    "                ...\n",
    "            ...\n",
    "      - path_list: A list contains the path of all image files.\n",
    "      - label_list: A list contains the label of all image files.\n",
    "      - label: If label is None, represents only folders in the current directory.\n",
    "              Otherwise it represents the label of all files in the current directory\n",
    "    \n",
    "    \"\"\"\n",
    "    for file in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        if os.path.isdir(file_path):\n",
    "            search(file_path, path_list, label_list, label=file)\n",
    "        elif file[-4:] in {'.png', '.jpg'}:\n",
    "            path_list.append(file_path)\n",
    "            label_list.append(label)\n",
    "            \n",
    "            \n",
    "def get_paths_and_labels_from_directory(directory, returns='list'):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if returns not in {'array', 'list'}:\n",
    "        raise ValueError('The parameter of \\'returns\\' is wrong. \\\n",
    "        It must be \\'array\\' or \\'list\\'.')\n",
    "        \n",
    "    return_paths, return_labels = [], []\n",
    "    search(directory, return_paths, return_labels)\n",
    "    \n",
    "    if returns is 'array':\n",
    "        return_paths = np.array(return_paths)\n",
    "        return_labels = np.array(return_labels)\n",
    "    \n",
    "    return return_paths, return_labels\n",
    "\n",
    "\n",
    "def map_labels_to_integers(label_array):\n",
    "    \"\"\" \n",
    "    Input: \n",
    "      - label_array:\n",
    "    \n",
    "    Returns:\n",
    "      - unique_labels:\n",
    "      - integer_array:\n",
    "    \"\"\"\n",
    "    unique_labels, integer_array = np.unique(label_array, \n",
    "                                             return_inverse=True)\n",
    "    \n",
    "    return unique_labels, integer_array\n",
    "\n",
    "\n",
    "def read_images_from_paths(path_array, color_mode='RGB', image_size=224):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "      - path_array\n",
    "      - color_mode:\n",
    "      - image_size:\n",
    "      \n",
    "    Return:\n",
    "      - image_array:\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start = time.time()\n",
    "    image_list = []\n",
    "    for index, path in enumerate(path_array):\n",
    "        if (index + 1) % 1000 is 0:\n",
    "            print('Now reading {}th image and this task has taken time {}s'.format(\n",
    "                index + 1, time.time() - start))\n",
    "        image_data = io.imread(path)\n",
    "        image_data = transform.resize(image_data, output_shape=(\n",
    "            image_size, image_size), mode='constant')\n",
    "        image_list.append(image_data)\n",
    "    \n",
    "    image_array = np.array(image_list)\n",
    "    if color_mode is 'gray':\n",
    "        image_array = np.expand_dims(image_array, axis=3)\n",
    "    print('Done! A total of {} images were processed and it took time {}s'.format(\n",
    "        image_array.shape[0], time.time() - start))\n",
    "    \n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of path_array: (40000,)\n",
      "The shape pf label_array: (40000,)\n",
      "The unique labels:\n",
      "['且' '世' '东' '九' '亭' '今' '从' '令' '作' '使' '侯' '元' '光' '利' '印' '去' '受' '右'\n",
      " '司' '合' '名' '周' '命' '和' '唯' '堂' '士' '多' '夜' '奉' '女' '好' '始' '字' '孝' '守'\n",
      " '宗' '官' '定' '宜' '室' '家' '寒' '左' '常' '建' '徐' '御' '必' '思' '意' '我' '敬' '新'\n",
      " '易' '春' '更' '朝' '李' '来' '林' '正' '武' '氏' '永' '流' '海' '深' '清' '游' '父' '物'\n",
      " '玉' '用' '申' '白' '皇' '益' '福' '秋' '立' '章' '老' '臣' '良' '莫' '虎' '衣' '西' '起'\n",
      " '足' '身' '通' '遂' '重' '陵' '雨' '高' '黄' '鼎']\n",
      "The integers corresponding to the labels:\n",
      "[ 0  0  0 ..., 99 99 99]\n",
      "The unique integers:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99]\n"
     ]
    }
   ],
   "source": [
    "path_array, label_array = get_paths_and_labels_from_directory('train/', returns='array')\n",
    "print('The shape of path_array: {}'.format(path_array.shape))\n",
    "print('The shape pf label_array: {}'.format(label_array.shape))\n",
    "unique_label, integer_array = map_labels_to_integers(label_array)\n",
    "print('The unique labels:')\n",
    "print(unique_label)\n",
    "print('The integers corresponding to the labels:')\n",
    "print(integer_array)\n",
    "print('The unique integers:')\n",
    "print(np.unique(integer_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the mapping relationship between labels and integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "mapping = []\n",
    "mapping.append(['integer', 'label'])\n",
    "for integer, label in enumerate(unique_label):\n",
    "    mapping.append([integer, label])\n",
    "\n",
    "with open('mapping.csv', 'w', newline='',encoding='utf-8-sig') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data set (train + validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_path, valid_path, train_label, valid_label = train_test_split(path_array, \n",
    "                                                                    integer_array, \n",
    "                                                                    test_size=0.1, \n",
    "                                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading 1000th image and this task has taken time 2.1620943546295166s\n",
      "Now reading 2000th image and this task has taken time 4.438292980194092s\n",
      "Now reading 3000th image and this task has taken time 6.694552898406982s\n",
      "Now reading 4000th image and this task has taken time 8.794950723648071s\n",
      "Now reading 5000th image and this task has taken time 10.731443166732788s\n",
      "Now reading 6000th image and this task has taken time 12.713847637176514s\n",
      "Now reading 7000th image and this task has taken time 14.763439416885376s\n",
      "Now reading 8000th image and this task has taken time 16.903366088867188s\n",
      "Now reading 9000th image and this task has taken time 19.138242483139038s\n",
      "Now reading 10000th image and this task has taken time 21.382657051086426s\n",
      "Now reading 11000th image and this task has taken time 23.934577226638794s\n",
      "Now reading 12000th image and this task has taken time 26.403843641281128s\n",
      "Now reading 13000th image and this task has taken time 28.908321619033813s\n",
      "Now reading 14000th image and this task has taken time 31.524216413497925s\n",
      "Now reading 15000th image and this task has taken time 34.24770998954773s\n",
      "Now reading 16000th image and this task has taken time 37.138503551483154s\n",
      "Now reading 17000th image and this task has taken time 39.93535566329956s\n",
      "Now reading 18000th image and this task has taken time 42.82567095756531s\n",
      "Now reading 19000th image and this task has taken time 45.888631105422974s\n",
      "Now reading 20000th image and this task has taken time 48.99792170524597s\n",
      "Now reading 21000th image and this task has taken time 52.16918635368347s\n",
      "Now reading 22000th image and this task has taken time 55.35654044151306s\n",
      "Now reading 23000th image and this task has taken time 58.60655331611633s\n",
      "Now reading 24000th image and this task has taken time 62.013131618499756s\n",
      "Now reading 25000th image and this task has taken time 65.45040488243103s\n",
      "Now reading 26000th image and this task has taken time 69.0599627494812s\n",
      "Now reading 27000th image and this task has taken time 72.7161192893982s\n",
      "Now reading 28000th image and this task has taken time 76.48333525657654s\n",
      "Now reading 29000th image and this task has taken time 80.35647511482239s\n",
      "Now reading 30000th image and this task has taken time 84.21615099906921s\n",
      "Now reading 31000th image and this task has taken time 88.05238366127014s\n",
      "Now reading 32000th image and this task has taken time 91.96492862701416s\n",
      "Now reading 33000th image and this task has taken time 96.13984036445618s\n",
      "Now reading 34000th image and this task has taken time 100.3260145187378s\n",
      "Now reading 35000th image and this task has taken time 104.56040835380554s\n",
      "Now reading 36000th image and this task has taken time 108.84090280532837s\n",
      "Done! A total of 36000 images were processed and it took time 109.77860116958618s\n",
      "The shape of X_train: (36000, 96, 96, 1)\n",
      "The shape of y_train: (36000,)\n",
      "The number of classes in the training set: 100\n",
      "The unique labels in the training set: \n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99]\n",
      "The number of each label: \n",
      "[360 363 363 367 356 350 352 357 359 371 351 359 356 358 359 369 357 356\n",
      " 354 362 345 359 365 373 370 353 350 368 354 367 370 366 357 366 364 351\n",
      " 357 370 356 355 358 367 361 367 352 361 361 370 354 357 363 369 368 351\n",
      " 359 361 359 363 345 361 363 362 360 354 367 358 358 358 353 354 355 357\n",
      " 358 357 352 367 359 359 362 366 353 356 363 372 372 357 366 355 358 365\n",
      " 369 354 360 358 359 359 367 356 352 368]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = read_images_from_paths(train_path, color_mode='gray', image_size=96), train_label\n",
    "\n",
    "print(\"The shape of X_train: {}\".format(X_train.shape))\n",
    "print(\"The shape of y_train: {}\".format(y_train.shape))\n",
    "print('The number of classes in the training set: {}'.format(np.unique(y_train).shape[0]))\n",
    "labels, counts = np.unique(y_train, return_counts=True)\n",
    "print('The unique labels in the training set: ')\n",
    "print(labels)\n",
    "print('The number of each label: ')\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading 1000th image and this task has taken time 1.8540523052215576s\n",
      "Now reading 2000th image and this task has taken time 15.200077772140503s\n",
      "Now reading 3000th image and this task has taken time 34.606528520584106s\n",
      "Now reading 4000th image and this task has taken time 54.18334126472473s\n",
      "Done! A total of 4000 images were processed and it took time 54.30836224555969s\n",
      "The shape of X_valid: (4000, 96, 96, 1)\n",
      "The shape of y_valid: (4000,)\n",
      "The number of classes in the validation set: 100\n",
      "The unique labels in the validation set: \n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n",
      " 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74\n",
      " 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99]\n",
      "The number of each label: \n",
      "[40 37 37 33 44 50 48 43 41 29 49 41 44 42 41 31 43 44 46 38 55 41 35 27 30\n",
      " 47 50 32 46 33 30 34 43 34 36 49 43 30 44 45 42 33 39 33 48 39 39 30 46 43\n",
      " 37 31 32 49 41 39 41 37 55 39 37 38 40 46 33 42 42 42 47 46 45 43 42 43 48\n",
      " 33 41 41 38 34 47 44 37 28 28 43 34 45 42 35 31 46 40 42 41 41 33 44 48 32]\n"
     ]
    }
   ],
   "source": [
    "X_valid, y_valid = read_images_from_paths(valid_path, color_mode='gray', image_size=96), valid_label\n",
    "print(\"The shape of X_valid: {}\".format(X_valid.shape))\n",
    "print(\"The shape of y_valid: {}\".format(y_valid.shape))\n",
    "print('The number of classes in the validation set: {}'.format(np.unique(y_valid).shape[0]))\n",
    "labels, counts = np.unique(y_valid, return_counts=True)\n",
    "print('The unique labels in the validation set: ')\n",
    "print(labels)\n",
    "print('The number of each label: ')\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of test_path: (10000,)\n",
      "Now reading 1000th image and this task has taken time 1.9395294189453125s\n",
      "Now reading 2000th image and this task has taken time 9.253499507904053s\n",
      "Now reading 3000th image and this task has taken time 18.471209287643433s\n",
      "Now reading 4000th image and this task has taken time 29.502728700637817s\n",
      "Now reading 5000th image and this task has taken time 42.98972177505493s\n",
      "Now reading 6000th image and this task has taken time 57.44044852256775s\n",
      "Now reading 7000th image and this task has taken time 74.39432168006897s\n",
      "Now reading 8000th image and this task has taken time 88.22165942192078s\n",
      "Now reading 9000th image and this task has taken time 99.29895043373108s\n",
      "Now reading 10000th image and this task has taken time 107.41473245620728s\n",
      "Done! A total of 10000 images were processed and it took time 107.68702101707458s\n",
      "The shape of X_test: (10000, 96, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "test_path, _ = get_paths_and_labels_from_directory('test/', returns='array')\n",
    "print('The shape of test_path: {}'.format(test_path.shape))\n",
    "X_test = read_images_from_paths(test_path, color_mode='gray', image_size=96)\n",
    "print(\"The shape of X_test: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open('train_data.npy', 'wb'), X_train)\n",
    "np.save(open('train_labels.npy', 'wb'), y_train)\n",
    "np.save(open('valid_data.npy', 'wb'), X_valid)\n",
    "np.save(open('valid_labels.npy', 'wb'), y_valid)\n",
    "np.save(open('test_data.npy', 'wb'), X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Flatten, Dense, BatchNormalization, Activation, Dropout\n",
    "from keras.models import Model\n",
    "def build_model_based_on_resnet50(fea_dims, out_dims):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      - fea_dims: \n",
    "      - out_dims:\n",
    "      \n",
    "    Return:\n",
    "       - model: \n",
    "    \"\"\"\n",
    "    resnet50_base_model = ResNet50(weights=None, include_top=False, input_shape=(224, 224, 1))\n",
    "    x = resnet50_base_model.get_layer('avg_pool').output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(fea_dims)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(out_dims)(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    \n",
    "    model_input = resnet50_base_model.input\n",
    "    model_output = x \n",
    "    model = Model(inputs=model_input, outputs=model_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Flatten, Dense, BatchNormalization, Activation, Dropout\n",
    "from keras.models import Model\n",
    "def build_model_based_on_vgg16(fea_dims, out_dims):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      - fea_dims: \n",
    "      - out_dims:\n",
    "      \n",
    "    Return:\n",
    "       - model: \n",
    "    \"\"\"\n",
    "    vgg16_base_model = VGG16(weights=None, include_top=False, input_shape=(96, 96, 1))\n",
    "    x = vgg16_base_model.get_layer('block5_pool').output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(fea_dims)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(out_dims)(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    \n",
    "    model_input = vgg16_base_model.input\n",
    "    model_output = x \n",
    "    model = Model(inputs=model_input, outputs=model_output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 * 3 * 512\n",
    "model = build_model_based_on_vgg16(1024, 100)\n",
    "from keras.optimizers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "for layer in model.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, to_categorical(y_train, num_classes=100), epochs=40, \n",
    "          batch_size=64, validation_data=(X_valid, to_categorical(y_valid, num_classes=100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test top-5 accuracy of the valiation with our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_valid)\n",
    "top_five = np.argsort(prediction, axis=1)[:, -5:]\n",
    "correct_number = 0\n",
    "total_number = 0\n",
    "for (five, correct_class) in zip(top_five, y_valid):\n",
    "    if correct_class in five:\n",
    "        correct_number += 1\n",
    "    total_number += 1\n",
    "print('Validation accuracy: {:.2%}'.format(correct_number / total_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(open('test_features_resnet50_avg_pool.npy', 'rb'))\n",
    "print('The shape of X_test: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = []\n",
    "for path in test_path:\n",
    "    filename.append(path[path.rfind('\\\\')+1:])\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "top_five = np.argsort(prediction, axis=1)[:, -5:]\n",
    "answer = unique_label[top_five]\n",
    "\n",
    "import csv\n",
    "data = []\n",
    "data.append(['filename', 'label'])\n",
    "for name, label in zip(filename, answer):\n",
    "    label = list(label)\n",
    "    label.reverse()\n",
    "    # label = label[::-1]\n",
    "    data.append([name, ''.join(label)])\n",
    "with open('results.csv', 'w', newline='',encoding='utf-8-sig') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
