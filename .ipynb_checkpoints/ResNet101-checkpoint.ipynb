{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from recognition import model_utils as mu\n",
    "from recognition import train_model as tm\n",
    "from recognition import evaluate_model as em\n",
    "from recognition import csv_utils as cu\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "BATCH_SIZE = 32 # batch size\n",
    "IMAGE_SIZE = 224 # image size\n",
    "COLOR_MODE = 'grayscale' # color mode \n",
    "RESCALE = 1./255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39987 images belonging to 100 classes.\n",
      "Found 3807 images belonging to 100 classes.\n",
      "Writing the class_indices into csv file.\n",
      "OK!\n"
     ]
    }
   ],
   "source": [
    "train_generator = mu.my_generator('train', \n",
    "                                  rescale=RESCALE,\n",
    "                                  horizontal_flip=False,\n",
    "                                  vertical_flip=False,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  zoom_range=0.1,\n",
    "                                  shuffle=True,\n",
    "                                  batch_size=BATCH_SIZE, \n",
    "                                  color_mode=COLOR_MODE, \n",
    "                                  target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "valid_generator = mu.my_generator('datasets/validation', \n",
    "                                  rescale=RESCALE,\n",
    "                                  shuffle=True,\n",
    "                                  batch_size=BATCH_SIZE, \n",
    "                                  color_mode=COLOR_MODE, \n",
    "                                  target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "print('Writing the class_indices into csv file.')\n",
    "cu.write_into_csv(train_generator.class_indices, csv_path='class_indices.csv')\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv1_zeropadding\n",
      "2 conv1\n",
      "3 bn_conv1\n",
      "4 scale_conv1\n",
      "5 conv1_relu\n",
      "6 pool1\n",
      "7 res2a_branch2a\n",
      "8 bn2a_branch2a\n",
      "9 scale2a_branch2a\n",
      "10 res2a_branch2a_relu\n",
      "11 res2a_branch2b_zeropadding\n",
      "12 res2a_branch2b\n",
      "13 bn2a_branch2b\n",
      "14 scale2a_branch2b\n",
      "15 res2a_branch2b_relu\n",
      "16 res2a_branch2c\n",
      "17 res2a_branch1\n",
      "18 bn2a_branch2c\n",
      "19 bn2a_branch1\n",
      "20 scale2a_branch2c\n",
      "21 scale2a_branch1\n",
      "22 add2a\n",
      "23 res2a_relu\n",
      "24 res2b_branch2a\n",
      "25 bn2b_branch2a\n",
      "26 scale2b_branch2a\n",
      "27 res2b_branch2a_relu\n",
      "28 res2b_branch2b_zeropadding\n",
      "29 res2b_branch2b\n",
      "30 bn2b_branch2b\n",
      "31 scale2b_branch2b\n",
      "32 res2b_branch2b_relu\n",
      "33 res2b_branch2c\n",
      "34 bn2b_branch2c\n",
      "35 scale2b_branch2c\n",
      "36 add2b\n",
      "37 res2b_relu\n",
      "38 res2c_branch2a\n",
      "39 bn2c_branch2a\n",
      "40 scale2c_branch2a\n",
      "41 res2c_branch2a_relu\n",
      "42 res2c_branch2b_zeropadding\n",
      "43 res2c_branch2b\n",
      "44 bn2c_branch2b\n",
      "45 scale2c_branch2b\n",
      "46 res2c_branch2b_relu\n",
      "47 res2c_branch2c\n",
      "48 bn2c_branch2c\n",
      "49 scale2c_branch2c\n",
      "50 add2c\n",
      "51 res2c_relu\n",
      "52 res3a_branch2a\n",
      "53 bn3a_branch2a\n",
      "54 scale3a_branch2a\n",
      "55 res3a_branch2a_relu\n",
      "56 res3a_branch2b_zeropadding\n",
      "57 res3a_branch2b\n",
      "58 bn3a_branch2b\n",
      "59 scale3a_branch2b\n",
      "60 res3a_branch2b_relu\n",
      "61 res3a_branch2c\n",
      "62 res3a_branch1\n",
      "63 bn3a_branch2c\n",
      "64 bn3a_branch1\n",
      "65 scale3a_branch2c\n",
      "66 scale3a_branch1\n",
      "67 add3a\n",
      "68 res3a_relu\n",
      "69 res3b1_branch2a\n",
      "70 bn3b1_branch2a\n",
      "71 scale3b1_branch2a\n",
      "72 res3b1_branch2a_relu\n",
      "73 res3b1_branch2b_zeropadding\n",
      "74 res3b1_branch2b\n",
      "75 bn3b1_branch2b\n",
      "76 scale3b1_branch2b\n",
      "77 res3b1_branch2b_relu\n",
      "78 res3b1_branch2c\n",
      "79 bn3b1_branch2c\n",
      "80 scale3b1_branch2c\n",
      "81 add3b1\n",
      "82 res3b1_relu\n",
      "83 res3b2_branch2a\n",
      "84 bn3b2_branch2a\n",
      "85 scale3b2_branch2a\n",
      "86 res3b2_branch2a_relu\n",
      "87 res3b2_branch2b_zeropadding\n",
      "88 res3b2_branch2b\n",
      "89 bn3b2_branch2b\n",
      "90 scale3b2_branch2b\n",
      "91 res3b2_branch2b_relu\n",
      "92 res3b2_branch2c\n",
      "93 bn3b2_branch2c\n",
      "94 scale3b2_branch2c\n",
      "95 add3b2\n",
      "96 res3b2_relu\n",
      "97 res3b3_branch2a\n",
      "98 bn3b3_branch2a\n",
      "99 scale3b3_branch2a\n",
      "100 res3b3_branch2a_relu\n",
      "101 res3b3_branch2b_zeropadding\n",
      "102 res3b3_branch2b\n",
      "103 bn3b3_branch2b\n",
      "104 scale3b3_branch2b\n",
      "105 res3b3_branch2b_relu\n",
      "106 res3b3_branch2c\n",
      "107 bn3b3_branch2c\n",
      "108 scale3b3_branch2c\n",
      "109 add3b3\n",
      "110 res3b3_relu\n",
      "111 res4a_branch2a\n",
      "112 bn4a_branch2a\n",
      "113 scale4a_branch2a\n",
      "114 res4a_branch2a_relu\n",
      "115 res4a_branch2b_zeropadding\n",
      "116 res4a_branch2b\n",
      "117 bn4a_branch2b\n",
      "118 scale4a_branch2b\n",
      "119 res4a_branch2b_relu\n",
      "120 res4a_branch2c\n",
      "121 res4a_branch1\n",
      "122 bn4a_branch2c\n",
      "123 bn4a_branch1\n",
      "124 scale4a_branch2c\n",
      "125 scale4a_branch1\n",
      "126 add4a\n",
      "127 res4a_relu\n",
      "128 res4b1_branch2a\n",
      "129 bn4b1_branch2a\n",
      "130 scale4b1_branch2a\n",
      "131 res4b1_branch2a_relu\n",
      "132 res4b1_branch2b_zeropadding\n",
      "133 res4b1_branch2b\n",
      "134 bn4b1_branch2b\n",
      "135 scale4b1_branch2b\n",
      "136 res4b1_branch2b_relu\n",
      "137 res4b1_branch2c\n",
      "138 bn4b1_branch2c\n",
      "139 scale4b1_branch2c\n",
      "140 add4b1\n",
      "141 res4b1_relu\n",
      "142 res4b2_branch2a\n",
      "143 bn4b2_branch2a\n",
      "144 scale4b2_branch2a\n",
      "145 res4b2_branch2a_relu\n",
      "146 res4b2_branch2b_zeropadding\n",
      "147 res4b2_branch2b\n",
      "148 bn4b2_branch2b\n",
      "149 scale4b2_branch2b\n",
      "150 res4b2_branch2b_relu\n",
      "151 res4b2_branch2c\n",
      "152 bn4b2_branch2c\n",
      "153 scale4b2_branch2c\n",
      "154 add4b2\n",
      "155 res4b2_relu\n",
      "156 res4b3_branch2a\n",
      "157 bn4b3_branch2a\n",
      "158 scale4b3_branch2a\n",
      "159 res4b3_branch2a_relu\n",
      "160 res4b3_branch2b_zeropadding\n",
      "161 res4b3_branch2b\n",
      "162 bn4b3_branch2b\n",
      "163 scale4b3_branch2b\n",
      "164 res4b3_branch2b_relu\n",
      "165 res4b3_branch2c\n",
      "166 bn4b3_branch2c\n",
      "167 scale4b3_branch2c\n",
      "168 add4b3\n",
      "169 res4b3_relu\n",
      "170 res4b4_branch2a\n",
      "171 bn4b4_branch2a\n",
      "172 scale4b4_branch2a\n",
      "173 res4b4_branch2a_relu\n",
      "174 res4b4_branch2b_zeropadding\n",
      "175 res4b4_branch2b\n",
      "176 bn4b4_branch2b\n",
      "177 scale4b4_branch2b\n",
      "178 res4b4_branch2b_relu\n",
      "179 res4b4_branch2c\n",
      "180 bn4b4_branch2c\n",
      "181 scale4b4_branch2c\n",
      "182 add4b4\n",
      "183 res4b4_relu\n",
      "184 res4b5_branch2a\n",
      "185 bn4b5_branch2a\n",
      "186 scale4b5_branch2a\n",
      "187 res4b5_branch2a_relu\n",
      "188 res4b5_branch2b_zeropadding\n",
      "189 res4b5_branch2b\n",
      "190 bn4b5_branch2b\n",
      "191 scale4b5_branch2b\n",
      "192 res4b5_branch2b_relu\n",
      "193 res4b5_branch2c\n",
      "194 bn4b5_branch2c\n",
      "195 scale4b5_branch2c\n",
      "196 add4b5\n",
      "197 res4b5_relu\n",
      "198 res4b6_branch2a\n",
      "199 bn4b6_branch2a\n",
      "200 scale4b6_branch2a\n",
      "201 res4b6_branch2a_relu\n",
      "202 res4b6_branch2b_zeropadding\n",
      "203 res4b6_branch2b\n",
      "204 bn4b6_branch2b\n",
      "205 scale4b6_branch2b\n",
      "206 res4b6_branch2b_relu\n",
      "207 res4b6_branch2c\n",
      "208 bn4b6_branch2c\n",
      "209 scale4b6_branch2c\n",
      "210 add4b6\n",
      "211 res4b6_relu\n",
      "212 res4b7_branch2a\n",
      "213 bn4b7_branch2a\n",
      "214 scale4b7_branch2a\n",
      "215 res4b7_branch2a_relu\n",
      "216 res4b7_branch2b_zeropadding\n",
      "217 res4b7_branch2b\n",
      "218 bn4b7_branch2b\n",
      "219 scale4b7_branch2b\n",
      "220 res4b7_branch2b_relu\n",
      "221 res4b7_branch2c\n",
      "222 bn4b7_branch2c\n",
      "223 scale4b7_branch2c\n",
      "224 add4b7\n",
      "225 res4b7_relu\n",
      "226 res4b8_branch2a\n",
      "227 bn4b8_branch2a\n",
      "228 scale4b8_branch2a\n",
      "229 res4b8_branch2a_relu\n",
      "230 res4b8_branch2b_zeropadding\n",
      "231 res4b8_branch2b\n",
      "232 bn4b8_branch2b\n",
      "233 scale4b8_branch2b\n",
      "234 res4b8_branch2b_relu\n",
      "235 res4b8_branch2c\n",
      "236 bn4b8_branch2c\n",
      "237 scale4b8_branch2c\n",
      "238 add4b8\n",
      "239 res4b8_relu\n",
      "240 res4b9_branch2a\n",
      "241 bn4b9_branch2a\n",
      "242 scale4b9_branch2a\n",
      "243 res4b9_branch2a_relu\n",
      "244 res4b9_branch2b_zeropadding\n",
      "245 res4b9_branch2b\n",
      "246 bn4b9_branch2b\n",
      "247 scale4b9_branch2b\n",
      "248 res4b9_branch2b_relu\n",
      "249 res4b9_branch2c\n",
      "250 bn4b9_branch2c\n",
      "251 scale4b9_branch2c\n",
      "252 add4b9\n",
      "253 res4b9_relu\n",
      "254 res4b10_branch2a\n",
      "255 bn4b10_branch2a\n",
      "256 scale4b10_branch2a\n",
      "257 res4b10_branch2a_relu\n",
      "258 res4b10_branch2b_zeropadding\n",
      "259 res4b10_branch2b\n",
      "260 bn4b10_branch2b\n",
      "261 scale4b10_branch2b\n",
      "262 res4b10_branch2b_relu\n",
      "263 res4b10_branch2c\n",
      "264 bn4b10_branch2c\n",
      "265 scale4b10_branch2c\n",
      "266 add4b10\n",
      "267 res4b10_relu\n",
      "268 res4b11_branch2a\n",
      "269 bn4b11_branch2a\n",
      "270 scale4b11_branch2a\n",
      "271 res4b11_branch2a_relu\n",
      "272 res4b11_branch2b_zeropadding\n",
      "273 res4b11_branch2b\n",
      "274 bn4b11_branch2b\n",
      "275 scale4b11_branch2b\n",
      "276 res4b11_branch2b_relu\n",
      "277 res4b11_branch2c\n",
      "278 bn4b11_branch2c\n",
      "279 scale4b11_branch2c\n",
      "280 add4b11\n",
      "281 res4b11_relu\n",
      "282 res4b12_branch2a\n",
      "283 bn4b12_branch2a\n",
      "284 scale4b12_branch2a\n",
      "285 res4b12_branch2a_relu\n",
      "286 res4b12_branch2b_zeropadding\n",
      "287 res4b12_branch2b\n",
      "288 bn4b12_branch2b\n",
      "289 scale4b12_branch2b\n",
      "290 res4b12_branch2b_relu\n",
      "291 res4b12_branch2c\n",
      "292 bn4b12_branch2c\n",
      "293 scale4b12_branch2c\n",
      "294 add4b12\n",
      "295 res4b12_relu\n",
      "296 res4b13_branch2a\n",
      "297 bn4b13_branch2a\n",
      "298 scale4b13_branch2a\n",
      "299 res4b13_branch2a_relu\n",
      "300 res4b13_branch2b_zeropadding\n",
      "301 res4b13_branch2b\n",
      "302 bn4b13_branch2b\n",
      "303 scale4b13_branch2b\n",
      "304 res4b13_branch2b_relu\n",
      "305 res4b13_branch2c\n",
      "306 bn4b13_branch2c\n",
      "307 scale4b13_branch2c\n",
      "308 add4b13\n",
      "309 res4b13_relu\n",
      "310 res4b14_branch2a\n",
      "311 bn4b14_branch2a\n",
      "312 scale4b14_branch2a\n",
      "313 res4b14_branch2a_relu\n",
      "314 res4b14_branch2b_zeropadding\n",
      "315 res4b14_branch2b\n",
      "316 bn4b14_branch2b\n",
      "317 scale4b14_branch2b\n",
      "318 res4b14_branch2b_relu\n",
      "319 res4b14_branch2c\n",
      "320 bn4b14_branch2c\n",
      "321 scale4b14_branch2c\n",
      "322 add4b14\n",
      "323 res4b14_relu\n",
      "324 res4b15_branch2a\n",
      "325 bn4b15_branch2a\n",
      "326 scale4b15_branch2a\n",
      "327 res4b15_branch2a_relu\n",
      "328 res4b15_branch2b_zeropadding\n",
      "329 res4b15_branch2b\n",
      "330 bn4b15_branch2b\n",
      "331 scale4b15_branch2b\n",
      "332 res4b15_branch2b_relu\n",
      "333 res4b15_branch2c\n",
      "334 bn4b15_branch2c\n",
      "335 scale4b15_branch2c\n",
      "336 add4b15\n",
      "337 res4b15_relu\n",
      "338 res4b16_branch2a\n",
      "339 bn4b16_branch2a\n",
      "340 scale4b16_branch2a\n",
      "341 res4b16_branch2a_relu\n",
      "342 res4b16_branch2b_zeropadding\n",
      "343 res4b16_branch2b\n",
      "344 bn4b16_branch2b\n",
      "345 scale4b16_branch2b\n",
      "346 res4b16_branch2b_relu\n",
      "347 res4b16_branch2c\n",
      "348 bn4b16_branch2c\n",
      "349 scale4b16_branch2c\n",
      "350 add4b16\n",
      "351 res4b16_relu\n",
      "352 res4b17_branch2a\n",
      "353 bn4b17_branch2a\n",
      "354 scale4b17_branch2a\n",
      "355 res4b17_branch2a_relu\n",
      "356 res4b17_branch2b_zeropadding\n",
      "357 res4b17_branch2b\n",
      "358 bn4b17_branch2b\n",
      "359 scale4b17_branch2b\n",
      "360 res4b17_branch2b_relu\n",
      "361 res4b17_branch2c\n",
      "362 bn4b17_branch2c\n",
      "363 scale4b17_branch2c\n",
      "364 add4b17\n",
      "365 res4b17_relu\n",
      "366 res4b18_branch2a\n",
      "367 bn4b18_branch2a\n",
      "368 scale4b18_branch2a\n",
      "369 res4b18_branch2a_relu\n",
      "370 res4b18_branch2b_zeropadding\n",
      "371 res4b18_branch2b\n",
      "372 bn4b18_branch2b\n",
      "373 scale4b18_branch2b\n",
      "374 res4b18_branch2b_relu\n",
      "375 res4b18_branch2c\n",
      "376 bn4b18_branch2c\n",
      "377 scale4b18_branch2c\n",
      "378 add4b18\n",
      "379 res4b18_relu\n",
      "380 res4b19_branch2a\n",
      "381 bn4b19_branch2a\n",
      "382 scale4b19_branch2a\n",
      "383 res4b19_branch2a_relu\n",
      "384 res4b19_branch2b_zeropadding\n",
      "385 res4b19_branch2b\n",
      "386 bn4b19_branch2b\n",
      "387 scale4b19_branch2b\n",
      "388 res4b19_branch2b_relu\n",
      "389 res4b19_branch2c\n",
      "390 bn4b19_branch2c\n",
      "391 scale4b19_branch2c\n",
      "392 add4b19\n",
      "393 res4b19_relu\n",
      "394 res4b20_branch2a\n",
      "395 bn4b20_branch2a\n",
      "396 scale4b20_branch2a\n",
      "397 res4b20_branch2a_relu\n",
      "398 res4b20_branch2b_zeropadding\n",
      "399 res4b20_branch2b\n",
      "400 bn4b20_branch2b\n",
      "401 scale4b20_branch2b\n",
      "402 res4b20_branch2b_relu\n",
      "403 res4b20_branch2c\n",
      "404 bn4b20_branch2c\n",
      "405 scale4b20_branch2c\n",
      "406 add4b20\n",
      "407 res4b20_relu\n",
      "408 res4b21_branch2a\n",
      "409 bn4b21_branch2a\n",
      "410 scale4b21_branch2a\n",
      "411 res4b21_branch2a_relu\n",
      "412 res4b21_branch2b_zeropadding\n",
      "413 res4b21_branch2b\n",
      "414 bn4b21_branch2b\n",
      "415 scale4b21_branch2b\n",
      "416 res4b21_branch2b_relu\n",
      "417 res4b21_branch2c\n",
      "418 bn4b21_branch2c\n",
      "419 scale4b21_branch2c\n",
      "420 add4b21\n",
      "421 res4b21_relu\n",
      "422 res4b22_branch2a\n",
      "423 bn4b22_branch2a\n",
      "424 scale4b22_branch2a\n",
      "425 res4b22_branch2a_relu\n",
      "426 res4b22_branch2b_zeropadding\n",
      "427 res4b22_branch2b\n",
      "428 bn4b22_branch2b\n",
      "429 scale4b22_branch2b\n",
      "430 res4b22_branch2b_relu\n",
      "431 res4b22_branch2c\n",
      "432 bn4b22_branch2c\n",
      "433 scale4b22_branch2c\n",
      "434 add4b22\n",
      "435 res4b22_relu\n",
      "436 res5a_branch2a\n",
      "437 bn5a_branch2a\n",
      "438 scale5a_branch2a\n",
      "439 res5a_branch2a_relu\n",
      "440 res5a_branch2b_zeropadding\n",
      "441 res5a_branch2b\n",
      "442 bn5a_branch2b\n",
      "443 scale5a_branch2b\n",
      "444 res5a_branch2b_relu\n",
      "445 res5a_branch2c\n",
      "446 res5a_branch1\n",
      "447 bn5a_branch2c\n",
      "448 bn5a_branch1\n",
      "449 scale5a_branch2c\n",
      "450 scale5a_branch1\n",
      "451 add5a\n",
      "452 res5a_relu\n",
      "453 res5b_branch2a\n",
      "454 bn5b_branch2a\n",
      "455 scale5b_branch2a\n",
      "456 res5b_branch2a_relu\n",
      "457 res5b_branch2b_zeropadding\n",
      "458 res5b_branch2b\n",
      "459 bn5b_branch2b\n",
      "460 scale5b_branch2b\n",
      "461 res5b_branch2b_relu\n",
      "462 res5b_branch2c\n",
      "463 bn5b_branch2c\n",
      "464 scale5b_branch2c\n",
      "465 add5b\n",
      "466 res5b_relu\n",
      "467 res5c_branch2a\n",
      "468 bn5c_branch2a\n",
      "469 scale5c_branch2a\n",
      "470 res5c_branch2a_relu\n",
      "471 res5c_branch2b_zeropadding\n",
      "472 res5c_branch2b\n",
      "473 bn5c_branch2b\n",
      "474 scale5c_branch2b\n",
      "475 res5c_branch2b_relu\n",
      "476 res5c_branch2c\n",
      "477 bn5c_branch2c\n",
      "478 scale5c_branch2c\n",
      "479 add5c\n",
      "480 res5c_relu\n",
      "481 avg_pool\n",
      "482 flatten_1\n",
      "483 batch_normalization_1\n",
      "484 p_re_lu_1\n",
      "485 dropout_1\n",
      "486 dense_1\n",
      "487 batch_normalization_2\n",
      "488 p_re_lu_2\n",
      "489 dropout_2\n",
      "490 dense_2\n",
      "491 activation_1\n",
      "\n",
      " The architecture of the model:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_zeropadding (ZeroPadding2 (None, 230, 230, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 3136        conv1_zeropadding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "scale_conv1 (Scale)             (None, 112, 112, 64) 128         bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           scale_conv1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 55, 55, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4096        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2a (Scale)        (None, 55, 55, 64)   128         bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a_relu (Activation (None, 55, 55, 64)   0           scale2a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_zeropadding (Zer (None, 57, 57, 64)   0           res2a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36864       res2a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2b (Scale)        (None, 55, 55, 64)   128         bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b_relu (Activation (None, 55, 55, 64)   0           scale2a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16384       res2a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16384       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch2c (Scale)        (None, 55, 55, 256)  512         bn2a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale2a_branch1 (Scale)         (None, 55, 55, 256)  512         bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add2a (Add)                     (None, 55, 55, 256)  0           scale2a_branch2c[0][0]           \n",
      "                                                                 scale2a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res2a_relu (Activation)         (None, 55, 55, 256)  0           add2a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16384       res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2a (Scale)        (None, 55, 55, 64)   128         bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a_relu (Activation (None, 55, 55, 64)   0           scale2b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_zeropadding (Zer (None, 57, 57, 64)   0           res2b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36864       res2b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2b (Scale)        (None, 55, 55, 64)   128         bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b_relu (Activation (None, 55, 55, 64)   0           scale2b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16384       res2b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2b_branch2c (Scale)        (None, 55, 55, 256)  512         bn2b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add2b (Add)                     (None, 55, 55, 256)  0           scale2b_branch2c[0][0]           \n",
      "                                                                 res2a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2b_relu (Activation)         (None, 55, 55, 256)  0           add2b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16384       res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2a (Scale)        (None, 55, 55, 64)   128         bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a_relu (Activation (None, 55, 55, 64)   0           scale2c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_zeropadding (Zer (None, 57, 57, 64)   0           res2c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36864       res2c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2b (Scale)        (None, 55, 55, 64)   128         bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b_relu (Activation (None, 55, 55, 64)   0           scale2c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16384       res2c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale2c_branch2c (Scale)        (None, 55, 55, 256)  512         bn2c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add2c (Add)                     (None, 55, 55, 256)  0           scale2c_branch2c[0][0]           \n",
      "                                                                 res2b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2c_relu (Activation)         (None, 55, 55, 256)  0           add2c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32768       res2c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2a (Scale)        (None, 28, 28, 128)  256         bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a_relu (Activation (None, 28, 28, 128)  0           scale3a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_zeropadding (Zer (None, 30, 30, 128)  0           res3a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147456      res3a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2b (Scale)        (None, 28, 28, 128)  256         bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b_relu (Activation (None, 28, 28, 128)  0           scale3a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  65536       res3a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131072      res2c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch2c (Scale)        (None, 28, 28, 512)  1024        bn3a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale3a_branch1 (Scale)         (None, 28, 28, 512)  1024        bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add3a (Add)                     (None, 28, 28, 512)  0           scale3a_branch2c[0][0]           \n",
      "                                                                 scale3a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3a_relu (Activation)         (None, 28, 28, 512)  0           add3a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b1_branch2a (Conv2D)        (None, 28, 28, 128)  65536       res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn3b1_branch2a (BatchNormalizat (None, 28, 28, 128)  512         res3b1_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b1_branch2a (Scale)       (None, 28, 28, 128)  256         bn3b1_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b1_branch2a_relu (Activatio (None, 28, 28, 128)  0           scale3b1_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b1_branch2b_zeropadding (Ze (None, 30, 30, 128)  0           res3b1_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b1_branch2b (Conv2D)        (None, 28, 28, 128)  147456      res3b1_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b1_branch2b (BatchNormalizat (None, 28, 28, 128)  512         res3b1_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b1_branch2b (Scale)       (None, 28, 28, 128)  256         bn3b1_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b1_branch2b_relu (Activatio (None, 28, 28, 128)  0           scale3b1_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b1_branch2c (Conv2D)        (None, 28, 28, 512)  65536       res3b1_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b1_branch2c (BatchNormalizat (None, 28, 28, 512)  2048        res3b1_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b1_branch2c (Scale)       (None, 28, 28, 512)  1024        bn3b1_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add3b1 (Add)                    (None, 28, 28, 512)  0           scale3b1_branch2c[0][0]          \n",
      "                                                                 res3a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res3b1_relu (Activation)        (None, 28, 28, 512)  0           add3b1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b2_branch2a (Conv2D)        (None, 28, 28, 128)  65536       res3b1_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn3b2_branch2a (BatchNormalizat (None, 28, 28, 128)  512         res3b2_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b2_branch2a (Scale)       (None, 28, 28, 128)  256         bn3b2_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b2_branch2a_relu (Activatio (None, 28, 28, 128)  0           scale3b2_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b2_branch2b_zeropadding (Ze (None, 30, 30, 128)  0           res3b2_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b2_branch2b (Conv2D)        (None, 28, 28, 128)  147456      res3b2_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b2_branch2b (BatchNormalizat (None, 28, 28, 128)  512         res3b2_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b2_branch2b (Scale)       (None, 28, 28, 128)  256         bn3b2_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b2_branch2b_relu (Activatio (None, 28, 28, 128)  0           scale3b2_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b2_branch2c (Conv2D)        (None, 28, 28, 512)  65536       res3b2_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b2_branch2c (BatchNormalizat (None, 28, 28, 512)  2048        res3b2_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b2_branch2c (Scale)       (None, 28, 28, 512)  1024        bn3b2_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add3b2 (Add)                    (None, 28, 28, 512)  0           scale3b2_branch2c[0][0]          \n",
      "                                                                 res3b1_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res3b2_relu (Activation)        (None, 28, 28, 512)  0           add3b2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b3_branch2a (Conv2D)        (None, 28, 28, 128)  65536       res3b2_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn3b3_branch2a (BatchNormalizat (None, 28, 28, 128)  512         res3b3_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b3_branch2a (Scale)       (None, 28, 28, 128)  256         bn3b3_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b3_branch2a_relu (Activatio (None, 28, 28, 128)  0           scale3b3_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b3_branch2b_zeropadding (Ze (None, 30, 30, 128)  0           res3b3_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res3b3_branch2b (Conv2D)        (None, 28, 28, 128)  147456      res3b3_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn3b3_branch2b (BatchNormalizat (None, 28, 28, 128)  512         res3b3_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b3_branch2b (Scale)       (None, 28, 28, 128)  256         bn3b3_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b3_branch2b_relu (Activatio (None, 28, 28, 128)  0           scale3b3_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res3b3_branch2c (Conv2D)        (None, 28, 28, 512)  65536       res3b3_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn3b3_branch2c (BatchNormalizat (None, 28, 28, 512)  2048        res3b3_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale3b3_branch2c (Scale)       (None, 28, 28, 512)  1024        bn3b3_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add3b3 (Add)                    (None, 28, 28, 512)  0           scale3b3_branch2c[0][0]          \n",
      "                                                                 res3b2_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res3b3_relu (Activation)        (None, 28, 28, 512)  0           add3b3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131072      res3b3_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2a (Scale)        (None, 14, 14, 256)  512         bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a_relu (Activation (None, 14, 14, 256)  0           scale4a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_zeropadding (Zer (None, 16, 16, 256)  0           res4a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  589824      res4a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2b (Scale)        (None, 14, 14, 256)  512         bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b_relu (Activation (None, 14, 14, 256)  0           scale4a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 262144      res4a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 524288      res3b3_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch2c (Scale)        (None, 14, 14, 1024) 2048        bn4a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale4a_branch1 (Scale)         (None, 14, 14, 1024) 2048        bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add4a (Add)                     (None, 14, 14, 1024) 0           scale4a_branch2c[0][0]           \n",
      "                                                                 scale4a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4a_relu (Activation)         (None, 14, 14, 1024) 0           add4a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b1_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn4b1_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b1_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b1_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b1_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b1_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b1_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b1_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b1_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b1_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b1_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b1_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b1_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b1_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b1_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b1_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b1_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b1_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b1_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b1_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b1_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b1_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b1_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add4b1 (Add)                    (None, 14, 14, 1024) 0           scale4b1_branch2c[0][0]          \n",
      "                                                                 res4a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res4b1_relu (Activation)        (None, 14, 14, 1024) 0           add4b1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b2_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b1_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b2_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b2_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b2_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b2_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b2_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b2_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b2_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b2_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b2_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b2_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b2_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b2_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b2_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b2_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b2_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b2_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b2_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b2_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b2_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b2_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b2_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b2_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add4b2 (Add)                    (None, 14, 14, 1024) 0           scale4b2_branch2c[0][0]          \n",
      "                                                                 res4b1_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b2_relu (Activation)        (None, 14, 14, 1024) 0           add4b2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b3_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b2_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b3_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b3_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b3_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b3_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b3_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b3_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b3_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b3_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b3_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b3_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b3_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b3_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b3_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b3_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b3_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b3_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b3_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b3_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b3_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b3_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b3_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b3_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add4b3 (Add)                    (None, 14, 14, 1024) 0           scale4b3_branch2c[0][0]          \n",
      "                                                                 res4b2_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b3_relu (Activation)        (None, 14, 14, 1024) 0           add4b3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b4_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b3_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b4_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b4_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b4_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b4_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b4_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b4_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b4_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b4_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b4_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b4_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b4_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b4_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b4_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b4_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b4_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b4_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b4_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b4_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b4_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b4_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b4_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b4_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add4b4 (Add)                    (None, 14, 14, 1024) 0           scale4b4_branch2c[0][0]          \n",
      "                                                                 res4b3_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b4_relu (Activation)        (None, 14, 14, 1024) 0           add4b4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b5_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b4_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b5_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b5_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b5_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b5_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b5_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b5_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b5_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b5_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b5_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b5_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b5_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b5_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b5_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b5_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b5_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b5_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b5_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b5_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b5_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b5_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b5_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b5_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add4b5 (Add)                    (None, 14, 14, 1024) 0           scale4b5_branch2c[0][0]          \n",
      "                                                                 res4b4_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b5_relu (Activation)        (None, 14, 14, 1024) 0           add4b5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b6_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b5_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b6_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b6_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b6_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b6_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b6_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b6_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b6_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b6_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b6_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b6_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b6_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b6_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b6_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b6_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b6_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b6_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b6_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b6_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b6_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b6_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b6_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b6_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add4b6 (Add)                    (None, 14, 14, 1024) 0           scale4b6_branch2c[0][0]          \n",
      "                                                                 res4b5_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b6_relu (Activation)        (None, 14, 14, 1024) 0           add4b6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b7_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b6_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b7_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b7_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b7_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b7_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b7_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b7_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b7_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b7_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b7_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b7_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b7_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b7_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b7_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b7_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b7_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b7_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b7_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b7_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b7_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b7_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b7_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b7_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add4b7 (Add)                    (None, 14, 14, 1024) 0           scale4b7_branch2c[0][0]          \n",
      "                                                                 res4b6_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b7_relu (Activation)        (None, 14, 14, 1024) 0           add4b7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b8_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b7_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b8_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b8_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b8_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b8_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b8_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b8_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b8_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b8_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b8_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b8_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b8_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b8_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b8_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b8_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b8_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b8_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b8_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b8_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b8_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b8_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b8_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b8_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add4b8 (Add)                    (None, 14, 14, 1024) 0           scale4b8_branch2c[0][0]          \n",
      "                                                                 res4b7_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b8_relu (Activation)        (None, 14, 14, 1024) 0           add4b8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b9_branch2a (Conv2D)        (None, 14, 14, 256)  262144      res4b8_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b9_branch2a (BatchNormalizat (None, 14, 14, 256)  1024        res4b9_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b9_branch2a (Scale)       (None, 14, 14, 256)  512         bn4b9_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b9_branch2a_relu (Activatio (None, 14, 14, 256)  0           scale4b9_branch2a[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b9_branch2b_zeropadding (Ze (None, 16, 16, 256)  0           res4b9_branch2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "res4b9_branch2b (Conv2D)        (None, 14, 14, 256)  589824      res4b9_branch2b_zeropadding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "bn4b9_branch2b (BatchNormalizat (None, 14, 14, 256)  1024        res4b9_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b9_branch2b (Scale)       (None, 14, 14, 256)  512         bn4b9_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b9_branch2b_relu (Activatio (None, 14, 14, 256)  0           scale4b9_branch2b[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "res4b9_branch2c (Conv2D)        (None, 14, 14, 1024) 262144      res4b9_branch2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn4b9_branch2c (BatchNormalizat (None, 14, 14, 1024) 4096        res4b9_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "scale4b9_branch2c (Scale)       (None, 14, 14, 1024) 2048        bn4b9_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add4b9 (Add)                    (None, 14, 14, 1024) 0           scale4b9_branch2c[0][0]          \n",
      "                                                                 res4b8_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b9_relu (Activation)        (None, 14, 14, 1024) 0           add4b9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b10_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b9_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bn4b10_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b10_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b10_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b10_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b10_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b10_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b10_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b10_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b10_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b10_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b10_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b10_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b10_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b10_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b10_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b10_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b10_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b10_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b10_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b10_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b10_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b10_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add4b10 (Add)                   (None, 14, 14, 1024) 0           scale4b10_branch2c[0][0]         \n",
      "                                                                 res4b9_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res4b10_relu (Activation)       (None, 14, 14, 1024) 0           add4b10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b11_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b10_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b11_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b11_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b11_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b11_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b11_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b11_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b11_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b11_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b11_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b11_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b11_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b11_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b11_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b11_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b11_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b11_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b11_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b11_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b11_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b11_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b11_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b11_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add4b11 (Add)                   (None, 14, 14, 1024) 0           scale4b11_branch2c[0][0]         \n",
      "                                                                 res4b10_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b11_relu (Activation)       (None, 14, 14, 1024) 0           add4b11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b12_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b11_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b12_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b12_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b12_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b12_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b12_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b12_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b12_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b12_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b12_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b12_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b12_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b12_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b12_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b12_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b12_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b12_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b12_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b12_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b12_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b12_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b12_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b12_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add4b12 (Add)                   (None, 14, 14, 1024) 0           scale4b12_branch2c[0][0]         \n",
      "                                                                 res4b11_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b12_relu (Activation)       (None, 14, 14, 1024) 0           add4b12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b13_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b12_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b13_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b13_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b13_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b13_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b13_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b13_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b13_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b13_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b13_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b13_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b13_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b13_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b13_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b13_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b13_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b13_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b13_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b13_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b13_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b13_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b13_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b13_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add4b13 (Add)                   (None, 14, 14, 1024) 0           scale4b13_branch2c[0][0]         \n",
      "                                                                 res4b12_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b13_relu (Activation)       (None, 14, 14, 1024) 0           add4b13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b14_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b13_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b14_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b14_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b14_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b14_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b14_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b14_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b14_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b14_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b14_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b14_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b14_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b14_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b14_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b14_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b14_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b14_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b14_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b14_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b14_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b14_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b14_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b14_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add4b14 (Add)                   (None, 14, 14, 1024) 0           scale4b14_branch2c[0][0]         \n",
      "                                                                 res4b13_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b14_relu (Activation)       (None, 14, 14, 1024) 0           add4b14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b15_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b14_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b15_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b15_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b15_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b15_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b15_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b15_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b15_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b15_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b15_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b15_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b15_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b15_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b15_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b15_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b15_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b15_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b15_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b15_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b15_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b15_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b15_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b15_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add4b15 (Add)                   (None, 14, 14, 1024) 0           scale4b15_branch2c[0][0]         \n",
      "                                                                 res4b14_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b15_relu (Activation)       (None, 14, 14, 1024) 0           add4b15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b16_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b15_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b16_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b16_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b16_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b16_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b16_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b16_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b16_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b16_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b16_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b16_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b16_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b16_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b16_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b16_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b16_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b16_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b16_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b16_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b16_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b16_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b16_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b16_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add4b16 (Add)                   (None, 14, 14, 1024) 0           scale4b16_branch2c[0][0]         \n",
      "                                                                 res4b15_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b16_relu (Activation)       (None, 14, 14, 1024) 0           add4b16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b17_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b16_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b17_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b17_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b17_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b17_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b17_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b17_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b17_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b17_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b17_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b17_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b17_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b17_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b17_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b17_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b17_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b17_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b17_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b17_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b17_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b17_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b17_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b17_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add4b17 (Add)                   (None, 14, 14, 1024) 0           scale4b17_branch2c[0][0]         \n",
      "                                                                 res4b16_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b17_relu (Activation)       (None, 14, 14, 1024) 0           add4b17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b18_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b17_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b18_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b18_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b18_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b18_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b18_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b18_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b18_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b18_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b18_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b18_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b18_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b18_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b18_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b18_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b18_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b18_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b18_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b18_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b18_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b18_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b18_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b18_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add4b18 (Add)                   (None, 14, 14, 1024) 0           scale4b18_branch2c[0][0]         \n",
      "                                                                 res4b17_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b18_relu (Activation)       (None, 14, 14, 1024) 0           add4b18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b19_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b18_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b19_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b19_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b19_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b19_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b19_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b19_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b19_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b19_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b19_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b19_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b19_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b19_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b19_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b19_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b19_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b19_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b19_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b19_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b19_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b19_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b19_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b19_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add4b19 (Add)                   (None, 14, 14, 1024) 0           scale4b19_branch2c[0][0]         \n",
      "                                                                 res4b18_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b19_relu (Activation)       (None, 14, 14, 1024) 0           add4b19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b20_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b19_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b20_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b20_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b20_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b20_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b20_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b20_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b20_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b20_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b20_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b20_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b20_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b20_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b20_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b20_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b20_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b20_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b20_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b20_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b20_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b20_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b20_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b20_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add4b20 (Add)                   (None, 14, 14, 1024) 0           scale4b20_branch2c[0][0]         \n",
      "                                                                 res4b19_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b20_relu (Activation)       (None, 14, 14, 1024) 0           add4b20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b21_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b20_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b21_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b21_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b21_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b21_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b21_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b21_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b21_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b21_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b21_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b21_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b21_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b21_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b21_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b21_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b21_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b21_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b21_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b21_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b21_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b21_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b21_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b21_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add4b21 (Add)                   (None, 14, 14, 1024) 0           scale4b21_branch2c[0][0]         \n",
      "                                                                 res4b20_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b21_relu (Activation)       (None, 14, 14, 1024) 0           add4b21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res4b22_branch2a (Conv2D)       (None, 14, 14, 256)  262144      res4b21_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn4b22_branch2a (BatchNormaliza (None, 14, 14, 256)  1024        res4b22_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b22_branch2a (Scale)      (None, 14, 14, 256)  512         bn4b22_branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b22_branch2a_relu (Activati (None, 14, 14, 256)  0           scale4b22_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b22_branch2b_zeropadding (Z (None, 16, 16, 256)  0           res4b22_branch2a_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "res4b22_branch2b (Conv2D)       (None, 14, 14, 256)  589824      res4b22_branch2b_zeropadding[0][0\n",
      "__________________________________________________________________________________________________\n",
      "bn4b22_branch2b (BatchNormaliza (None, 14, 14, 256)  1024        res4b22_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b22_branch2b (Scale)      (None, 14, 14, 256)  512         bn4b22_branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res4b22_branch2b_relu (Activati (None, 14, 14, 256)  0           scale4b22_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "res4b22_branch2c (Conv2D)       (None, 14, 14, 1024) 262144      res4b22_branch2b_relu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bn4b22_branch2c (BatchNormaliza (None, 14, 14, 1024) 4096        res4b22_branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "scale4b22_branch2c (Scale)      (None, 14, 14, 1024) 2048        bn4b22_branch2c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add4b22 (Add)                   (None, 14, 14, 1024) 0           scale4b22_branch2c[0][0]         \n",
      "                                                                 res4b21_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4b22_relu (Activation)       (None, 14, 14, 1024) 0           add4b22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524288      res4b22_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2a (Scale)        (None, 7, 7, 512)    1024        bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a_relu (Activation (None, 7, 7, 512)    0           scale5a_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_zeropadding (Zer (None, 9, 9, 512)    0           res5a_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359296     res5a_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2b (Scale)        (None, 7, 7, 512)    1024        bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b_relu (Activation (None, 7, 7, 512)    0           scale5a_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1048576     res5a_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2097152     res4b22_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch2c (Scale)        (None, 7, 7, 2048)   4096        bn5a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "scale5a_branch1 (Scale)         (None, 7, 7, 2048)   4096        bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add5a (Add)                     (None, 7, 7, 2048)   0           scale5a_branch2c[0][0]           \n",
      "                                                                 scale5a_branch1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res5a_relu (Activation)         (None, 7, 7, 2048)   0           add5a[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1048576     res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2a (Scale)        (None, 7, 7, 512)    1024        bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a_relu (Activation (None, 7, 7, 512)    0           scale5b_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_zeropadding (Zer (None, 9, 9, 512)    0           res5b_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359296     res5b_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2b (Scale)        (None, 7, 7, 512)    1024        bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b_relu (Activation (None, 7, 7, 512)    0           scale5b_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1048576     res5b_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "scale5b_branch2c (Scale)        (None, 7, 7, 2048)   4096        bn5b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add5b (Add)                     (None, 7, 7, 2048)   0           scale5b_branch2c[0][0]           \n",
      "                                                                 res5a_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5b_relu (Activation)         (None, 7, 7, 2048)   0           add5b[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1048576     res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2a (Scale)        (None, 7, 7, 512)    1024        bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a_relu (Activation (None, 7, 7, 512)    0           scale5c_branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_zeropadding (Zer (None, 9, 9, 512)    0           res5c_branch2a_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359296     res5c_branch2b_zeropadding[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2b (Scale)        (None, 7, 7, 512)    1024        bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b_relu (Activation (None, 7, 7, 512)    0           scale5c_branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1048576     res5c_branch2b_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "scale5c_branch2c (Scale)        (None, 7, 7, 2048)   4096        bn5c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add5c (Add)                     (None, 7, 7, 2048)   0           scale5c_branch2c[0][0]           \n",
      "                                                                 res5b_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res5c_relu (Activation)         (None, 7, 7, 2048)   0           add5c[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           res5c_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2048)         8192        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 2048)         2048        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          1049088     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 512)          512         batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          51300       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 100)          0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 43,817,764\n",
      "Trainable params: 43,707,300\n",
      "Non-trainable params: 110,464\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, PReLU, BatchNormalization, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, Activation, add\n",
    "from keras.models import Model\n",
    "from recognition.scale_layer import Scale\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    '''The identity_block is the block that has no conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(nb_filter1, (1, 1), name=conv_name_base + '2a', use_bias=False)(input_tensor)\n",
    "    x = BatchNormalization(epsilon=eps, axis=3, name=bn_name_base + '2a')(x)\n",
    "    x = Scale(axis=3, name=scale_name_base + '2a')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
    "    x = Conv2D(nb_filter2, (kernel_size, kernel_size),\n",
    "               name=conv_name_base + '2b', use_bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=3, name=bn_name_base + '2b')(x)\n",
    "    x = Scale(axis=3, name=scale_name_base + '2b')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
    "\n",
    "    x = Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c', use_bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=3, name=bn_name_base + '2c')(x)\n",
    "    x = Scale(axis=3, name=scale_name_base + '2c')(x)\n",
    "\n",
    "    x = add([x, input_tensor], name='add' + str(stage) + block)\n",
    "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    '''conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "    And the shortcut should have strides=(2,2) as well\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(nb_filter1, (1, 1), strides=strides,\n",
    "               name=conv_name_base + '2a', use_bias=False)(input_tensor)\n",
    "    x = BatchNormalization(epsilon=eps, axis=3, name=bn_name_base + '2a')(x)\n",
    "    x = Scale(axis=3, name=scale_name_base + '2a')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
    "    x = Conv2D(nb_filter2, (kernel_size, kernel_size),\n",
    "               name=conv_name_base + '2b', use_bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=3, name=bn_name_base + '2b')(x)\n",
    "    x = Scale(axis=3, name=scale_name_base + '2b')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
    "\n",
    "    x = Conv2D(nb_filter3, (1, 1), name=conv_name_base + '2c', use_bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=3, name=bn_name_base + '2c')(x)\n",
    "    x = Scale(axis=3, name=scale_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(nb_filter3, (1, 1), strides=strides,\n",
    "                      name=conv_name_base + '1', use_bias=False)(input_tensor)\n",
    "    shortcut = BatchNormalization(epsilon=eps, axis=3, name=bn_name_base + '1')(shortcut)\n",
    "    shortcut = Scale(axis=3, name=scale_name_base + '1')(shortcut)\n",
    "\n",
    "    x = add([x, shortcut], name='add' + str(stage) + block)\n",
    "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_model_based_on_resnet101(out_dims, base_weights=None, \n",
    "                                   input_shape=(224, 224, 3), weights=None):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      - out_dims:\n",
    "      \n",
    "    Return:\n",
    "       - model: \n",
    "    \"\"\"\n",
    "    eps = 1.1e-5\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(inputs)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', use_bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=3, name='bn_conv1')(x)\n",
    "    x = Scale(axis=3, name='scale_conv1')(x)\n",
    "    x = Activation('relu', name='conv1_relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    for i in range(1,4):\n",
    "        x = identity_block(x, 3, [128, 128, 512], stage=3, block='b'+str(i))\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    for i in range(1,23):\n",
    "        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b'+str(i))\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(512)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(out_dims, kernel_regularizer=l2(0.01))(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    \n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "mu.clear_session()\n",
    "\n",
    "channels = mu.get_channels(COLOR_MODE)\n",
    "if channels is 1:\n",
    "    base_weights = None\n",
    "else:\n",
    "    base_weights = 'imagenet'\n",
    "\n",
    "model = build_model_based_on_resnet101(100, \n",
    "                                       base_weights=base_weights, \n",
    "                                       input_shape=(IMAGE_SIZE, IMAGE_SIZE, channels), \n",
    "                                       weights=None)\n",
    "for index, layer in enumerate(model.layers):\n",
    "    print(index, layer.name)\n",
    "    \n",
    "print('\\n The architecture of the model:')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 43,817,764\n",
      "Trainable params: 43,707,300\n",
      "Non-trainable params: 110,464\n"
     ]
    }
   ],
   "source": [
    "model = mu.freeze_layers(model, index=-1)\n",
    "mu.count_parameters(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,512,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: bn3b3_branch2c/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=1.1e-05, is_training=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res3b3_branch2c/convolution, bn3b3_branch2c/gamma/read, bn3b3_branch2c/beta/read, bn5c_branch2a/Const_4, bn5c_branch2a/Const_4)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: dense_2/BiasAdd/_5575 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_15800_dense_2/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'bn3b3_branch2c/FusedBatchNorm', defined at:\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\asyncio\\base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-4ff638cd6318>\", line 152, in <module>\n    weights=None)\n  File \"<ipython-input-6-4ff638cd6318>\", line 111, in build_model_based_on_resnet101\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b'+str(i))\n  File \"<ipython-input-6-4ff638cd6318>\", line 35, in identity_block\n    x = BatchNormalization(epsilon=eps, axis=3, name=bn_name_base + '2c')(x)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\layers\\normalization.py\", line 181, in call\n    epsilon=self.epsilon)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1827, in normalize_batch_in_training\n    epsilon=epsilon)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1802, in _fused_normalize_batch_in_training\n    data_format=tf_data_format)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\", line 906, in fused_batch_norm\n    name=name)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 2569, in _fused_batch_norm\n    is_training=is_training, name=name)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,512,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: bn3b3_branch2c/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=1.1e-05, is_training=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res3b3_branch2c/convolution, bn3b3_branch2c/gamma/read, bn3b3_branch2c/beta/read, bn5c_branch2a/Const_4, bn5c_branch2a/Const_4)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: dense_2/BiasAdd/_5575 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_15800_dense_2/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,512,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: bn3b3_branch2c/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=1.1e-05, is_training=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res3b3_branch2c/convolution, bn3b3_branch2c/gamma/read, bn3b3_branch2c/beta/read, bn5c_branch2a/Const_4, bn5c_branch2a/Const_4)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: dense_2/BiasAdd/_5575 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_15800_dense_2/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ac6d2b7aa47b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m                          \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                          \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDECAY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                          epochs=EPOCHS)\n\u001b[0m",
      "\u001b[1;32mD:\\TMD\\recognition\\train_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_generator, valid_generator, model_path, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2224\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,512,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: bn3b3_branch2c/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=1.1e-05, is_training=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res3b3_branch2c/convolution, bn3b3_branch2c/gamma/read, bn3b3_branch2c/beta/read, bn5c_branch2a/Const_4, bn5c_branch2a/Const_4)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: dense_2/BiasAdd/_5575 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_15800_dense_2/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'bn3b3_branch2c/FusedBatchNorm', defined at:\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\asyncio\\base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-4ff638cd6318>\", line 152, in <module>\n    weights=None)\n  File \"<ipython-input-6-4ff638cd6318>\", line 111, in build_model_based_on_resnet101\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b'+str(i))\n  File \"<ipython-input-6-4ff638cd6318>\", line 35, in identity_block\n    x = BatchNormalization(epsilon=eps, axis=3, name=bn_name_base + '2c')(x)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\layers\\normalization.py\", line 181, in call\n    epsilon=self.epsilon)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1827, in normalize_batch_in_training\n    epsilon=epsilon)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1802, in _fused_normalize_batch_in_training\n    data_format=tf_data_format)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\", line 906, in fused_batch_norm\n    name=name)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 2569, in _fused_batch_norm\n    is_training=is_training, name=name)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"c:\\users\\-msi-\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,512,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: bn3b3_branch2c/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=1.1e-05, is_training=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](res3b3_branch2c/convolution, bn3b3_branch2c/gamma/read, bn3b3_branch2c/beta/read, bn5c_branch2a/Const_4, bn5c_branch2a/Const_4)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: dense_2/BiasAdd/_5575 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_15800_dense_2/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.000001\n",
    "DECAY = 0\n",
    "EPOCHS = 1\n",
    "\n",
    "model_path = 'models/ResNet101/model1.h5'\n",
    "history = tm.train_model(model, \n",
    "                         train_generator, \n",
    "                         valid_generator, \n",
    "                         model_path=model_path, \n",
    "                         print_lr=False,\n",
    "                         patience=1,\n",
    "                         reduce_factor=0.1,\n",
    "                         reduce_time=4,\n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         learning_rate=LEARNING_RATE, \n",
    "                         decay=DECAY, \n",
    "                         epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw history curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.draw_plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the performance of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mu.load_my_model('models/ResNet101/model6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the mapping from classes to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'且': 0, '世': 1, '东': 2, '九': 3, '亭': 4, '今': 5, '从': 6, '令': 7, '作': 8, '使': 9, '侯': 10, '元': 11, '光': 12, '利': 13, '印': 14, '去': 15, '受': 16, '右': 17, '司': 18, '合': 19, '名': 20, '周': 21, '命': 22, '和': 23, '唯': 24, '堂': 25, '士': 26, '多': 27, '夜': 28, '奉': 29, '女': 30, '好': 31, '始': 32, '字': 33, '孝': 34, '守': 35, '宗': 36, '官': 37, '定': 38, '宜': 39, '室': 40, '家': 41, '寒': 42, '左': 43, '常': 44, '建': 45, '徐': 46, '御': 47, '必': 48, '思': 49, '意': 50, '我': 51, '敬': 52, '新': 53, '易': 54, '春': 55, '更': 56, '朝': 57, '李': 58, '来': 59, '林': 60, '正': 61, '武': 62, '氏': 63, '永': 64, '流': 65, '海': 66, '深': 67, '清': 68, '游': 69, '父': 70, '物': 71, '玉': 72, '用': 73, '申': 74, '白': 75, '皇': 76, '益': 77, '福': 78, '秋': 79, '立': 80, '章': 81, '老': 82, '臣': 83, '良': 84, '莫': 85, '虎': 86, '衣': 87, '西': 88, '起': 89, '足': 90, '身': 91, '通': 92, '遂': 93, '重': 94, '陵': 95, '雨': 96, '高': 97, '黄': 98, '鼎': 99}\n"
     ]
    }
   ],
   "source": [
    "class_indices = cu.get_class_indices('class_indices.csv')\n",
    "print(class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the prediction for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39987 images belonging to 100 classes.\n",
      "OK!\n"
     ]
    }
   ],
   "source": [
    "generator = mu.my_generator('train',\n",
    "                             shuffle=False,\n",
    "                             rescale=RESCALE, \n",
    "                             batch_size=BATCH_SIZE, \n",
    "                             target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "                             color_mode=COLOR_MODE)\n",
    "\n",
    "prediction = em.get_prediction_by_single_generator(model, generator)\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy: 99.98%\n",
      "Top-5 accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "output = {}\n",
    "for k in [1, 5]:\n",
    "    output[str(k)] = em.evaluate_topk_accuracy_by_single_generator(generator, \n",
    "                                                                   class_indices,\n",
    "                                                                   prediction=prediction, \n",
    "                                                                   k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the wrong information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': '266395ecf0678b40123f7377052e55addb3e84dc.jpg', 'correct': '九', 'predict': ['左']}\n",
      "{'filename': '0d0e248cfb4a8d9ae27823824bb0348eb43ee5a1.jpg', 'correct': '今', 'predict': ['令']}\n",
      "{'filename': '7d25676d4311181020d79b4ae265f4a9075c163c.jpg', 'correct': '从', 'predict': ['御']}\n",
      "{'filename': '35152bede168b1569c678e649df1ba16dcab22d6.jpg', 'correct': '使', 'predict': ['李']}\n",
      "{'filename': '5d17e0c879d96a57f951e6e3db7da4bb3c28bd63.jpg', 'correct': '利', 'predict': ['和']}\n",
      "{'filename': '458095f2b55426ec242ba12ab9df08e6636bcb8a.jpg', 'correct': '敬', 'predict': ['御']}\n",
      "{'filename': '8d3ac4bb6a8c1de3c2edc527c25f33f0b40e231e.jpg', 'correct': '来', 'predict': ['和']}\n",
      "{'filename': '3962f3202f6ef25488ae2291e353da1dc4ad6e96.jpg', 'correct': '永', 'predict': ['从']}\n"
     ]
    }
   ],
   "source": [
    "correct_number, total_number, topk_indices, topk_classes, wrong_info = output[str(1)]\n",
    "for info in wrong_info:\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the wrong images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iu.show_images_in_wrong_info(wrong_info, 'datasets/validation', number=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write answer in the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 1 classes.\n",
      "OK!\n"
     ]
    }
   ],
   "source": [
    "test_generator = mu.my_generator('datasets/test',\n",
    "                                 shuffle=False,\n",
    "                                 rescale=RESCALE, \n",
    "                                 batch_size=BATCH_SIZE, \n",
    "                                 target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "                                 color_mode=COLOR_MODE)\n",
    "\n",
    "use_augment = False\n",
    "\n",
    "if use_augment:\n",
    "    prediction = em.predict_by_augment_patches(model,\n",
    "                                               'datasets/test',\n",
    "                                               test_generator, \n",
    "                                               batch_size=256, \n",
    "                                               num_classes=100,\n",
    "                                               show_first_fig=False,\n",
    "                                               rescale=RESCALE,\n",
    "                                               color_mode=COLOR_MODE, \n",
    "                                               target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "else:\n",
    "    prediction = em.get_prediction_by_single_generator(model, test_generator)\n",
    "\n",
    "    \n",
    "topk_indices = em.get_topk_indices_by_single_generator(test_generator, \n",
    "                                                       prediction=prediction, \n",
    "                                                       k=5)\n",
    "answer = cu.get_csv_format_data(test_generator, class_indices, topk_indices=topk_indices)\n",
    "cu.write_into_csv(answer, 'test.csv')\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get and write top1 answer into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cu.get_top1_from_topk_and_write('results.csv', 'top1_results.csv')\n",
    "print('OK!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
